{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T11:45:42.602230Z",
     "start_time": "2025-12-15T11:45:39.486592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.ma.core import shape\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from triton.language import dtype\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ],
   "id": "51d9cd7f105a3ecd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T11:45:42.747064Z",
     "start_time": "2025-12-15T11:45:42.613871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verify that GPU is connected and available\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(torch.cuda.get_device_name(0))"
   ],
   "id": "4dc4960e2b98d73c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu128\n",
      "NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T11:45:44.717347Z",
     "start_time": "2025-12-15T11:45:44.552671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class MSGameManager:\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        self.player_board = torch.zeros([22, 22], dtype=torch.int8)\n",
    "        self.mine_board = torch.zeros([22, 22], dtype=torch.int8) # Location of All Mines, 9 for mine, 0-8 for clue\n",
    "        self.flagged_board = torch.zeros([22, 22], dtype=torch.int8)\n",
    "        self.opened_board = torch.zeros([22, 22], dtype=torch.int8)\n",
    "        self.number_of_mines = -1\n",
    "\n",
    "        # Logic bot variables\n",
    "        self.cells_remaining = set()\n",
    "        self.inferred_safe = set()\n",
    "        self.inferred_mine = set()\n",
    "        self.clue_number = dict()\n",
    "        self.size = 22\n",
    "        self.moves_taken = 0\n",
    "        self.initial_start_coords = None\n",
    "        self.is_game_over = False\n",
    "        self.mines_triggered = 0\n",
    "\n",
    "    def reset_game(self):\n",
    "        # This method handles resetting ALL state variables for a new game\n",
    "        self.player_board = torch.zeros([self.size, self.size], dtype=torch.int8)\n",
    "        self.mine_board = torch.zeros([self.size, self.size], dtype=torch.int8)\n",
    "        self.flagged_board = torch.zeros([self.size, self.size], dtype=torch.int8)\n",
    "        self.opened_board = torch.zeros([self.size, self.size], dtype=torch.int8)\n",
    "        self.number_of_mines = -1 # Set back to default, to be set later\n",
    "        self.cells_remaining = set()\n",
    "        self.inferred_safe = set()\n",
    "        self.inferred_mine = set()\n",
    "        self.clue_number = dict()\n",
    "        self.moves_taken = 0\n",
    "        self.initial_start_coords = None\n",
    "        self.is_game_over = False\n",
    "        self.mines_triggered = 0\n",
    "\n",
    "    def initialize_board(self, difficulty: str):\n",
    "\n",
    "        self.reset_game()\n",
    "\n",
    "        self.number_of_mines = 50 if difficulty == \"easy\" \\\n",
    "            else 80 if difficulty == \"medium\" \\\n",
    "                else 100\n",
    "\n",
    "        # Add all cells into the remaining set and reset boards\n",
    "        self.cells_remaining = set((r, c) for r in range(self.size) for c in range(self.size))\n",
    "        self.mine_board = torch.zeros([self.size, self.size], dtype=torch.int8)\n",
    "\n",
    "        # Generate a random starting location\n",
    "        initial_start = torch.randint(0, self.size, (2, ), dtype=torch.int8)\n",
    "        start_r, start_c = initial_start[0].item(), initial_start[1].item()\n",
    "        self.initial_start_coords = (start_r, start_c)\n",
    "\n",
    "        # Remove the starting cell from the board\n",
    "        self.cells_remaining.remove(self.initial_start_coords)\n",
    "\n",
    "        # All possible coordinates excluding the initial start cell\n",
    "        possible_mine_locations = list(self.cells_remaining)\n",
    "\n",
    "        # Grab the squares that will be set to mines\n",
    "        mine_locations = random.sample(possible_mine_locations, self.number_of_mines)\n",
    "\n",
    "        # Place mines on the mine board\n",
    "        MINE = 9\n",
    "        for r, c in mine_locations:\n",
    "            self.mine_board[r, c] = MINE\n",
    "\n",
    "        # Calculate and place clues on the mine_board\n",
    "        self.calculate_clues()\n",
    "\n",
    "        # Perform the initial move so we can have a starting board\n",
    "        self.open_cell(start_r, start_c)\n",
    "\n",
    "    def start_bot_game(self, difficulty: str, allow_mine: bool = False):\n",
    "\n",
    "        self.initialize_board(difficulty)\n",
    "        self.is_game_over = False\n",
    "        self.moves_taken = 0\n",
    "        self.mines_triggered = 0\n",
    "\n",
    "        while not self.is_game_over:\n",
    "\n",
    "            # 1. Get the bot's next move choice\n",
    "            move = self.get_logic_bot_move()  # ← Assign to variable first\n",
    "\n",
    "            # 2. CHECK FOR None BEFORE UNPACKING\n",
    "            if move is None:\n",
    "                self.is_game_over = True\n",
    "                break\n",
    "\n",
    "            r, c = move  # ← Now safe to unpack\n",
    "\n",
    "            # 3. Execute the move\n",
    "            success, game_over = self.make_move(r, c, allow_mine)\n",
    "\n",
    "            if game_over:\n",
    "                self.is_game_over = True\n",
    "                break\n",
    "\n",
    "        # Return the required metrics\n",
    "        return {\n",
    "            \"success\": self.check_win_condition(),\n",
    "            \"moves_taken\": self.moves_taken,\n",
    "            \"mines_triggered\": self.mines_triggered\n",
    "        }\n",
    "\n",
    "    def get_neighbors(self, r, c):\n",
    "        \"\"\"Returns a list of valid neighboring coordinates (up to 8).\"\"\"\n",
    "        neighbors = []\n",
    "        for dr in [-1, 0, 1]:\n",
    "            for dc in [-1, 0, 1]:\n",
    "                if dr == 0 and dc == 0:\n",
    "                    continue\n",
    "                nr, nc = r + dr, c + dc\n",
    "\n",
    "                # Check for boundary conditions\n",
    "                if 0 <= nr < self.size and 0 <= nc < self.size:\n",
    "                    neighbors.append((nr, nc))\n",
    "        return neighbors\n",
    "\n",
    "    def calculate_clues(self):\n",
    "        \"\"\"Iterates over the board and calculates the clue number for non-mine cells.\"\"\"\n",
    "        MINE = 9\n",
    "\n",
    "        for r in range(self.size):\n",
    "            for c in range(self.size):\n",
    "\n",
    "                # Skip square if it is a mine\n",
    "                if self.mine_board[r, c] == MINE:\n",
    "                    continue\n",
    "\n",
    "                mine_count = 0\n",
    "                for nr, nc in self.get_neighbors(r, c):\n",
    "                    # Check if the neighbor is a mine\n",
    "                    if self.mine_board[nr, nc] == MINE:\n",
    "                        mine_count += 1\n",
    "\n",
    "                # Store the clue number (0-8) on the mine_board\n",
    "                self.mine_board[r, c] = mine_count\n",
    "\n",
    "    def open_cell(self, r, c, allow_mine: bool = False):\n",
    "        \"\"\"\n",
    "        Performs the action of opening a cell, updating all state boards,\n",
    "        and handling the chain reaction if a blank (clue 0) is hit.\n",
    "        Returns: True if the move was successful (not a mine), False otherwise.\n",
    "        \"\"\"\n",
    "        if self.opened_board[r, c] == 1:\n",
    "            return True # Already opened, treat as successful non-fatal move\n",
    "\n",
    "        # 1. Update general state\n",
    "        self.opened_board[r, c] = 1\n",
    "        coord = (r, c)\n",
    "        if coord in self.cells_remaining:\n",
    "             self.cells_remaining.remove(coord)\n",
    "\n",
    "        # Also remove from inferred sets if it was picked\n",
    "        if coord in self.inferred_safe:\n",
    "            self.inferred_safe.remove(coord)\n",
    "\n",
    "        # 2. Get the ground truth value\n",
    "        value = self.mine_board[r, c].item()\n",
    "\n",
    "        MINE_CODE = 9\n",
    "\n",
    "        if value == MINE_CODE: # Mine is hit\n",
    "            self.is_game_over = True if not allow_mine else False\n",
    "            self.mines_triggered += 1\n",
    "            self.player_board[r, c] = -1 # A code for 'detonated mine'\n",
    "            return False # Game over, move was unsuccessful\n",
    "\n",
    "        elif value == 0: # Blank cell (Clue 0) - start chain reaction\n",
    "            self.player_board[r, c] = 9 # Use 9 for revealed blank\n",
    "            self.clue_number[coord] = 0\n",
    "\n",
    "            # --- Chain Reaction Logic (using BFS for cascade) ---\n",
    "            # ... (The full chain reaction logic from the previous answer goes here) ...\n",
    "\n",
    "            queue = [(r, c)]\n",
    "            visited = set([(r, c)])\n",
    "\n",
    "            while queue:\n",
    "                curr_r, curr_c = queue.pop(0)\n",
    "\n",
    "                for nr, nc in self.get_neighbors(curr_r, curr_c):\n",
    "                    neighbor_coord = (nr, nc)\n",
    "                    if neighbor_coord in visited or self.opened_board[nr, nc] == 1:\n",
    "                        continue\n",
    "\n",
    "                    visited.add(neighbor_coord)\n",
    "                    true_value = self.mine_board[nr, nc].item()\n",
    "\n",
    "                    if true_value == 0:\n",
    "                        # Continue the cascade (reveal blank, add to queue)\n",
    "                        self.player_board[nr, nc] = 9\n",
    "                        self.opened_board[nr, nc] = 1\n",
    "                        self.clue_number[neighbor_coord] = 0\n",
    "                        if neighbor_coord in self.cells_remaining:\n",
    "                            self.cells_remaining.remove(neighbor_coord)\n",
    "                        queue.append(neighbor_coord)\n",
    "\n",
    "                    elif 1 <= true_value <= 8:\n",
    "                        # Stop the cascade (reveal clue)\n",
    "                        self.player_board[nr, nc] = true_value\n",
    "                        self.opened_board[nr, nc] = 1\n",
    "                        self.clue_number[neighbor_coord] = true_value\n",
    "                        if neighbor_coord in self.cells_remaining:\n",
    "                            self.cells_remaining.remove(neighbor_coord)\n",
    "\n",
    "            return True\n",
    "\n",
    "        elif 1 <= value <= 8: # Clue cell\n",
    "            self.player_board[r, c] = value\n",
    "            self.clue_number[coord] = value\n",
    "            return True\n",
    "\n",
    "        return True # Should not be reached, but ensures return value\n",
    "\n",
    "    def get_logic_bot_move(self):\n",
    "        \"\"\"\n",
    "        The main move logic for the simple bot.\n",
    "        1. Runs inferences to find safe cells.\n",
    "        2. Picks an inferred safe cell if available, otherwise picks randomly.\n",
    "        Returns: (r, c) tuple of the next move.\n",
    "        \"\"\"\n",
    "        # Step 1: Run inferences until the board is stable [cite: 24]\n",
    "        self.run_logic_inferences()\n",
    "\n",
    "        # Step 2: Select a cell to open [cite: 18]\n",
    "        if self.inferred_safe:\n",
    "            # Pick one of the inferred safe cells\n",
    "            r, c = self.inferred_safe.pop()\n",
    "        elif self.cells_remaining:\n",
    "            # No safe inference found, pick a cell from the remaining pool at random [cite: 18]\n",
    "            r, c = random.choice(list(self.cells_remaining))\n",
    "            # Note: The assignment implies the cells_remaining only holds cells *not* inferred as mine.\n",
    "        else:\n",
    "            # Game is likely won or stuck\n",
    "            return None\n",
    "\n",
    "        return r, c\n",
    "\n",
    "    def make_move(self, r, c, allow_mine: bool = False):\n",
    "        \"\"\"\n",
    "        Executes a move at (r, c) and updates game state and metrics.\n",
    "        Returns: Tuple (success: bool, is_game_over: bool)\n",
    "        \"\"\"\n",
    "        if self.is_game_over or self.opened_board[r, c] == 1:\n",
    "            return True, self.is_game_over # Cannot make move or already open\n",
    "\n",
    "        # If the move is flagged, we assume the bot unflags it first (optional)\n",
    "        if self.flagged_board[r, c] == 1:\n",
    "             self.flagged_board[r, c] = 0 # Unflag before opening\n",
    "\n",
    "        self.moves_taken += 1 # Increment step counter\n",
    "\n",
    "        move_successful = self.open_cell(r, c, allow_mine)\n",
    "\n",
    "        # Check for win condition after a successful move\n",
    "        if move_successful and self.check_win_condition():\n",
    "            self.is_game_over = True\n",
    "\n",
    "        return move_successful, self.is_game_over\n",
    "\n",
    "    def check_win_condition(self):\n",
    "        \"\"\"Checks if all safe cells have been opened.\"\"\"\n",
    "        total_cells = self.size * self.size\n",
    "        cells_opened = torch.sum(self.opened_board).item()\n",
    "\n",
    "        # Win condition: Number of opened cells equals (Total Cells - Number of Mines)\n",
    "        return cells_opened == (total_cells - self.number_of_mines)\n",
    "\n",
    "    def run_logic_inferences(self):\n",
    "        \"\"\"\n",
    "        Applies the two main Minesweeper logic rules iteratively until no new inferences are found.\n",
    "        Returns True if any new inference was made, False otherwise.\n",
    "        \"\"\"\n",
    "        inferences_made = False\n",
    "\n",
    "        # [cite_start]Loop until a full pass yields no new inferences [cite: 24]\n",
    "        while True:\n",
    "            new_inferences_in_pass = False\n",
    "\n",
    "            # Iterate over all cells where a clue has been revealed\n",
    "            for r, c in list(self.clue_number.keys()):\n",
    "                clue = self.clue_number[(r, c)]\n",
    "                neighbors = self.get_neighbors(r, c)\n",
    "\n",
    "                # --- Categorize Neighbors ---\n",
    "                unrevealed_neighbors = set()\n",
    "                mines_inferred_count = 0\n",
    "                safe_inferred_count = 0\n",
    "\n",
    "                for nr, nc in neighbors:\n",
    "                    coord = (nr, nc)\n",
    "                    if coord in self.inferred_mine:\n",
    "                        mines_inferred_count += 1\n",
    "                    elif coord in self.inferred_safe or self.opened_board[nr, nc] == 1:\n",
    "                        safe_inferred_count += 1\n",
    "                    elif self.opened_board[nr, nc] == 0:\n",
    "                        # This cell is truly unrevealed and un-inferred\n",
    "                        unrevealed_neighbors.add(coord)\n",
    "\n",
    "                num_unrevealed = len(unrevealed_neighbors)\n",
    "\n",
    "                # 1. Mine Inference (Rule 1)\n",
    "                # [cite_start]If (cell clue) - (# neighbors inferred to be mines) = (# unrevealed neighbors) [cite: 22]\n",
    "                if clue - mines_inferred_count == num_unrevealed and num_unrevealed > 0:\n",
    "                    for nr, nc in unrevealed_neighbors:\n",
    "                        coord = (nr, nc)\n",
    "\n",
    "                        # Only infer if not already marked as mine\n",
    "                        if coord not in self.inferred_mine:\n",
    "                            self.inferred_mine.add(coord)\n",
    "\n",
    "                            # --- FIX: FLAG THE INFERRED MINE ---\n",
    "                            self.flagged_board[nr, nc] = 1 # Mark the cell as flagged\n",
    "\n",
    "                            # [cite_start]Remove them from cells_remaining [cite: 22]\n",
    "                            if coord in self.cells_remaining:\n",
    "                                self.cells_remaining.remove(coord)\n",
    "\n",
    "                            new_inferences_in_pass = True\n",
    "\n",
    "                # 2. Safe Inference (Rule 2)\n",
    "                # [cite_start]If ((# neighbors) - (cell clue)) - (# neighbors revealed or inferred to be safe) = (# unrevealed neighbors) [cite: 23]\n",
    "                num_non_mines_required = len(neighbors) - clue\n",
    "\n",
    "                # Total cells known to be safe (opened + inferred safe)\n",
    "                total_known_safe = safe_inferred_count + num_unrevealed\n",
    "\n",
    "                # If the total known safe cells (including all unrevealed) equals\n",
    "                # the total number of non-mines possible\n",
    "                if num_non_mines_required == total_known_safe and num_unrevealed > 0:\n",
    "                    for nr, nc in unrevealed_neighbors:\n",
    "                        coord = (nr, nc)\n",
    "\n",
    "                        # Only infer if not already marked as safe\n",
    "                        if coord not in self.inferred_safe and self.opened_board[nr, nc] == 0:\n",
    "                            self.inferred_safe.add(coord)\n",
    "                            # [cite_start]Remove from cells_remaining [cite: 23]\n",
    "                            if coord in self.cells_remaining:\n",
    "                                self.cells_remaining.remove(coord)\n",
    "\n",
    "                            new_inferences_in_pass = True\n",
    "\n",
    "            # [cite_start]If no new inferences were made in this full pass, the loop terminates [cite: 24]\n",
    "            if not new_inferences_in_pass:\n",
    "                break\n",
    "            else:\n",
    "                inferences_made = True\n",
    "\n",
    "        return inferences_made\n",
    "\n",
    "    # def get_nn_input_state(self):\n",
    "    #     \"\"\"\n",
    "    #     Creates the 4-channel input tensor (4, 22, 22) for the Neural Network.\n",
    "    #     \"\"\"\n",
    "    #     size = self.size\n",
    "    #\n",
    "    #     # Channel 1: Clue Values (0-8)\n",
    "    #     # Use player_board, but replace the 'blank' code (9) with 0 for clean clue representation\n",
    "    #     clues_channel = self.player_board.clone().float()\n",
    "    #     clues_channel[clues_channel == 9] = 0.0\n",
    "    #     clues_channel[clues_channel == -1] = 0.0 # Ignore detonated mines if applicable\n",
    "    #\n",
    "    #     # Channel 2: Opened Mask (1/0)\n",
    "    #     opened_mask_channel = self.opened_board.clone().float()\n",
    "    #\n",
    "    #     # Channel 3: Flag Mask (1/0)\n",
    "    #     flag_mask_channel = self.flagged_board.clone().float()\n",
    "    #\n",
    "    #     # Channel 4: Global Context (e.g., Mine Density)\n",
    "    #     # Represented as the ratio of mines to total cells\n",
    "    #     mine_density = self.number_of_mines / (size * size)\n",
    "    #     global_context_channel = torch.full((size, size), mine_density, dtype=torch.float32)\n",
    "    #\n",
    "    #     # Stack the channels\n",
    "    #     nn_input = torch.stack([\n",
    "    #         clues_channel,\n",
    "    #         opened_mask_channel,\n",
    "    #         flag_mask_channel,\n",
    "    #         global_context_channel\n",
    "    #     ], dim=0)\n",
    "    #\n",
    "    #     return nn_input\n",
    "\n",
    "    def get_nn_input_state(self):\n",
    "        \"\"\"\n",
    "        Creates the 10-channel input tensor for the Neural Network using one-hot encoding for clues.\n",
    "        Channels: 9 Clue One-Hot + 1 Opened Mask.\n",
    "        \"\"\"\n",
    "        size = self.size\n",
    "\n",
    "        # Start with the player_board, clean up the codes (9 for blank, -1 for mine)\n",
    "        clue_board = self.player_board.clone().float()\n",
    "\n",
    "        # Treat detonated mines (-1) and untouched mines (implicit 0) as 0 for this step\n",
    "        clue_board[clue_board == -1] = 0.0\n",
    "\n",
    "        # --- 1. Clue Identity Channels (9 channels: 0 through 8) ---\n",
    "        clue_channels = []\n",
    "\n",
    "        for clue_value in range(9):\n",
    "            if clue_value == 0:\n",
    "                # FIX: Only select Revealed Blanks (9.0).\n",
    "                # Do NOT include Unopened (0.0).\n",
    "                mask = (clue_board == 9.0)\n",
    "            else:\n",
    "                mask = (clue_board == clue_value)\n",
    "\n",
    "            clue_channels.append(mask.float())\n",
    "\n",
    "        # Convert list of tensors to a single tensor of shape (9, 22, 22)\n",
    "        clue_input = torch.stack(clue_channels, dim=0)\n",
    "\n",
    "\n",
    "        # --- 2. Board State Channel (1 channel) ---\n",
    "        # Channel 10: Opened Mask (Already 1/0)\n",
    "        # Use unsqueeze(0) to give it a channel dimension (1, 22, 22)\n",
    "        opened_mask_channel = self.opened_board.clone().float().unsqueeze(0)\n",
    "\n",
    "        # --- Final Stack ---\n",
    "        # Stack the 9 clue channels and 1 opened mask channel\n",
    "        nn_input = torch.cat([\n",
    "            clue_input,\n",
    "            opened_mask_channel,\n",
    "        ], dim=0)\n",
    "\n",
    "        # Resulting shape: (10, 22, 22)\n",
    "        return nn_input\n",
    "\n",
    "    def get_safety_label(self):\n",
    "        \"\"\"\n",
    "        Creates ground-truth MINE map.\n",
    "        - 1.0 for mines (unopened)\n",
    "        - 0.0 for safe, unopened cells\n",
    "        - -1.0 for opened cells (masked out)\n",
    "        \"\"\"\n",
    "        MINE_CODE = 9\n",
    "\n",
    "        # 1. Start with All Zeros\n",
    "        # (We assume everything is safe/0.0 initially)\n",
    "        mine_label = torch.zeros((self.size, self.size), dtype=torch.float32)\n",
    "\n",
    "        # 2. Mark Mines as 1.0\n",
    "        mine_label[self.mine_board == MINE_CODE] = 1.0\n",
    "\n",
    "        # 3. Mask out opened cells with -1.0\n",
    "        mine_label[self.opened_board == 1] = -1.0\n",
    "\n",
    "        return mine_label\n",
    "\n",
    "\n",
    "    def generate_random_walk_data(self, difficulty: str, num_games: int, min_moves: int = 20, max_moves: int = 150):\n",
    "        \"\"\"\n",
    "        Generates training data (X, Y) for Task 1 (Mine Prediction).\n",
    "        The policy takes a limited number of random, safe steps (not using logic bot)\n",
    "        to ensure data contains varied mid-game states.\n",
    "\n",
    "        Returns:\n",
    "            X_data: (N, 4, 22, 22) - board states\n",
    "            Y_data: (N, 22, 22) - ground truth safety maps\n",
    "        \"\"\"\n",
    "        X_data = [] # List of (4, 22, 22) input tensors\n",
    "        Y_data = [] # List of (22, 22) output safety label tensors\n",
    "\n",
    "        for game_idx in range(num_games):\n",
    "            self.reset_game()\n",
    "            self.initialize_board(difficulty)\n",
    "\n",
    "            if game_idx == 0:\n",
    "                print(f\"Generating Task 1 Random Walk data ({min_moves}-{max_moves} steps)...\")\n",
    "\n",
    "            # 1. Determine the maximum number of moves for this run\n",
    "            max_steps_for_game = random.randint(min_moves, max_moves)\n",
    "\n",
    "            self.moves_taken = 0\n",
    "            self.is_game_over = False\n",
    "            moves_made = 0\n",
    "\n",
    "            # Get list of all unopened cells after initial cascade\n",
    "            current_unopened_cells = list(set((r, c) for r in range(self.size) for c in range(self.size) if self.opened_board[r, c] == 0))\n",
    "\n",
    "            # Loop to take moves up to the max_steps_for_game threshold\n",
    "            while not self.is_game_over and moves_made < max_steps_for_game:\n",
    "\n",
    "                if not current_unopened_cells:\n",
    "                    break\n",
    "\n",
    "                # --- DATA COLLECTION POINT (BEFORE THE MOVE) ---\n",
    "\n",
    "                # 1. Capture the current state (X)\n",
    "                current_input_state = self.get_nn_input_state() # 4-channel input\n",
    "\n",
    "                # 2. Capture the ground truth label (Y)\n",
    "                current_safety_label = self.get_safety_label()\n",
    "\n",
    "                # Store the data pair\n",
    "                X_data.append(current_input_state)\n",
    "                Y_data.append(current_safety_label)\n",
    "\n",
    "                # --- MOVE DECISION: Random Safe Move ---\n",
    "\n",
    "                # Find only the SAFE, unopened cells for random selection\n",
    "                safe_unopened_cells = [(r, c) for r, c in current_unopened_cells if self.mine_board[r, c].item() != 9]\n",
    "\n",
    "                if not safe_unopened_cells:\n",
    "                    # No safe moves left, forced to click a mine, so we stop data collection here.\n",
    "                    self.is_game_over = True\n",
    "                    break\n",
    "\n",
    "                # 3. Select a random safe move\n",
    "                r, c = random.choice(safe_unopened_cells)\n",
    "\n",
    "                # 4. Execute the move (allow_mine=False since we only select safe cells)\n",
    "                success, game_over = self.make_move(r, c, allow_mine=False)\n",
    "\n",
    "                if game_over:\n",
    "                    # Should not happen since we checked for mines, but break if win condition hit\n",
    "                    self.is_game_over = True\n",
    "                    break\n",
    "\n",
    "                moves_made += 1\n",
    "\n",
    "                # Update the list of unopened cells for the next iteration\n",
    "                current_unopened_cells = list(set((r, c) for r in range(self.size) for c in range(self.size) if self.opened_board[r, c] == 0))\n",
    "\n",
    "\n",
    "            if (game_idx + 1) % 100 == 0:\n",
    "                print(f\"Completed {game_idx + 1} games. Total data points: {len(X_data)}\")\n",
    "\n",
    "        # Convert lists to final PyTorch tensors\n",
    "        X_tensor = torch.stack(X_data)\n",
    "        Y_tensor = torch.stack(Y_data)\n",
    "\n",
    "        return X_tensor, Y_tensor\n",
    "\n",
    "    def generate_training_data(self, difficulty: str, num_games: int, allow_mine: bool = False):\n",
    "\n",
    "        # Lists to store the collected Input (X) and Output (Y) tensors\n",
    "        X_data = [] # List of (4, 22, 22) input tensors\n",
    "        Y_data = [] # List of (22, 22) output safety label tensors\n",
    "\n",
    "        for game_idx in range(num_games):\n",
    "\n",
    "            # Start a fresh game\n",
    "            self.reset_game()\n",
    "            self.initialize_board(difficulty)\n",
    "\n",
    "            # Print after initialize_board sets number_of_mines\n",
    "            if game_idx == 0:\n",
    "                mode_str = \"with mines allowed\" if allow_mine else \"standard mode\"\n",
    "                print(f\"Generating data for {difficulty.upper()} difficulty ({self.number_of_mines} mines) - {mode_str}...\")\n",
    "\n",
    "            self.is_game_over = False\n",
    "            self.moves_taken = 0\n",
    "            self.mines_triggered = 0\n",
    "\n",
    "            # Logic Bot Play Loop\n",
    "            while not self.is_game_over:\n",
    "\n",
    "                # --- DATA COLLECTION POINT (BEFORE THE MOVE) ---\n",
    "\n",
    "                # 1. Capture the current state (X)\n",
    "                current_input_state = self.get_nn_input_state()\n",
    "\n",
    "                # 2. Capture the ground truth label (Y)\n",
    "                current_safety_label = self.get_safety_label()\n",
    "\n",
    "                # Store the data pair\n",
    "                X_data.append(current_input_state)\n",
    "                Y_data.append(current_safety_label)\n",
    "\n",
    "                # --- BOT DECISION AND EXECUTION ---\n",
    "\n",
    "                # 3. Get the bot's next move choice (r, c)\n",
    "                move = self.get_logic_bot_move()\n",
    "\n",
    "                # CHECK FOR None BEFORE UNPACKING\n",
    "                if move is None:\n",
    "                    # Game ended (won or no moves left)\n",
    "                    self.is_game_over = True\n",
    "                    break\n",
    "\n",
    "                r, c = move  # Now safe to unpack\n",
    "\n",
    "                # 4. Execute the move (updates game state)\n",
    "                success, game_over = self.make_move(r, c, allow_mine)\n",
    "\n",
    "            if (game_idx + 1) % 100 == 0:\n",
    "                print(f\"Completed {game_idx + 1} games. Total data points: {len(X_data)}\")\n",
    "\n",
    "        # Convert lists to final PyTorch tensors\n",
    "        X_tensor = torch.stack(X_data)\n",
    "        Y_tensor = torch.stack(Y_data)\n",
    "\n",
    "        return X_tensor, Y_tensor\n",
    "\n",
    "    def get_frontier_mask(self):\n",
    "        \"\"\"\n",
    "        Uses 2D Convolution to find the 'Frontier': Unopened cells adjacent to Opened cells.\n",
    "        Returns: (22, 22) tensor where 1.0 = Frontier, 0.0 = Background/Opened\n",
    "        \"\"\"\n",
    "        # Ensure opened_board is float for conv2d\n",
    "        # Add Batch and Channel dims: (1, 1, 22, 22)\n",
    "        opened_input = self.opened_board.float().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # 3x3 Kernel of 1s to aggregate neighbors\n",
    "        kernel = torch.ones((1, 1, 3, 3), dtype=torch.float32)\n",
    "\n",
    "        # Convolve: padding=1 ensures output size matches board size\n",
    "        neighbor_count = F.conv2d(opened_input, kernel, padding=1)\n",
    "\n",
    "        # Squeeze back to (22, 22)\n",
    "        neighbor_count = neighbor_count.squeeze()\n",
    "\n",
    "        # Frontier Definition:\n",
    "        # 1. Must have at least one opened neighbor (neighbor_count > 0)\n",
    "        # 2. Must NOT be opened itself (self.opened_board == 0)\n",
    "        frontier_mask = (neighbor_count > 0) & (self.opened_board == 0)\n",
    "\n",
    "        return frontier_mask.float()\n",
    "\n",
    "    def get_constrained_safety_label(self):\n",
    "        \"\"\"\n",
    "        Generates Y label for Safe Prediction (1=Safe, 0=Mine),\n",
    "        BUT masks out everything except the Frontier.\n",
    "\n",
    "        Returns:\n",
    "             Y tensor where:\n",
    "             1.0 = Safe Frontier\n",
    "             0.0 = Mine Frontier\n",
    "            -1.0 = Everything else (Fog, Opened cells) -> Ignored by Loss\n",
    "        \"\"\"\n",
    "        MINE_CODE = 9\n",
    "\n",
    "        # 1. Get the Frontier Mask\n",
    "        frontier = self.get_frontier_mask()\n",
    "\n",
    "        # 2. Start with a mask of -1.0 (Ignore everything)\n",
    "        label = torch.full((self.size, self.size), -1.0, dtype=torch.float32)\n",
    "\n",
    "        # 3. Apply labels ONLY where Frontier is active\n",
    "        # Identify mines and safe cells\n",
    "        is_mine = (self.mine_board == MINE_CODE)\n",
    "        is_safe = (self.mine_board != MINE_CODE)\n",
    "\n",
    "        # Set Frontier Mines to 0.0\n",
    "        label[frontier.bool() & is_mine] = 0.0\n",
    "\n",
    "        # Set Frontier Safe cells to 1.0\n",
    "        label[frontier.bool() & is_safe] = 1.0\n",
    "\n",
    "        return label\n",
    "\n",
    "    def generate_frontier_training_data(self, difficulty: str, num_games: int, min_moves: int = 20, max_moves: int = 150):\n",
    "        \"\"\"\n",
    "        Generates data by playing 'realistically':\n",
    "        Only clicking safe cells that are on the frontier.\n",
    "        \"\"\"\n",
    "        X_data = []\n",
    "        Y_data = []\n",
    "\n",
    "        for game_idx in range(num_games):\n",
    "            self.reset_game()\n",
    "            self.initialize_board(difficulty)\n",
    "\n",
    "            if game_idx == 0:\n",
    "                print(f\"Generating Frontier-Constrained Data ({difficulty})...\")\n",
    "\n",
    "            max_steps = random.randint(min_moves, max_moves)\n",
    "            steps = 0\n",
    "\n",
    "            while not self.is_game_over and steps < max_steps:\n",
    "\n",
    "                # --- 1. Identify Valid Moves (Safe Frontier) ---\n",
    "                # Get the frontier mask\n",
    "                frontier = self.get_frontier_mask()\n",
    "\n",
    "                # Filter for SAFE cells on the frontier\n",
    "                # Note: We cheat slightly here to generate 'Safe' training data,\n",
    "                # ensuring the bot sees valid gameplay sequences.\n",
    "                safe_frontier_indices = torch.nonzero(frontier.bool() & (self.mine_board != 9), as_tuple=False)\n",
    "\n",
    "                if len(safe_frontier_indices) == 0:\n",
    "                    # If frontier is purely mines (or empty at start), we must pick ANY safe unopened cell to continue\n",
    "                    # (This happens rarely, usually at start or end game)\n",
    "                    unopened = (self.opened_board == 0) & (self.mine_board != 9)\n",
    "                    safe_indices = torch.nonzero(unopened, as_tuple=False)\n",
    "                    if len(safe_indices) == 0: break\n",
    "                    move_idx = random.randint(0, len(safe_indices) - 1)\n",
    "                    r, c = safe_indices[move_idx].tolist()\n",
    "                else:\n",
    "                    # Pick a random SAFE FRONTIER cell (Realistic play)\n",
    "                    move_idx = random.randint(0, len(safe_frontier_indices) - 1)\n",
    "                    r, c = safe_frontier_indices[move_idx].tolist()\n",
    "\n",
    "                # --- 2. Capture Data ---\n",
    "                X_data.append(self.get_nn_input_state()) # Your existing 10-channel input\n",
    "                Y_data.append(self.get_constrained_safety_label()) # NEW Frontier-only label\n",
    "\n",
    "                # --- 3. Make Move ---\n",
    "                self.make_move(r, c, allow_mine=False)\n",
    "                steps += 1\n",
    "\n",
    "            if (game_idx + 1) % 100 == 0:\n",
    "                print(f\"Generated {game_idx + 1} games. Total samples: {len(X_data)}\")\n",
    "\n",
    "        return torch.stack(X_data), torch.stack(Y_data)\n",
    "\n",
    "\n",
    "    def generate_critic_training_data(self, difficulty: str, num_games: int, actor: nn.Module):\n",
    "        \"\"\"\n",
    "        Generates training data for Critic using 5-channel input.\n",
    "\n",
    "        Input: (5, 22, 22) where channel 4 is the selected move\n",
    "        Output: number of moves survived\n",
    "        \"\"\"\n",
    "        X_data = []  # List of (5, 22, 22) tensors\n",
    "        Y_data = []  # List of survival counts\n",
    "\n",
    "        for game_idx in range(num_games):\n",
    "            self.reset_game()\n",
    "            self.initialize_board(difficulty)\n",
    "\n",
    "            if game_idx == 0:\n",
    "                print(f\"Generating Critic data for {difficulty.upper()} (5-channel approach)...\")\n",
    "\n",
    "            # Store game trajectory\n",
    "            game_inputs = []\n",
    "\n",
    "            while not self.is_game_over:\n",
    "                # Get current 4-channel state\n",
    "                current_state = self.get_nn_input_state()  # (4, 22, 22)\n",
    "\n",
    "                # Get move from actor\n",
    "                if actor is None:\n",
    "                    move = self.get_logic_bot_move()\n",
    "                else:\n",
    "                    pass\n",
    "                    move = self.get_actor_move(actor)  # Your trained actor\n",
    "\n",
    "                if move is None:\n",
    "                    break\n",
    "\n",
    "                r, c = move\n",
    "\n",
    "                # Create move channel (one-hot encoding of the move)\n",
    "                move_channel = torch.zeros((self.size, self.size), dtype=torch.float32)\n",
    "                move_channel[r, c] = 1.0\n",
    "\n",
    "                # Combine into 5-channel input\n",
    "                full_input = torch.cat([\n",
    "                    current_state,  # (4, 22, 22)\n",
    "                    move_channel.unsqueeze(0)  # (1, 22, 22)\n",
    "                ], dim=0)  # Result: (5, 22, 22)\n",
    "\n",
    "                game_inputs.append(full_input)\n",
    "\n",
    "                # Execute move (allow continuing after mines)\n",
    "                success, game_over = self.make_move(r, c, allow_mine=True)\n",
    "\n",
    "            # Retrospectively label with survival counts\n",
    "            total_moves = len(game_inputs)\n",
    "            for i in range(total_moves):\n",
    "                moves_survived = total_moves - i\n",
    "\n",
    "                X_data.append(game_inputs[i])\n",
    "                Y_data.append(moves_survived)\n",
    "\n",
    "            if (game_idx + 1) % 100 == 0:\n",
    "                print(f\"Completed {game_idx + 1} games. Total data points: {len(X_data)}\")\n",
    "\n",
    "        return torch.stack(X_data), torch.tensor(Y_data, dtype=torch.float32)\n",
    "\n",
    "    def generate_actor_training_data(self, difficulty: str, num_games: int, critic_model):\n",
    "        \"\"\"\n",
    "        Generate training data for the Actor network.\n",
    "\n",
    "        Process:\n",
    "        1. For each game state, evaluate ALL possible moves using the Critic\n",
    "        2. Create targets based on Critic's predictions\n",
    "        3. Actor learns to predict these values directly from board state\n",
    "\n",
    "        Returns:\n",
    "            X_data: (N, 4, 22, 22) - board states\n",
    "            Y_data: (N, 22, 22) - value map for each cell\n",
    "        \"\"\"\n",
    "        X_data = []  # Board states\n",
    "        Y_data = []  # Value maps (predicted survival for each cell)\n",
    "\n",
    "        for game_idx in range(num_games):\n",
    "            self.reset_game()\n",
    "            self.initialize_board(difficulty)\n",
    "\n",
    "            if game_idx == 0:\n",
    "                print(f\"Generating Actor training data for {difficulty.upper()}...\")\n",
    "\n",
    "            while not self.is_game_over:\n",
    "                current_state = self.get_nn_input_state()  # (4, 22, 22)\n",
    "\n",
    "                # Create value map by querying Critic for all possible moves\n",
    "                value_map = self.create_value_map_from_critic(current_state, critic_model)\n",
    "\n",
    "                # Store this training pair\n",
    "                X_data.append(current_state)\n",
    "                Y_data.append(value_map)\n",
    "\n",
    "                # Make a move using current Actor (or logic bot initially)\n",
    "                move = self.get_best_move_from_value_map(value_map)\n",
    "\n",
    "                if move is None:\n",
    "                    break\n",
    "\n",
    "                r, c = move\n",
    "                success, game_over = self.make_move(r, c, allow_mine=False)\n",
    "\n",
    "                if not success:\n",
    "                    break\n",
    "\n",
    "            if (game_idx + 1) % 100 == 0:\n",
    "                print(f\"Actor data: Completed {game_idx + 1} games. Data points: {len(X_data)}\")\n",
    "\n",
    "        return (\n",
    "            torch.stack(X_data),   # (N, 4, 22, 22)\n",
    "            torch.stack(Y_data)    # (N, 22, 22)\n",
    "        )\n",
    "\n",
    "\n",
    "    def create_value_map_from_critic(self, current_state, critic_model):\n",
    "        \"\"\"\n",
    "        Query the Critic for all possible moves to create a value map.\n",
    "\n",
    "        Returns:\n",
    "            value_map: (22, 22) tensor where each cell contains predicted survival\n",
    "                       -1 for already opened cells\n",
    "        \"\"\"\n",
    "        value_map = torch.full((self.size, self.size), -1.0, dtype=torch.float32)\n",
    "\n",
    "        critic_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for r in range(self.size):\n",
    "                for c in range(self.size):\n",
    "                    if self.opened_board[r, c] == 0:  # Unopened cell\n",
    "                        # Create 5-channel input for this move\n",
    "                        move_channel = torch.zeros((self.size, self.size), dtype=torch.float32)\n",
    "                        move_channel[r, c] = 1.0\n",
    "\n",
    "                        full_input = torch.cat([\n",
    "                            current_state,\n",
    "                            move_channel.unsqueeze(0)\n",
    "                        ], dim=0).unsqueeze(0)  # (1, 5, 22, 22)\n",
    "\n",
    "                        full_input = full_input.to(device)\n",
    "\n",
    "                        # Get Critic's prediction\n",
    "                        predicted_survival = critic_model(full_input)\n",
    "                        value_map[r, c] = predicted_survival.item()\n",
    "\n",
    "        return value_map\n",
    "\n",
    "\n",
    "    def get_best_move_from_value_map(self, value_map):\n",
    "        \"\"\"\n",
    "        Select the best move from value map.\n",
    "        \"\"\"\n",
    "        # Get valid moves (value >= 0)\n",
    "        valid_moves = []\n",
    "        values = []\n",
    "\n",
    "        for r in range(self.size):\n",
    "            for c in range(self.size):\n",
    "                if value_map[r, c] >= 0:  # Valid move\n",
    "                    valid_moves.append((r, c))\n",
    "                    values.append(value_map[r, c])\n",
    "\n",
    "        if not valid_moves:\n",
    "            return None\n",
    "\n",
    "        # Select move with highest value\n",
    "        values_tensor = torch.tensor(values)\n",
    "        best_idx = torch.argmax(values_tensor).item()\n",
    "\n",
    "        return valid_moves[best_idx]\n",
    "\n",
    "\n",
    "    def get_actor_move(self, actor):\n",
    "        \"\"\"\n",
    "        Get the best move from the Actor network.\n",
    "\n",
    "        Args:\n",
    "            actor: Trained Actor network\n",
    "\n",
    "        Returns:\n",
    "            (r, c) tuple of selected move, or None if no moves available\n",
    "        \"\"\"\n",
    "        actor.eval()\n",
    "        with torch.no_grad():\n",
    "            # Get current board state\n",
    "            current_state = self.get_nn_input_state().to(device)  # (4, 22, 22)\n",
    "\n",
    "            # Get Actor's value predictions for all cells\n",
    "            value_map = actor(current_state.unsqueeze(0)).squeeze(0)  # (22, 22)\n",
    "\n",
    "            value_map = value_map.reshape((self.size, self.size))\n",
    "\n",
    "            # Get all valid (unopened) moves and their predicted values\n",
    "            valid_moves = []\n",
    "            values = []\n",
    "\n",
    "            for r in range(self.size):\n",
    "                for c in range(self.size):\n",
    "                    if self.opened_board[r, c] == 0:  # Cell is unopened\n",
    "                        valid_moves.append((r, c))\n",
    "                        values.append(value_map[r, c].item())\n",
    "\n",
    "            if not valid_moves:\n",
    "                return None\n",
    "\n",
    "            # Select move with highest predicted value\n",
    "            values_tensor = torch.tensor(values)\n",
    "            best_idx = torch.argmax(values_tensor).item()\n",
    "\n",
    "            return valid_moves[best_idx]\n",
    "\n",
    "\n",
    "    def train_critc(self, critic, train_loader, test_loader, hp):\n",
    "        epoch_over_training = []\n",
    "        epoch_over_testing = []\n",
    "\n",
    "        # Hyperparameter setup\n",
    "        epochs = hp['epochs']\n",
    "        learning_rate = hp['learning_rate']\n",
    "        decay_rate = hp['decay_rate']\n",
    "\n",
    "        c_dropout = hp['cnn_dropout']\n",
    "        f_dropout = hp['linear_dropout']\n",
    "\n",
    "        print('######## Beginning training for MS Critic ##########')\n",
    "\n",
    "        model = critic\n",
    "        model.to(device)\n",
    "\n",
    "        loss_function = nn.MSELoss()\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(),\n",
    "                               lr=learning_rate,\n",
    "                               weight_decay=decay_rate\n",
    "                               )\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "\n",
    "        # Have references to variables outside of the epoch loop\n",
    "\n",
    "        avg_training_loss = 0\n",
    "        avg_testing_loss = 0\n",
    "\n",
    "        # Epoch Loop\n",
    "        for epoch in range(epochs):\n",
    "            print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "            avg_training_loss = 0\n",
    "            avg_testing_loss = 0\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            for x, Y in tqdm(train_loader, desc='Training', unit=' batch'):\n",
    "                # Transfer images to GPU\n",
    "                x = x.to(device)\n",
    "                Y = Y.to(device)\n",
    "\n",
    "                # Zero out gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Send images to model\n",
    "                x_pred = model(x)\n",
    "\n",
    "                Y = Y.unsqueeze(1)\n",
    "\n",
    "                # Calc loss\n",
    "                loss = loss_function(x_pred, Y)\n",
    "\n",
    "                # Calc gradient and update weights\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    avg_training_loss += loss.item()\n",
    "\n",
    "            # Switch to eval mode\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for x, Y in tqdm(test_loader, desc='Testing', unit=' batches'):\n",
    "                    # Move the images to the GPU\n",
    "                    x = x.to(device)\n",
    "                    Y = Y.to(device)\n",
    "\n",
    "                    # Get logits and sum up total loss\n",
    "                    x_pred = model(x)\n",
    "                    Y = Y.unsqueeze(1)\n",
    "                    avg_testing_loss += loss_function(x_pred, Y).item()\n",
    "\n",
    "            # Get training loss\n",
    "            avg_training_loss /= len(train_loader)\n",
    "\n",
    "             # Get testing loss\n",
    "            avg_testing_loss /= len(test_loader)\n",
    "\n",
    "            # Monitor learning\n",
    "            scheduler.step(avg_testing_loss)\n",
    "\n",
    "            # Switch model back to training mode\n",
    "            model.train()\n",
    "\n",
    "            epoch_over_training.append({\n",
    "                \"epoch\": epoch,\n",
    "                \"training_loss\": avg_training_loss\n",
    "                })\n",
    "\n",
    "            epoch_over_testing.append({\n",
    "                \"epoch\": epoch,\n",
    "                \"testing_loss\": avg_testing_loss\n",
    "                })\n",
    "\n",
    "\n",
    "            print(\"\")\n",
    "\n",
    "            print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "            print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n",
    "\n",
    "\n",
    "        return epoch_over_training, epoch_over_testing\n",
    "\n",
    "\n",
    "    def train_actor(self, actor, train_loader, test_loader, hp):\n",
    "        epoch_over_training = []\n",
    "        epoch_over_testing = []\n",
    "\n",
    "        # Hyperparameter setup\n",
    "        epochs = hp['epochs']\n",
    "        learning_rate = hp['learning_rate']\n",
    "        decay_rate = hp['decay_rate']\n",
    "\n",
    "        c_dropout = hp['cnn_dropout']\n",
    "        f_dropout = hp['linear_dropout']\n",
    "\n",
    "        print('######## Beginning training for MS Actor ##########')\n",
    "\n",
    "        model = actor\n",
    "        model.to(device)\n",
    "\n",
    "        pos_weight_tensor = torch.tensor(30.0, device=device)\n",
    "\n",
    "        loss_function = masked_bce_loss\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(),\n",
    "                               lr=learning_rate,\n",
    "                               weight_decay=decay_rate\n",
    "                               )\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "\n",
    "        # Have references to variables outside of the epoch loop\n",
    "\n",
    "        avg_training_loss = 0\n",
    "        avg_testing_loss = 0\n",
    "\n",
    "\n",
    "        # Epoch Loop\n",
    "        for epoch in range(epochs):\n",
    "            print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "            avg_training_loss = 0\n",
    "            avg_testing_loss = 0\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            for x, Y in tqdm(train_loader, desc='Training', unit=' batch'):\n",
    "                # Transfer images to GPU\n",
    "                x = x.to(device)\n",
    "                Y = Y.to(device)\n",
    "\n",
    "                # Zero out gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Send images to model\n",
    "                x_pred = model(x)\n",
    "\n",
    "                # Calc loss\n",
    "                loss = loss_function(x_pred, Y, pos_weight_tensor)\n",
    "\n",
    "                # Calc gradient and update weights\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    avg_training_loss += loss.item()\n",
    "\n",
    "            # Switch to eval mode\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for x, Y in tqdm(test_loader, desc='Testing', unit=' batches'):\n",
    "                    # Move the images to the GPU\n",
    "                    x = x.to(device)\n",
    "                    Y = Y.to(device)\n",
    "\n",
    "                    # Get logits and sum up total loss\n",
    "                    x_pred = model(x)\n",
    "                    avg_testing_loss += loss_function(x_pred, Y, pos_weight_tensor).item()\n",
    "\n",
    "            # Get training loss\n",
    "            avg_training_loss /= len(train_loader)\n",
    "\n",
    "             # Get testing loss\n",
    "            avg_testing_loss /= len(test_loader)\n",
    "\n",
    "            scheduler.step(avg_testing_loss)\n",
    "\n",
    "            # Switch model back to training mode\n",
    "            model.train()\n",
    "\n",
    "            epoch_over_training.append({\n",
    "                \"epoch\": epoch,\n",
    "                \"training_loss\": avg_training_loss\n",
    "                })\n",
    "\n",
    "            epoch_over_testing.append({\n",
    "                \"epoch\": epoch,\n",
    "                \"testing_loss\": avg_testing_loss\n",
    "                })\n",
    "\n",
    "\n",
    "            print(\"\")\n",
    "\n",
    "            print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "            print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n",
    "\n",
    "\n",
    "        return epoch_over_training, epoch_over_testing\n",
    "\n",
    "\n",
    "    def critic_and_actor_training_loop(self, hp_c, hp_a, num_of_games = 50, epochs=10, difficulty: str = 'medium'):\n",
    "\n",
    "        old_actor: nn.Module | None = None\n",
    "        old_critic: nn.Module | None = None\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Get new models\n",
    "            critic = Critic()\n",
    "            actor = Actor()\n",
    "\n",
    "            # Generate Initial Critic data based off of logic bot\n",
    "            x, y = self.generate_critic_training_data(num_games=num_of_games, difficulty=difficulty, actor=old_actor)\n",
    "\n",
    "            # Convert to dataloader\n",
    "            critic_train_loader, critic_test_loader = get_dataloader(x, y, 64)\n",
    "\n",
    "            # Train Critic\n",
    "            self.train_critc(critic=critic, train_loader=critic_train_loader, test_loader=critic_test_loader, hp=hp_c)\n",
    "\n",
    "            # Get actor data\n",
    "            x, y = self.generate_actor_training_data('medium', num_of_games, critic)\n",
    "\n",
    "            # Convert to dataloader\n",
    "            actor_train_loader, actor_test_loader = get_dataloader(x, y, 64)\n",
    "\n",
    "            # Train the actor\n",
    "            self.train_actor(actor=actor, train_loader=actor_train_loader, test_loader=actor_test_loader, hp=hp_a)\n",
    "\n",
    "            old_actor = actor\n",
    "\n",
    "\n",
    "        return old_actor, old_critic"
   ],
   "id": "532c2b183f7a8cd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:55:41.654630Z",
     "start_time": "2025-12-15T15:55:41.644968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def start_nn_game(manager, model, difficulty: str, device: torch.device, allow_mines: bool = False, thinking_time: int = 0):\n",
    "    \"\"\"\n",
    "    Runs a complete game simulation using the trained Neural Network model.\n",
    "    \"\"\"\n",
    "    manager.initialize_board(difficulty)\n",
    "    manager.is_game_over = False\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while not manager.is_game_over:\n",
    "            # 1. Get the current state (Input: X)\n",
    "            X_current = manager.get_nn_input_state().to(device)\n",
    "            # Add batch dimension: (4, 22, 22) -> (1, 4, 22, 22)\n",
    "            X_batch = X_current.unsqueeze(0)\n",
    "\n",
    "            # 2. Get the model's prediction (Output: Y_pred)\n",
    "            logits = model(X_batch) if thinking_time == -1 else model(X_batch, thinking_time)\n",
    "\n",
    "            # Convert logits to probabilities using sigmoid\n",
    "            probs = torch.sigmoid(logits)  # Range [0, 1]\n",
    "\n",
    "            # Reshape to 22x22 safety map\n",
    "            safety_map = probs.view(manager.size, manager.size)  # Shape: (22, 22)\n",
    "\n",
    "            # 3. Choose the move (The NN's decision logic)\n",
    "            r, c = get_nn_move_choice(safety_map, manager.opened_board.to(device))\n",
    "\n",
    "            if r is None:\n",
    "                # No safe moves found, game likely won or stuck\n",
    "                manager.is_game_over = True\n",
    "                break\n",
    "\n",
    "            # 4. Execute the move\n",
    "            success, game_over = manager.make_move(r, c, allow_mines)\n",
    "\n",
    "    # Return the results for metric calculation\n",
    "    return {\n",
    "        \"success\": manager.check_win_condition(),\n",
    "        \"moves_taken\": manager.moves_taken,\n",
    "        \"mines_triggered\": manager.mines_triggered\n",
    "    }\n",
    "\n",
    "\n",
    "# def get_nn_move_choice(mine_map, opened_board):\n",
    "#     # Mask opened cells with a HIGH value so they aren't picked as 'minimum'\n",
    "#     masked_map = mine_map.clone()\n",
    "#     masked_map[opened_board == 1] = 100.0\n",
    "#\n",
    "#     # Find the MINIMUM score (Lowest probability of being a mine)\n",
    "#     min_score = masked_map.min()\n",
    "#\n",
    "#     # Safety Check: If the 'best' move has a high chance of being a mine, don't move.\n",
    "#     # (e.g., if the lowest probability on the board is 0.5, you are guessing)\n",
    "#     # if min_score > 0.5: # Only move if < 5% chance of mine\n",
    "#     #     return None, None\n",
    "#\n",
    "#     # Get coordinates\n",
    "#     r_idx, c_idx = torch.where(masked_map == min_score)\n",
    "#\n",
    "#     # If there are ties, pick one randomly\n",
    "#     if len(r_idx) > 1:\n",
    "#         choice = torch.randint(0, len(r_idx), (1,)).item()\n",
    "#         return r_idx[choice].item(), c_idx[choice].item()\n",
    "#     else:\n",
    "#         return r_idx[0].item(), c_idx[0].item()\n",
    "\n",
    "def get_nn_move_choice(safety_map, opened_board):\n",
    "    \"\"\"\n",
    "    Finds the unopened cell with the highest predicted safety score.\n",
    "    \"\"\"\n",
    "    # Mask out opened cells by setting their scores to a very low value\n",
    "    masked_safety_map = safety_map.clone()\n",
    "    masked_safety_map[opened_board == 1] = -1e9\n",
    "\n",
    "    # Find the maximum score\n",
    "    max_score = masked_safety_map.max()\n",
    "\n",
    "    # Check if all cells are opened/invalid\n",
    "    if max_score < -1e8:\n",
    "        return None, None\n",
    "\n",
    "    # Find coordinates of the max score\n",
    "    r_idx, c_idx = torch.where(masked_safety_map == max_score)\n",
    "\n",
    "    # If there are ties, pick one randomly\n",
    "    if len(r_idx) > 1:\n",
    "        # Note: Added .cpu() here for robustness, assuming map is on GPU\n",
    "        r_idx = r_idx.cpu()\n",
    "        c_idx = c_idx.cpu()\n",
    "        choice = torch.randint(0, len(r_idx), (1,)).item()\n",
    "        return r_idx[choice].item(), c_idx[choice].item()\n",
    "    else:\n",
    "        # Note: Added .cpu() here for robustness, assuming map is on GPU\n",
    "        return r_idx[0].cpu().item(), c_idx[0].cpu().item()\n",
    "\n",
    "\n",
    "def calculate_bot_stats(model: nn.Module, num_of_games: int, think_time: int = -1):\n",
    "\n",
    "    bot_type = 'NN' if model else 'Logic Bot'\n",
    "\n",
    "    for mode in [True, False] if think_time == -1 else [False]:\n",
    "\n",
    "        print('\\n--------------------Real Game Rules----------------------' if not mode else '\\n--------------Mines can be detonated----------------')\n",
    "\n",
    "        for difficulty in ['easy', 'medium', 'hard']:\n",
    "\n",
    "            moves_per_game = []\n",
    "            games_won = 0\n",
    "            mines_set_off = []\n",
    "\n",
    "            for game_idx in range(num_of_games):\n",
    "\n",
    "                stats = start_nn_game(MSGameManager(), model, difficulty=difficulty, device=device, allow_mines=mode, thinking_time=think_time) if model \\\n",
    "                    else manager.start_bot_game(difficulty=difficulty, allow_mine=mode)\n",
    "\n",
    "                mines_set_off.append(stats['mines_triggered'])\n",
    "\n",
    "                if think_time == -1:\n",
    "                    moves_per_game.append(['moves_taken'])\n",
    "\n",
    "                if stats['success']:\n",
    "                    games_won += 1\n",
    "\n",
    "                    if think_time != -1:\n",
    "                        moves_per_game.append(stats[\"moves_taken\"])\n",
    "\n",
    "            win_rate = games_won / num_of_games * 100\n",
    "            avg_moves_per_won_game = np.average(moves_per_game) if win_rate > 0 else 0\n",
    "            sample_variance = np.var(moves_per_game) if win_rate > 0 else 0\n",
    "            sample_std = np.std(moves_per_game) if win_rate > 0 else 0\n",
    "\n",
    "            avg_mines_set_off = np.average(mines_set_off)\n",
    "\n",
    "            print(f'Using thinking time {int(think_time)}, on {difficulty}, the NN was able to move an average of {avg_moves_per_won_game:.2f} per match and won {win_rate:.2f}% matches' if think_time != -1 else '')\n",
    "\n",
    "            print(f'On {difficulty}: the {bot_type} won {win_rate:.2f}% of the games, averaged {avg_moves_per_won_game:.2f} moves per won game which had a variance of {sample_variance:.2f} and std deviation {sample_std:.2f}' if not mode and think_time == -1 else '')\n",
    "\n",
    "            print(f'On {difficulty} mode, the average number of mines that were set off was {avg_mines_set_off}' if mode else '')"
   ],
   "id": "f7b7e59ac57a1085",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T11:45:46.961322Z",
     "start_time": "2025-12-15T11:45:46.957414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MSDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X: torch.Tensor, y: torch.Tensor):\n",
    "\n",
    "        self.X = X.float()\n",
    "\n",
    "        # CRITICAL FIX: Only reshape Y if it is not scalar data (i.e., not Critic data).\n",
    "        # We need to preserve the shape of scalar Critic data (N,)\n",
    "        if y.ndim > 1:\n",
    "            self.y = y.float().view(y.size(0), -1) # Reshape the label to match model output (N x 484)\n",
    "        else:\n",
    "            # If y is already a 1D tensor of scalar values (Critic data), keep it as is.\n",
    "            self.y = y.float()\n",
    "\n",
    "        self.size = X.size(-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Retrieve the original sample\n",
    "        # X is (C, 22, 22). Y is either a scalar (Critic) or (484) vector (Actor).\n",
    "\n",
    "        # Use .clone().contiguous() to ensure data is independently owned\n",
    "        X = self.X[idx].clone().contiguous()\n",
    "        Y = self.y[idx].clone().contiguous()\n",
    "\n",
    "        return X, Y"
   ],
   "id": "4a4a09826abeef0f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T11:45:48.565573Z",
     "start_time": "2025-12-15T11:45:48.552921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MSSafeSquares(nn.Module):\n",
    "\n",
    "    def __init__(self, lin_dropout=0, cnn_dropout=0):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.BOARD_SIZE = 22\n",
    "\n",
    "        cnn_layer_1_size = 32\n",
    "        cnn_layer_2_size = 64\n",
    "        cnn_layer_3_size = 128\n",
    "        cnn_layer_4_size = 128\n",
    "\n",
    "        lin_layer_1_size = 2000\n",
    "        lin_layer_2_size = 1500\n",
    "        lin_layer_3_size = 1000\n",
    "        lin_layer_4_size = 500\n",
    "\n",
    "        self.CNN = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=cnn_layer_1_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(cnn_layer_1_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=cnn_dropout),\n",
    "\n",
    "\n",
    "            nn.Conv2d(in_channels=cnn_layer_1_size, out_channels=cnn_layer_2_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(cnn_layer_2_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=cnn_dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=cnn_layer_2_size, out_channels=cnn_layer_3_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(cnn_layer_3_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=cnn_dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=cnn_layer_3_size, out_channels=cnn_layer_4_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(cnn_layer_4_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=cnn_dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=cnn_layer_4_size, out_channels=1, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        logits = self.CNN(x)\n",
    "\n",
    "        return logits.view(x.size(0), -1)\n",
    "\n",
    "class CNN_Block(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.cnn_dropout = cnn_dropout\n",
    "\n",
    "        self.skip = nn.Sequential()\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_planes, out_channels=planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "\n",
    "            nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "        )\n",
    "\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            # Use a 1x1 convolution to match dimensions\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Pass the input through the block\n",
    "        logits = self.conv_block(x)\n",
    "\n",
    "        # Skip the original data\n",
    "        logits += self.skip(x)\n",
    "\n",
    "        # Activation Function\n",
    "        logits = F.relu(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "class MS_ResNet(nn.Module):\n",
    "    def __init__(self, num_blocks:list, linear_dropout=0.25, cnn_dropout=0.25):\n",
    "        super().__init__()\n",
    "\n",
    "        self.BOARD_SIZE = 22\n",
    "\n",
    "        # Initial size of the CNN layer that accepts the image\n",
    "        # Also used when creating stages of blocks self.stage_layer\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.image_input_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=self.in_planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.in_planes),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # range_beginning = 48\n",
    "        # range_end = 144\n",
    "        # range_step = range_beginning\n",
    "        #\n",
    "        # self.cnn_plane_range = range(range_beginning, range_end + 1, range_step)\n",
    "\n",
    "        # self.stages = nn.Sequential(\n",
    "        #     *[self.make_stage(planes, num_block, 1 if idx == 0 else 2)\n",
    "        #         for idx, (planes, num_block) in enumerate(zip(self.cnn_plane_range, num_blocks))]\n",
    "        # )\n",
    "\n",
    "        self.stages = nn.Sequential(\n",
    "            self.make_stage(64, num_blocks[0], 1),\n",
    "            self.make_stage(128, num_blocks[1], 2),\n",
    "            self.make_stage(192, num_blocks[2], 2),\n",
    "        )\n",
    "\n",
    "        self.lin_layer_1_size = 100\n",
    "        self.lin_layer_2_size = 500\n",
    "        self.lin_layer_3_size = 1000\n",
    "        self.lin_layer_4_size = 500\n",
    "\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(192, self.lin_layer_1_size),\n",
    "            nn.LayerNorm(self.lin_layer_1_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_1_size, self.lin_layer_2_size),\n",
    "            nn.LayerNorm(self.lin_layer_2_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_2_size, self.lin_layer_3_size),\n",
    "            nn.LayerNorm(self.lin_layer_3_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_3_size, self.lin_layer_4_size),\n",
    "            nn.LayerNorm(self.lin_layer_4_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_4_size, self.BOARD_SIZE * self.BOARD_SIZE)\n",
    "        )\n",
    "\n",
    "\n",
    "    def make_stage(self, planes, num_blocks, stride):\n",
    "\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        for stride in strides:\n",
    "            # Add ResBlock to list\n",
    "            layers.append(CNN_Block(self.in_planes, planes, stride))\n",
    "            # Reset the in planes to preserve in_channels of the next blocks\n",
    "            self.in_planes = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        logits = self.image_input_layer(x)\n",
    "\n",
    "        logits = self.stages(logits)\n",
    "\n",
    "        logits = F.avg_pool2d(logits, 6)\n",
    "\n",
    "        logits = logits.view(logits.size(0), -1)\n",
    "\n",
    "        logits = self.classifier(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "def masked_bce_loss(predictions, targets: torch.Tensor, pos_weight):\n",
    "    # Create mask FIRST\n",
    "    mask = (targets != -1.0).float()\n",
    "\n",
    "    # Replace -1 with 0 for valid BCE computation\n",
    "    targets_clean = targets.clone()\n",
    "    targets_clean[targets == -1.0] = 0.0\n",
    "\n",
    "    # Compute BCE loss\n",
    "    bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction='none')\n",
    "    loss = bce(predictions, targets_clean)\n",
    "\n",
    "    # Apply mask and average only over valid cells\n",
    "    masked_loss = (loss * mask).sum() / (mask.sum() + 1e-8)  # Avoid division by zero\n",
    "\n",
    "    return masked_loss"
   ],
   "id": "b62cb52c0252819b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:27:54.099713Z",
     "start_time": "2025-12-15T15:24:00.389377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_dataloader(X_dataset, Y_dataset, batch_size):\n",
    "    total_size = len(X_dataset)\n",
    "\n",
    "    train_size = int(0.8 * total_size)\n",
    "\n",
    "    label_size = total_size - train_size\n",
    "\n",
    "    X_train, X_test = torch.split(X_dataset, [train_size, label_size])\n",
    "    Y_train, Y_test = torch.split(Y_dataset, [train_size, label_size])\n",
    "\n",
    "    train_dataset = MSDataset(X_train, Y_train)\n",
    "    test_dataset = MSDataset(X_test, Y_test)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=5,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=5,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "manager = MSGameManager()\n",
    "\n",
    "X_1, Y_1 = manager.generate_frontier_training_data('easy', 1000, 70, 200)\n",
    "X_2, Y_2 = manager.generate_frontier_training_data('medium', 1000, 150, 200)\n",
    "X_3, Y_3 = manager.generate_frontier_training_data('hard', 1000, 200, 300)\n",
    "\n",
    "X, Y = torch.cat((X_1, X_2, X_3), dim=0), torch.cat((Y_1, Y_2, Y_3))\n",
    "\n",
    "MS_train_loader_easy, MS_test_loader_easy = get_dataloader(X, Y, 64)"
   ],
   "id": "2d1087cbe2234832",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Frontier-Constrained Data (easy)...\n",
      "Generated 100 games. Total samples: 7270\n",
      "Generated 200 games. Total samples: 14796\n",
      "Generated 300 games. Total samples: 22320\n",
      "Generated 400 games. Total samples: 29697\n",
      "Generated 500 games. Total samples: 37195\n",
      "Generated 600 games. Total samples: 44615\n",
      "Generated 700 games. Total samples: 52083\n",
      "Generated 800 games. Total samples: 59480\n",
      "Generated 900 games. Total samples: 66660\n",
      "Generated 1000 games. Total samples: 74305\n",
      "Generating Frontier-Constrained Data (medium)...\n",
      "Generated 100 games. Total samples: 15940\n",
      "Generated 200 games. Total samples: 31489\n",
      "Generated 300 games. Total samples: 47479\n",
      "Generated 400 games. Total samples: 63270\n",
      "Generated 500 games. Total samples: 78991\n",
      "Generated 600 games. Total samples: 94635\n",
      "Generated 700 games. Total samples: 110355\n",
      "Generated 800 games. Total samples: 125720\n",
      "Generated 900 games. Total samples: 141392\n",
      "Generated 1000 games. Total samples: 157203\n",
      "Generating Frontier-Constrained Data (hard)...\n",
      "Generated 100 games. Total samples: 20645\n",
      "Generated 200 games. Total samples: 41376\n",
      "Generated 300 games. Total samples: 62034\n",
      "Generated 400 games. Total samples: 82915\n",
      "Generated 500 games. Total samples: 103645\n",
      "Generated 600 games. Total samples: 124656\n",
      "Generated 700 games. Total samples: 145452\n",
      "Generated 800 games. Total samples: 166128\n",
      "Generated 900 games. Total samples: 186814\n",
      "Generated 1000 games. Total samples: 207478\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T12:15:40.103903Z",
     "start_time": "2025-12-15T12:15:40.096049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def training_loop(train_loader, test_loader, model: nn.Module, hp: dict):\n",
    "\n",
    "    epoch_over_training = []\n",
    "    epoch_over_testing = []\n",
    "\n",
    "    # Hyperparameter setup\n",
    "    epochs = hp['epochs']\n",
    "    learning_rate = hp['learning_rate']\n",
    "    decay_rate = hp['decay_rate']\n",
    "\n",
    "    c_dropout = hp['cnn_dropout']\n",
    "    f_dropout = hp['linear_dropout']\n",
    "\n",
    "    print('######## Beginning training for MS Safe Square Predictor ##########')\n",
    "\n",
    "    pos_weight_tensor = torch.tensor(hp['pos_weight'], device=device)\n",
    "\n",
    "    loss_function = masked_bce_loss\n",
    "    optimizer = optim.AdamW(model.parameters(),\n",
    "                           lr=learning_rate,\n",
    "                           weight_decay=decay_rate\n",
    "                           )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "\n",
    "    # Have references to variables outside of the epoch loop\n",
    "\n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "\n",
    "    # Epoch Loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "        avg_training_loss = 0\n",
    "        avg_testing_loss = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for x, Y in tqdm(train_loader, desc='Training', unit=' batch'):\n",
    "            # Transfer images to GPU\n",
    "            x = x.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            # Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Send images to model\n",
    "            x_pred = model(x)\n",
    "\n",
    "            # Calc loss\n",
    "            loss = loss_function(x_pred, Y, pos_weight_tensor)\n",
    "\n",
    "            # Calc gradient and update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                avg_training_loss += loss.item()\n",
    "\n",
    "        # Switch to eval mode\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, Y in tqdm(test_loader, desc='Testing', unit=' batches'):\n",
    "                # Move the images to the GPU\n",
    "                x = x.to(device)\n",
    "                Y = Y.to(device)\n",
    "\n",
    "                # Get logits and sum up total loss\n",
    "                x_pred = model(x)\n",
    "                avg_testing_loss += loss_function(x_pred, Y, pos_weight_tensor).item()\n",
    "\n",
    "        # Get training loss\n",
    "        avg_training_loss /= len(train_loader)\n",
    "\n",
    "         # Get testing loss\n",
    "        avg_testing_loss /= len(test_loader)\n",
    "\n",
    "        scheduler.step(avg_testing_loss)\n",
    "\n",
    "        # Switch model back to training mode\n",
    "        model.train()\n",
    "\n",
    "        epoch_over_training.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"training_loss\": avg_training_loss\n",
    "            })\n",
    "\n",
    "        epoch_over_testing.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"testing_loss\": avg_testing_loss\n",
    "            })\n",
    "\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "        print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "        print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n",
    "\n",
    "    return model, epoch_over_training, epoch_over_testing"
   ],
   "id": "865f3b3eef788e21",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T12:18:12.140881Z",
     "start_time": "2025-12-15T12:15:40.148782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperparameters = {\n",
    "    'epochs': 20,\n",
    "    'learning_rate': 1e-4,\n",
    "    'decay_rate': 1e-3,\n",
    "    'cnn_dropout': 0.3,\n",
    "    'linear_dropout': 0.6,\n",
    "    'pos_weight': 15\n",
    "}\n",
    "\n",
    "model_easy = MSSafeSquares(#[3,3,3],\n",
    "                       hyperparameters['linear_dropout'],\n",
    "                       hyperparameters['cnn_dropout']).to(device)\n",
    "\n",
    "model_easy, train, test= training_loop(train_loader=MS_train_loader_easy, test_loader=MS_test_loader_easy, hp=hyperparameters, model=model_easy)"
   ],
   "id": "8bb7304cd495c694",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Beginning training for MS Safe Square Predictor ##########\n",
      "----- Epoch: 1/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 291.82 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 550.15 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.9420\n",
      "\n",
      "   -> Testing Loss:  0.6995\n",
      "\n",
      "----- Epoch: 2/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 293.85 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 562.76 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.5514\n",
      "\n",
      "   -> Testing Loss:  0.5975\n",
      "\n",
      "----- Epoch: 3/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 294.71 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 540.66 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.4818\n",
      "\n",
      "   -> Testing Loss:  0.5480\n",
      "\n",
      "----- Epoch: 4/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 293.37 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 543.98 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.4472\n",
      "\n",
      "   -> Testing Loss:  0.5361\n",
      "\n",
      "----- Epoch: 5/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 297.20 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 555.82 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.4258\n",
      "\n",
      "   -> Testing Loss:  0.5167\n",
      "\n",
      "----- Epoch: 6/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 298.35 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 546.59 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.4102\n",
      "\n",
      "   -> Testing Loss:  0.5064\n",
      "\n",
      "----- Epoch: 7/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 297.01 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 544.99 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3986\n",
      "\n",
      "   -> Testing Loss:  0.4938\n",
      "\n",
      "----- Epoch: 8/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 298.04 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 551.13 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3895\n",
      "\n",
      "   -> Testing Loss:  0.4844\n",
      "\n",
      "----- Epoch: 9/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 299.09 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 553.86 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3825\n",
      "\n",
      "   -> Testing Loss:  0.4871\n",
      "\n",
      "----- Epoch: 10/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 294.51 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 562.01 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3758\n",
      "\n",
      "   -> Testing Loss:  0.4767\n",
      "\n",
      "----- Epoch: 11/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 298.47 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 547.11 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3712\n",
      "\n",
      "   -> Testing Loss:  0.4734\n",
      "\n",
      "----- Epoch: 12/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 300.08 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 547.83 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3665\n",
      "\n",
      "   -> Testing Loss:  0.4720\n",
      "\n",
      "----- Epoch: 13/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 300.01 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 548.29 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3624\n",
      "\n",
      "   -> Testing Loss:  0.4707\n",
      "\n",
      "----- Epoch: 14/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 298.15 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 547.66 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3587\n",
      "\n",
      "   -> Testing Loss:  0.4667\n",
      "\n",
      "----- Epoch: 15/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 297.51 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 544.20 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3556\n",
      "\n",
      "   -> Testing Loss:  0.4674\n",
      "\n",
      "----- Epoch: 16/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 297.17 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 565.74 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3528\n",
      "\n",
      "   -> Testing Loss:  0.4656\n",
      "\n",
      "----- Epoch: 17/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 301.62 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 562.32 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3505\n",
      "\n",
      "   -> Testing Loss:  0.4618\n",
      "\n",
      "----- Epoch: 18/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 301.35 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 552.51 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3480\n",
      "\n",
      "   -> Testing Loss:  0.4626\n",
      "\n",
      "----- Epoch: 19/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 301.78 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 544.57 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3463\n",
      "\n",
      "   -> Testing Loss:  0.4603\n",
      "\n",
      "----- Epoch: 20/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1992/1992 [00:06<00:00, 300.40 batch/s]\n",
      "Testing: 100%|██████████| 498/498 [00:00<00:00, 558.50 batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3439\n",
      "\n",
      "   -> Testing Loss:  0.4590\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T12:19:27.391158Z",
     "start_time": "2025-12-15T12:18:12.160904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "calculate_bot_stats(model_easy, 100)\n",
    "# calculate_bot_stats(None, 100)"
   ],
   "id": "5a8932b07054dcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------Mines can be detonated----------------\n",
      "\n",
      "On easy mode, the average number of mines that were set off was 5.67\n",
      "\n",
      "On medium mode, the average number of mines that were set off was 13.84\n",
      "\n",
      "On hard mode, the average number of mines that were set off was 30.92\n",
      "\n",
      "--------------------Real Game Rules----------------------\n",
      "On easy: the NN won 87.00% of the games, averaged 78.57 moves per won game which had a variance of 147.72 and std deviation 12.15\n",
      "\n",
      "On medium: the NN won 50.00% of the games, averaged 165.36 moves per won game which had a variance of 338.15 and std deviation 18.39\n",
      "\n",
      "On hard: the NN won 13.00% of the games, averaged 210.15 moves per won game which had a variance of 272.28 and std deviation 16.50\n",
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4c0b3bbc355f182f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Critic(nn.Module):\n",
    "\n",
    "    def __init__(self, linear_dropout=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.BOARD_SIZE = 22\n",
    "\n",
    "        cnn_layer_1_size = 32\n",
    "        cnn_layer_2_size = 32\n",
    "        cnn_layer_3_size = 64\n",
    "        cnn_layer_4_size = 64\n",
    "\n",
    "        self.CNN = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=5, out_channels=cnn_layer_1_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_1_size),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=cnn_layer_1_size, out_channels=cnn_layer_2_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_2_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=cnn_layer_2_size, out_channels=cnn_layer_3_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_3_size),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=cnn_layer_3_size, out_channels=cnn_layer_4_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_4_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        total_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, 5, self.BOARD_SIZE, self.BOARD_SIZE)\n",
    "\n",
    "            test_input.to(device)\n",
    "\n",
    "            features = self.CNN(test_input)\n",
    "\n",
    "            total_count = features.view(1, -1).size(1)\n",
    "\n",
    "        lin_layer_1_size = 2000\n",
    "        lin_layer_2_size = 2000\n",
    "        lin_layer_3_size = 1500\n",
    "        lin_layer_4_size = 500\n",
    "\n",
    "\n",
    "        self.Classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=total_count, out_features=lin_layer_1_size),\n",
    "            nn.BatchNorm1d(num_features=lin_layer_1_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=linear_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_1_size, out_features=lin_layer_2_size),\n",
    "            nn.BatchNorm1d(num_features=lin_layer_2_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=linear_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_2_size, out_features=lin_layer_3_size),\n",
    "            nn.BatchNorm1d(num_features=lin_layer_3_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=linear_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_3_size, out_features=lin_layer_4_size),\n",
    "            nn.BatchNorm1d(num_features=lin_layer_4_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=linear_dropout),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(in_features=lin_layer_4_size, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        logits = self.CNN(x)\n",
    "        logits = self.Classifier(logits)\n",
    "\n",
    "        logits = self.output_layer(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "class Actor(nn.Module):\n",
    "\n",
    "    def __init__(self, linear_dropout=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.BOARD_SIZE = 22\n",
    "\n",
    "        cnn_layer_1_size = 32\n",
    "        cnn_layer_2_size = 32\n",
    "        cnn_layer_3_size = 64\n",
    "        cnn_layer_4_size = 64\n",
    "\n",
    "        self.CNN = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=cnn_layer_1_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_1_size),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=cnn_layer_1_size, out_channels=cnn_layer_2_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_2_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=cnn_layer_2_size, out_channels=cnn_layer_3_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_3_size),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=cnn_layer_3_size, out_channels=cnn_layer_4_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_4_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        total_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, 4, self.BOARD_SIZE, self.BOARD_SIZE)\n",
    "\n",
    "            test_input.to(device)\n",
    "\n",
    "            features = self.CNN(test_input)\n",
    "\n",
    "            total_count = features.view(1, -1).size(1)\n",
    "\n",
    "        lin_layer_1_size = 2000\n",
    "        lin_layer_2_size = 2000\n",
    "        lin_layer_3_size = 1500\n",
    "        lin_layer_4_size = 500\n",
    "\n",
    "\n",
    "        self.Classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=total_count, out_features=lin_layer_1_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=linear_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_1_size, out_features=lin_layer_2_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=linear_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_2_size, out_features=lin_layer_3_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=linear_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_3_size, out_features=lin_layer_4_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=linear_dropout),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(in_features=lin_layer_4_size, out_features=self.BOARD_SIZE * self.BOARD_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        logits = self.CNN(x)\n",
    "        logits = self.Classifier(logits)\n",
    "\n",
    "        logits = self.output_layer(logits)\n",
    "\n",
    "        return logits\n"
   ],
   "id": "b2ca113c7a099819",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hp_a = {\n",
    "    'epochs': 5,\n",
    "    'learning_rate': 1e-2,\n",
    "    'decay_rate': 1e-3,\n",
    "    'cnn_dropout': 0.0,\n",
    "    'linear_dropout': 0.25\n",
    "}\n",
    "\n",
    "hp_c = {\n",
    "    'epochs': 5,\n",
    "    'learning_rate': 1e-4,\n",
    "    'decay_rate': 1e-3,\n",
    "    'cnn_dropout': 0.0,\n",
    "    'linear_dropout': 0.25\n",
    "}\n",
    "\n",
    "manager = MSGameManager()\n",
    "\n",
    "critic, actor = manager.critic_and_actor_training_loop(hp_a=hp_a, hp_c=hp_c, num_of_games=500)"
   ],
   "id": "75062e517944335d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:27:54.118214Z",
     "start_time": "2025-12-15T15:27:54.111506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MSThinker(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0):\n",
    "        super().__init__()\n",
    "        self.BOARD_SIZE = 22\n",
    "\n",
    "        cnn_layer_size = 64\n",
    "\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=cnn_layer_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "        )\n",
    "\n",
    "        self.RNN_Like_Block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=cnn_layer_size, out_channels=cnn_layer_size, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(in_channels=cnn_layer_size, out_channels=cnn_layer_size, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_size),\n",
    "        )\n",
    "\n",
    "        cnn_layer_1_size = 64\n",
    "        cnn_layer_2_size = 128\n",
    "        cnn_layer_3_size = 256\n",
    "\n",
    "        self.CNN = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=cnn_layer_size, out_channels=cnn_layer_1_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_1_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=cnn_layer_1_size, out_channels=cnn_layer_2_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_2_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=cnn_layer_2_size, out_channels=cnn_layer_3_size, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=cnn_layer_3_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=cnn_layer_3_size, out_channels=1, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, thinking_time):\n",
    "        logits_initial = self.input_layer(x)\n",
    "\n",
    "        # RNN Loop\n",
    "        for _ in range(thinking_time):\n",
    "            logits_initial_clone = logits_initial.clone()\n",
    "\n",
    "            logits_initial = logits_initial + self.RNN_Like_Block(logits_initial_clone)\n",
    "\n",
    "            logits_initial = F.relu(logits_initial)\n",
    "\n",
    "        logits = self.CNN(logits_initial)\n",
    "\n",
    "        logits = self.output_layer(logits)\n",
    "\n",
    "        return logits.view(x.size(0), -1)"
   ],
   "id": "4b50a0ae781c29e",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:27:54.170225Z",
     "start_time": "2025-12-15T15:27:54.161662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def training_loop_thinker(train_loader, test_loader, model: nn.Module, min_think, max_think, hp: dict):\n",
    "\n",
    "    epoch_over_training = []\n",
    "    epoch_over_testing = []\n",
    "\n",
    "    # Hyperparameter setup\n",
    "    epochs = hp['epochs']\n",
    "    learning_rate = hp['learning_rate']\n",
    "    decay_rate = hp['decay_rate']\n",
    "\n",
    "    print('######## Beginning training for MS Safe Square Predictor with Thinking ##########')\n",
    "\n",
    "    pos_weight_tensor = torch.tensor(hp['pos_weight'], device=device)\n",
    "\n",
    "    loss_function = masked_bce_loss\n",
    "    optimizer = optim.AdamW(model.parameters(),\n",
    "                           lr=learning_rate,\n",
    "                           weight_decay=decay_rate\n",
    "                           )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "\n",
    "    # Have references to variables outside of the epoch loop\n",
    "\n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    think_time = 0\n",
    "\n",
    "\n",
    "    # Epoch Loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "        avg_training_loss = 0\n",
    "        avg_testing_loss = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for x, Y in tqdm(train_loader, desc='Training', unit=' batch'):\n",
    "            # Transfer images to GPU\n",
    "            x = x.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            # Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                thinking_time = random.randint(min_think, max_think)\n",
    "\n",
    "            # Send images to model\n",
    "            x_pred = model(x, thinking_time)\n",
    "\n",
    "            # Calc loss\n",
    "            loss = loss_function(x_pred, Y, pos_weight_tensor)\n",
    "\n",
    "            # Calc gradient and update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                avg_training_loss += loss.item()\n",
    "\n",
    "        # Switch to eval mode\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, Y in tqdm(test_loader, desc='Testing', unit=' batches'):\n",
    "                # Move the images to the GPU\n",
    "                x = x.to(device)\n",
    "                Y = Y.to(device)\n",
    "\n",
    "                thinking_time = random.randint(min_think, max_think)\n",
    "\n",
    "                # Get logits and sum up total loss\n",
    "                x_pred = model(x, thinking_time)\n",
    "                avg_testing_loss += loss_function(x_pred, Y, pos_weight_tensor).item()\n",
    "\n",
    "        # Get training loss\n",
    "        avg_training_loss /= len(train_loader)\n",
    "\n",
    "         # Get testing loss\n",
    "        avg_testing_loss /= len(test_loader)\n",
    "\n",
    "        scheduler.step(avg_testing_loss)\n",
    "\n",
    "        # Switch model back to training mode\n",
    "        model.train()\n",
    "\n",
    "        epoch_over_training.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"training_loss\": avg_training_loss\n",
    "            })\n",
    "\n",
    "        epoch_over_testing.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"testing_loss\": avg_testing_loss\n",
    "            })\n",
    "\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "        print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "        print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n",
    "\n",
    "    return model, epoch_over_training, epoch_over_testing"
   ],
   "id": "7712dd2a88882fa1",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:45:17.291826Z",
     "start_time": "2025-12-15T15:27:54.211398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperparameters = {\n",
    "    'epochs': 20,\n",
    "    'learning_rate': 1e-5,\n",
    "    'decay_rate': 1e-3,\n",
    "    'cnn_dropout': 0.6,\n",
    "    'pos_weight': 15\n",
    "}\n",
    "\n",
    "model_thinker = MSThinker(hyperparameters['cnn_dropout']).to(device)\n",
    "\n",
    "\n",
    "model_thinker, train, test = training_loop_thinker(train_loader=MS_train_loader_easy, test_loader=MS_test_loader_easy, hp=hyperparameters, model=model_thinker, min_think=5, max_think=5)"
   ],
   "id": "681174f2f0ea7f6c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Beginning training for MS Safe Square Predictor with Thinking ##########\n",
      "----- Epoch: 1/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:49<00:00, 111.01 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 334.40 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.3543\n",
      "\n",
      "   -> Testing Loss:  1.2259\n",
      "\n",
      "----- Epoch: 2/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:49<00:00, 110.92 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 318.47 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.8956\n",
      "\n",
      "   -> Testing Loss:  0.7846\n",
      "\n",
      "----- Epoch: 3/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:47<00:00, 115.06 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 330.54 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.7026\n",
      "\n",
      "   -> Testing Loss:  0.6254\n",
      "\n",
      "----- Epoch: 4/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:47<00:00, 114.91 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 334.20 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.5830\n",
      "\n",
      "   -> Testing Loss:  0.5816\n",
      "\n",
      "----- Epoch: 5/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:47<00:00, 114.85 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 335.86 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.4998\n",
      "\n",
      "   -> Testing Loss:  0.5188\n",
      "\n",
      "----- Epoch: 6/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:48<00:00, 114.19 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 332.00 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.4360\n",
      "\n",
      "   -> Testing Loss:  0.5112\n",
      "\n",
      "----- Epoch: 7/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:47<00:00, 115.15 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 337.69 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3867\n",
      "\n",
      "   -> Testing Loss:  0.4810\n",
      "\n",
      "----- Epoch: 8/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:48<00:00, 114.12 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 338.54 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3511\n",
      "\n",
      "   -> Testing Loss:  0.4686\n",
      "\n",
      "----- Epoch: 9/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:48<00:00, 114.26 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 331.94 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3256\n",
      "\n",
      "   -> Testing Loss:  0.4484\n",
      "\n",
      "----- Epoch: 10/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:47<00:00, 114.64 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 339.10 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.3066\n",
      "\n",
      "   -> Testing Loss:  0.4444\n",
      "\n",
      "----- Epoch: 11/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:47<00:00, 114.36 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 335.54 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.2922\n",
      "\n",
      "   -> Testing Loss:  0.4373\n",
      "\n",
      "----- Epoch: 12/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:48<00:00, 114.21 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 335.84 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.2807\n",
      "\n",
      "   -> Testing Loss:  0.4239\n",
      "\n",
      "----- Epoch: 13/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:47<00:00, 114.51 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 330.71 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.2714\n",
      "\n",
      "   -> Testing Loss:  0.4086\n",
      "\n",
      "----- Epoch: 14/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:47<00:00, 114.41 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 333.64 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.2640\n",
      "\n",
      "   -> Testing Loss:  0.4103\n",
      "\n",
      "----- Epoch: 15/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:47<00:00, 114.44 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 335.99 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.2577\n",
      "\n",
      "   -> Testing Loss:  0.4144\n",
      "\n",
      "----- Epoch: 16/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:48<00:00, 113.51 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 332.09 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.2519\n",
      "\n",
      "   -> Testing Loss:  0.4067\n",
      "\n",
      "----- Epoch: 17/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:48<00:00, 114.04 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 337.79 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.2470\n",
      "\n",
      "   -> Testing Loss:  0.3996\n",
      "\n",
      "----- Epoch: 18/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:47<00:00, 115.33 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 335.83 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.2429\n",
      "\n",
      "   -> Testing Loss:  0.4075\n",
      "\n",
      "----- Epoch: 19/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:47<00:00, 115.65 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 336.01 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.2392\n",
      "\n",
      "   -> Testing Loss:  0.3988\n",
      "\n",
      "----- Epoch: 20/20 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5488/5488 [00:47<00:00, 115.40 batch/s]\n",
      "Testing: 100%|██████████| 1372/1372 [00:04<00:00, 335.47 batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.2355\n",
      "\n",
      "   -> Testing Loss:  0.3956\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T16:03:34.198195Z",
     "start_time": "2025-12-15T16:03:20.786745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_bot_stats_thinker(model, num_of_games, think_time):\n",
    "\n",
    "    for think in range(1, think_time + 1):\n",
    "        print(f\"~~~~~~~~~~~~ Thinking with {think} ~~~~~~~~~~~~~~~\")\n",
    "\n",
    "        calculate_bot_stats(model, num_of_games, think)\n",
    "\n",
    "\n",
    "calculate_bot_stats_thinker(model_thinker, 100, 5)"
   ],
   "id": "6601c2beb9a32923",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~ Thinking with 1 ~~~~~~~~~~~~~~~\n",
      "\n",
      "--------------------Real Game Rules----------------------\n",
      "Using thinking time 1, on easy, the NN was able to move an average of 67.14 per match and won 7.00% matches\n",
      "\n",
      "\n",
      "Using thinking time 1, on medium, the NN was able to move an average of 0.00 per match and won 0.00% matches\n",
      "\n",
      "\n",
      "Using thinking time 1, on hard, the NN was able to move an average of 0.00 per match and won 0.00% matches\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~ Thinking with 2 ~~~~~~~~~~~~~~~\n",
      "\n",
      "--------------------Real Game Rules----------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[94], line 9\u001B[0m\n\u001B[1;32m      4\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m~~~~~~~~~~~~ Thinking with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mthink\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ~~~~~~~~~~~~~~~\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m         calculate_bot_stats(model, num_of_games, think)\n\u001B[0;32m----> 9\u001B[0m \u001B[43mcalculate_bot_stats_thinker\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_thinker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[94], line 6\u001B[0m, in \u001B[0;36mcalculate_bot_stats_thinker\u001B[0;34m(model, num_of_games, think_time)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m think \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, think_time \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m~~~~~~~~~~~~ Thinking with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mthink\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ~~~~~~~~~~~~~~~\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m     \u001B[43mcalculate_bot_stats\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_of_games\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthink\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[92], line 115\u001B[0m, in \u001B[0;36mcalculate_bot_stats\u001B[0;34m(model, num_of_games, think_time)\u001B[0m\n\u001B[1;32m    111\u001B[0m mines_set_off \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m game_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_of_games):\n\u001B[0;32m--> 115\u001B[0m     stats \u001B[38;5;241m=\u001B[39m \u001B[43mstart_nn_game\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMSGameManager\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdifficulty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifficulty\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_mines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthinking_time\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthink_time\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m model \\\n\u001B[1;32m    116\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m manager\u001B[38;5;241m.\u001B[39mstart_bot_game(difficulty\u001B[38;5;241m=\u001B[39mdifficulty, allow_mine\u001B[38;5;241m=\u001B[39mmode)\n\u001B[1;32m    118\u001B[0m     mines_set_off\u001B[38;5;241m.\u001B[39mappend(stats[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmines_triggered\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m think_time \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "Cell \u001B[0;32mIn[92], line 36\u001B[0m, in \u001B[0;36mstart_nn_game\u001B[0;34m(manager, model, difficulty, device, allow_mines, thinking_time)\u001B[0m\n\u001B[1;32m     33\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m     35\u001B[0m         \u001B[38;5;66;03m# 4. Execute the move\u001B[39;00m\n\u001B[0;32m---> 36\u001B[0m         success, game_over \u001B[38;5;241m=\u001B[39m \u001B[43mmanager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_move\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_mines\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# Return the results for metric calculation\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msuccess\u001B[39m\u001B[38;5;124m\"\u001B[39m: manager\u001B[38;5;241m.\u001B[39mcheck_win_condition(),\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmoves_taken\u001B[39m\u001B[38;5;124m\"\u001B[39m: manager\u001B[38;5;241m.\u001B[39mmoves_taken,\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmines_triggered\u001B[39m\u001B[38;5;124m\"\u001B[39m: manager\u001B[38;5;241m.\u001B[39mmines_triggered\n\u001B[1;32m     43\u001B[0m }\n",
      "Cell \u001B[0;32mIn[4], line 261\u001B[0m, in \u001B[0;36mMSGameManager.make_move\u001B[0;34m(self, r, c, allow_mine)\u001B[0m\n\u001B[1;32m    257\u001B[0m      \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflagged_board[r, c] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;66;03m# Unflag before opening\u001B[39;00m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmoves_taken \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;66;03m# Increment step counter\u001B[39;00m\n\u001B[0;32m--> 261\u001B[0m move_successful \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen_cell\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_mine\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# Check for win condition after a successful move\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m move_successful \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_win_condition():\n",
      "Cell \u001B[0;32mIn[4], line 195\u001B[0m, in \u001B[0;36mMSGameManager.open_cell\u001B[0;34m(self, r, c, allow_mine)\u001B[0m\n\u001B[1;32m    192\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m    194\u001B[0m visited\u001B[38;5;241m.\u001B[39madd(neighbor_coord)\n\u001B[0;32m--> 195\u001B[0m true_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmine_board\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnc\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m true_value \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;66;03m# Continue the cascade (reveal blank, add to queue)\u001B[39;00m\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mplayer_board[nr, nc] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m9\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cd9fe79888e5520c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

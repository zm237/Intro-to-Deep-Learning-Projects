{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Homework 4",
   "id": "4bc89c27d1be5595"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Objective: Get the lowest loss on a CIFAR10 Classifier\n",
    "\n",
    "After taking the entirety of the Deep Learning course, I have had the opportunity to learn various of techniques to solve different problems using classical deep learning techniques. However, for this homework, I decided that the two most important things that will be helpful for me to get a lower loss on the CIFAR image classification task are Batch/Layer Normalization and ResNets. As such, I first decided to focus on making the best model I got in homework 2 better by introducing normalization and also trying different model architectures to lower the loss. Finally, I will showcase the ResNet I made to see if it can beat the optimized model from homework 2."
   ],
   "id": "740e12cb939ceca8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Route 1: Optimization of HW2 Model\n",
    "\n",
    "#### Initial Model Architecture\n",
    "\n",
    "To start, I decided to take a look at the model from the last homework that worked best for this task. Before doing anything, this model had 4 CNN layers with channels (30 -> 64 -> 128 -> 256), kernel sizes (5x5 -> 3x3 -> 3x3 -> 3x3), and a constant stride of 1, a Max Pooling layer with kernel 2x2 and stride 2, and finally a classification head with linear layers (1000 -> 500 -> 250 -> 10). Of course, dropout was placed between every layer when possible. Looking at the model, I saw that it was not currently using any form of normalization, so I thought to add batch normalization between the CNN layers and layer normalization between the linear layers. Furthermore, I decided to do this not just because it was a new tool but also since I saw that it was effective when used for the models in Homework 3.\n",
    "\n",
    "#### Model Training\n",
    "\n",
    "For the first training loop, I decided to use the hyperparameters that were kept for the original model in Homework 2 since the new architecture is very similar to the old architecture. For reference the hyperparameters used to train the new model are...\n",
    "\n",
    "---\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 5e-4\n",
    "\n",
    "decay_rate = 4e-4\n",
    "\n",
    "c_dropout = 0.30\n",
    "\n",
    "f_dropout = 0.30\n",
    "\n",
    "---\n",
    "\n",
    "After training the model, I noticed large improvements in training and testing loss being 0.6250 and 0.6327 at the 20th epoch which is better than the ~0.80 training and testing loss for the architecture from homework 2. From here, I tried to tinker with learning rate by setting it to 1e-4 but the model not only took longer to get to an optimal training and testing loss, around the 35th epoch, but could only get a loss around ~0.64. Fiddling with the dropout was also not successful and would only make the model take longer to train but not get losses lower than ~0.70.\n",
    "\n",
    "#### Second Model Architecture(s)\n",
    "\n",
    "After exhausting all of my options for the first model I made, I decided to instead try and make the model more complex, I noticed that the CNN Layers would expand the number of channels in a reverse funnel, but I never thought to just try and keep the channels constant. Originally, I used a reverse funnel since I wanted the model to be able to get a few base features in the first layer and then use those to create more and more complex features in subseqeunt layers. However, if I tried keeping the same, I could achieve the same effect but instead of tying to just repeatetly getting more and more complex features, I would be building more and more complex features in a more controlled way. As such, I decided to keep the number of channels to 64 for all four CNN layers.\n",
    "\n",
    "So, so the architecture for this model is now...\n",
    "\n",
    "4x CNN layers (64 -> 64 -> 64 -> 64) with kernels 3x3 and stride 1 into a Max Pool of kernel 2x2 and stride 2 finally into a Linear Classifier (1000 -> 500 -> 250 -> 10).\n",
    "\n",
    "Also you might notice that this section is suffixed with \"Architecture(s).\" This is because I experimented with various constant sizes for the CNN Layers which will be explained in the next section\n",
    "\n",
    "#### Second Model Training\n",
    "\n",
    "Once again, I decided to keep the hyperparameters that were previously listed since they seem to be the most optimal for the current model. By the 62th epoch, the model was able to get a new training and testing loss of ~0.60 around the 60th epoch. Knowing that it would be best to keep the hyperparameters the same, I decided that the only way forward would be to just adjust the width of the CNN layers, so I decided to go from 64 channels per layer to 128 channels per layer which allowed me to get a lower training and testing loss of ~0.57. For my next change, I decided to go even further and try using a constant size of 256 for the CNN channels and got a testing and training loss ~0.50 at the 31th epoch. From this, we can see that increasing the channels in the CNN layers in this way allows the model to reach better and better losses for the most part, but of course, this comes at the cost of longer training times. For one final push, I tried increasing the channels to 512 but not only did it take a while to train the lowest loss it got was around ~0.54 at the 17th epoch.\n",
    "\n",
    "#### Results\n",
    "\n",
    "Refer to Figure 1 for the loss graph.\n",
    "\n",
    "---\n",
    "\n",
    "Final Accuracy: 82.89%\n",
    "\n",
    "Final Training Loss: ~0.50\n",
    "\n",
    "Final Testing Loss: ~0.50\n",
    "\n",
    "Best Model Architecture: 4x CNN Layers (256 -> 256 -> 256 -> 256) of kernels 3x3 and stride 1 into MaxPool Layer of kernel 2x2 and stride 2 into Linear Classifier with layers (1000 -> 500 -> 250 -> 100 -> 10)\n",
    "\n",
    "---\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "decay_rate = 4e-4\n",
    "\n",
    "c_dropout = 0.30\n",
    "\n",
    "f_dropout = 0.30"
   ],
   "id": "aeb0ff93c2edbdb1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Route 2: ResNet Classifier\n",
    "\n",
    "#### ResNet Design\n",
    "\n",
    "To start, I decided that I wanted to make ResNet blocks out of purely CNN layers. This is because the original ResNet paper which used a ResNet on image classification also used a similar architecture, so I wanted to see if making a NN like it would be benefitital. To start, I decided to define a CNN block with two CNN layers that keep constant planes (another terminology meaning channels) based on user specification. The block keeps the size of the out planes constant so that we can perform the math of adding the logits processed from the block back to the original input. In addition, there are batch normalization layers in between the CNN layers. For the final ResNet, I made it so that it can make stages with a number of blocks per stages as specified by user. For the first stage, the NN keeps the dimensionality of the image the same, however, subsequent stages will downsample the image. After all the stages, the output is given to a Linear Classifier with dropout layers.\n",
    "\n",
    "#### Initial Model Architecture\n",
    "\n",
    "In the beginning, I decided to make the NN start with three stages each with 3 blocks. Additionally, I decided to start the model with 32 planes since I wanted a baseline to see how well the model can perform. Lastly, the Linear Classifier was made of four layers of sizes (2000 -> 1500 -> 1000 -> 500) with a final classification layer of size 10 and had dropout.\n",
    "\n",
    "For this trial, it was mearly a test run to see where I stood and what could be improved.\n",
    "\n",
    "#### Initial Model Training\n",
    "\n",
    "To start, I decided to use the hyperparameters...\n",
    "\n",
    "---\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "decay_rate = 1e-4\n",
    "\n",
    "f_dropout = 0.5\n",
    "\n",
    "---\n",
    "\n",
    "I wanted to keep use a higher learning rate and dropout as a baseline to see where I needed to adjust. Though the weight decay is also higher, I chose this not as a baseline but rather as another measure to further combat any overfitting since the model is not using dropout in the CNN blocks or layer normalization in the Linear Classifier. After training, the model was able to get a training loss of ~0.45 and testing loss of ~0.58 at the 16th epoch. Afterwards, the model would continue to overtrain severally. Though I wasn't able to immediately beat the best loss of the model in first half of the homework, the model is close to it without immediate tuning. Speaking of tuning, I decided against tuning the hyperparameters for this model since I wanted to test how long I can make the NN and beat the best model.\n",
    "\n",
    "#### Second Model Architecture\n",
    "\n",
    "For the next model, I decided to increase the number of stages from 3 to 4 and test changing the time image downsampling occurs. Instead of downsampling after the first stage, this model downsamples after the second stage since I wanted to find the bottleneck where the model could no longer benefit from keeping constant planes. For instance, for a simple regression task using linear layers, there is a point where adding more and more layers does not help model perform any better. Lastly, I decided to keep the starting in planes to 16 since I wanted to be able to train the model efficiently and increased the width of the Linear Classifier to see if there would be any benefit.\n",
    "\n",
    "As such, the model architecture is now...\n",
    "\n",
    "4x Stages (3 blocks per stage), starting with 16 planes and subsequence planes having 16 more planes than the last and downsampling starting at the third stage, into a Linear Classifier with 4x layers (2500 -> 1500 -> 1000 -> 500) into final output layer\n",
    "\n",
    "#### Second Model Training\n",
    "\n",
    "Again, I kept the hyperparameters stated previously. After training, the model was able to get a training loss of ~0.50 and testing loss of ~0.58 at the 17th epoch, beating the last ResNet. Training past this epoch caused the testing loss to oscillate between ~0.57 and ~0.63 as the training loss kept on decreasing. I tried experimenting with layer normalization for the ResNet, however, using it over dropout caused the ResNet to struggle to get loss lower than 1.0 during training.\n",
    "\n",
    "#### Final Testing and ResNet Conclusions\n",
    "\n",
    "In my last exploratory attempt, I decided to see the effects of increasing the in planes of the model with the stages 3 and 4 and saw no visible improvements. For instance, I tried to start the in planes at 64 or 128 with each subsequent stage having double the last stage in terms of planes, however, they could never really pass the ~0.57 testing loss barrier and would be stuck oscillating after the 25th epoch.\n",
    "\n",
    "Though the Second Model Architecture was able to barely outperform the first ResNet model, I believe that it was simply due to chance rather than being a better architecture. In fact, since the first ResNet is actually smaller in terms of overall parameters, I would say that outperforms the second ResNet model.\n",
    "\n",
    "#### Best Results for ResNet\n",
    "\n",
    "Refer to Figure 2 for the loss graph.\n",
    "\n",
    "---\n",
    "\n",
    "Final Accuracy: 80.93%\n",
    "\n",
    "Final Training Loss: ~0.45\n",
    "\n",
    "Final Testing Loss: ~0.58\n",
    "\n",
    "Best Model Architecture: 3x Stages (3 blocks per stage), starting with 32 planes and subsequence planes having 32 more planes than the last and downsampling starting at the second stage, into a Linear Classifier with 5x layers (2000 -> 1500 -> 1000 -> 500 -> 10) into final output layer\n",
    "\n",
    "---\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "decay_rate = 5e-4\n",
    "\n",
    "linear_dropout = 0.55\n",
    "\n",
    "---\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "After my tests, I can conclude that the CIFAR10 classification task prefers NN's that are wider instead of longer which can be seen with the standard CNN outperforming the ResNet. I believe this is the case since the CIFAR10 dataset, though leagues more complex than the MNIST dataset, is not complex enough to require the extraction, finetuning, and filtering of those features over a long range. Instead, blowing up the number of features immediately and then finding more and more features as fast as possible seems to be a better option, as can be seen with the CNN model architecture.\n",
    "\n",
    "In conclusion, the CNN model from the first half of this homework is better suited for CIFAR10 Image Classification.\n"
   ],
   "id": "cdc64873417cfc7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Code Used",
   "id": "74ff6553b01177e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports and Data Setup",
   "id": "cb06c50697eeed22"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Grab the MNIST dataset\n",
    "training_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testing_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "tfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset_full_CIFAR10 = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=tfm)\n",
    "testset_full_CIFAR10  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=tfm)"
   ],
   "id": "fffd1952ab91cd32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verify that GPU is connected and available\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(torch.cuda.get_device_name(0))"
   ],
   "id": "62c84a2afc22de88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CNN Classifier",
   "id": "16b95ced2322772b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CIFAR10_Classifier(nn.Module):\n",
    "    def __init__(self, C_dropout, F_dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        conv2d_dropout = C_dropout\n",
    "\n",
    "        conv_layer_1 = 256\n",
    "        conv_layer_2 = 256\n",
    "\n",
    "        conv_layer_3 = 256\n",
    "        conv_layer_4 = 256\n",
    "\n",
    "        self.forward_funnel_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=conv_layer_1, kernel_size=3),   # Extract useful features from the beginning\n",
    "            nn.BatchNorm2d(num_features=conv_layer_1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=conv_layer_1, out_channels=conv_layer_2, kernel_size=3),  # Extract useful features from the learned features\n",
    "            nn.BatchNorm2d(num_features=conv_layer_2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                       # Reduce dimensionality\n",
    "        )\n",
    "\n",
    "        self.forward_funnel_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=conv_layer_2, out_channels=conv_layer_3, kernel_size=3),   # Extract useful features from the beginning\n",
    "            nn.BatchNorm2d(num_features=conv_layer_3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=conv_layer_3, out_channels=conv_layer_4, kernel_size=3),  # Extract useful features from the learned features\n",
    "            nn.BatchNorm2d(num_features=conv_layer_4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Compute the number of features after the input has passed the funnel\n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, 3, 32, 32)\n",
    "\n",
    "            test_input.to(device)\n",
    "\n",
    "            features = self.forward_funnel_1(test_input)\n",
    "            features = self.forward_funnel_2(features)\n",
    "\n",
    "            total_count = features.view(1, -1).size(1)\n",
    "\n",
    "        full_node_dropout = F_dropout\n",
    "\n",
    "\n",
    "        lin_layer_1_size = 1000\n",
    "        lin_layer_2_size = 500\n",
    "        lin_layer_3_size = 250\n",
    "\n",
    "        self.output_nodes = 100\n",
    "\n",
    "        self.classifer = nn.Sequential(\n",
    "            nn.Flatten(),                                           # Flatten the image from the funnel\n",
    "            nn.Linear(in_features=total_count, out_features=lin_layer_1_size),\n",
    "            nn.LayerNorm(lin_layer_1_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_1_size, out_features=lin_layer_2_size),\n",
    "            nn.LayerNorm(lin_layer_2_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_2_size, out_features=lin_layer_3_size),\n",
    "            nn.LayerNorm(lin_layer_3_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_3_size, out_features=self.output_nodes),\n",
    "            nn.LayerNorm(self.output_nodes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(in_features=self.output_nodes, out_features=10)\n",
    "\n",
    "    def partial_forward(self, x):\n",
    "        x = self.forward_funnel_1(x)\n",
    "        x = self.forward_funnel_2(x)\n",
    "        x = self.classifer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.partial_forward(x)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        return logits"
   ],
   "id": "9eda8e70dd5aafa0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Collection and CNN Model Training Loop",
   "id": "883c7f5a06989156"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "epoch_over_training_loss_CIFAR10 = []\n",
    "epoch_over_testing_loss_CIFAR10 = []"
   ],
   "id": "411db29028bfd083",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Hyperparameter setup\n",
    "epochs = 31\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "decay_rate = 4e-4\n",
    "\n",
    "c_dropout = 0.30\n",
    "f_dropout = 0.30\n",
    "\n",
    "print('######## Begining training for CIFAR10 classifier ##########')\n",
    "\n",
    "# Setup data loaders\n",
    "trainset_loader_CIFAR10 = data.DataLoader(trainset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=8,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "testset_loader_CIFAR10 = data.DataLoader(testset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   num_workers=8,\n",
    "                                   shuffle=False,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "model = CIFAR10_Classifier(c_dropout, f_dropout)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                       lr=learning_rate,\n",
    "                       weight_decay=decay_rate\n",
    "                       )\n",
    "\n",
    "# Have references to variables outside of the epoch loop\n",
    "avg_training_loss = 0\n",
    "avg_testing_loss = 0\n",
    "\n",
    "# Epoch Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for x, Y in tqdm(trainset_loader_CIFAR10, desc='Training', unit=' batch'):\n",
    "        # Transfer images to GPU\n",
    "        x = x.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Send images to model\n",
    "        x_pred = model(x)\n",
    "\n",
    "        # Calc loss\n",
    "        loss = loss_function(x_pred, Y)\n",
    "\n",
    "        # Calc gradient and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_training_loss += loss.item()\n",
    "\n",
    "    # Switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, Y in tqdm(testset_loader_CIFAR10, desc='Testing', unit=' batches'):\n",
    "            # Move the images to the GPU\n",
    "            x = x.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            # Get logits and sum up total loss\n",
    "            x_pred = model(x)\n",
    "            avg_testing_loss += loss_function(x_pred, Y).item()\n",
    "\n",
    "    # Get training loss\n",
    "    avg_training_loss /= len(trainset_loader_CIFAR10)\n",
    "\n",
    "     # Get testing loss\n",
    "    avg_testing_loss /= len(testset_loader_CIFAR10)\n",
    "\n",
    "    # Switch model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    epoch_over_training_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"training_loss\": avg_training_loss\n",
    "        })\n",
    "\n",
    "    epoch_over_testing_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"testing_loss\": avg_testing_loss\n",
    "        })\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "    print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n"
   ],
   "id": "ef78fbe91c4a187d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CNN Model Performance Data Collection",
   "id": "dec2f5a9e7befb3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "\n",
    "correct = total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in testset_loader_CIFAR10:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total += yb.numel()\n",
    "\n",
    "final_accuracy = float(correct / total)\n",
    "\n",
    "print(f\"Final Accuracy: {final_accuracy}\")\n",
    "\n",
    "\n",
    "train_loss = [d[\"training_loss\"] for d in epoch_over_training_loss_CIFAR10]\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "test_loss = [d[\"testing_loss\"] for d in epoch_over_testing_loss_CIFAR10]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_loss, label=\"Training Loss\")\n",
    "plt.plot(epochs, test_loss, label=\"Testing Loss\")\n",
    "\n",
    "plt.xlim(0.9, len(train_loss) + 0.1)\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"CIFAR10 CNN Classifer: Training and Testing Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "a652301194dd7d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ResNet Model",
   "id": "214ec59afce2d103"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CNN_Block(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.cnn_dropout = cnn_dropout\n",
    "\n",
    "        self.skip = nn.Sequential()\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_planes, out_channels=planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "\n",
    "            nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "        )\n",
    "\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            # Use a 1x1 convolution to match dimensions\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Pass the input through the block\n",
    "        logits = self.conv_block(x)\n",
    "\n",
    "        # Skip the original data\n",
    "        logits += self.skip(x)\n",
    "\n",
    "        # Activation Function\n",
    "        logits = F.relu(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "class CIFAR10_ResNet(nn.Module):\n",
    "    def __init__(self, num_blocks:list, num_classes=10, linear_dropout=0.25):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initial size of the CNN layer that accepts the image\n",
    "        # Also used when creating stages of blocks self.stage_layer\n",
    "        self.in_planes = 32\n",
    "\n",
    "        self.image_input_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.in_planes),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # range_beginning = 48\n",
    "        # range_end = 144\n",
    "        # range_step = range_beginning\n",
    "        #\n",
    "        # self.cnn_plane_range = range(range_beginning, range_end + 1, range_step)\n",
    "\n",
    "        # self.stages = nn.Sequential(\n",
    "        #     *[self.make_stage(planes, num_block, 1 if idx == 0 else 2)\n",
    "        #         for idx, (planes, num_block) in enumerate(zip(self.cnn_plane_range, num_blocks))]\n",
    "        # )\n",
    "\n",
    "        self.stages = nn.Sequential(\n",
    "            self.make_stage(32, num_blocks[0], 1),\n",
    "            self.make_stage(64, num_blocks[1], 2),\n",
    "            self.make_stage(96, num_blocks[2], 2),\n",
    "        )\n",
    "\n",
    "        self.lin_layer_1_size = 2000\n",
    "        self.lin_layer_2_size = 1500\n",
    "        self.lin_layer_3_size = 1000\n",
    "        self.lin_layer_4_size = 500\n",
    "\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(96, self.lin_layer_1_size),\n",
    "            # nn.LayerNorm(self.lin_layer_1_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_1_size, self.lin_layer_2_size),\n",
    "            # nn.LayerNorm(self.lin_layer_2_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_2_size, self.lin_layer_3_size),\n",
    "            # nn.LayerNorm(self.lin_layer_3_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_3_size, self.lin_layer_4_size),\n",
    "            nn.LayerNorm(self.lin_layer_4_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_4_size, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "    def make_stage(self, planes, num_blocks, stride):\n",
    "\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        for stride in strides:\n",
    "            # Add ResBlock to list\n",
    "            layers.append(CNN_Block(self.in_planes, planes, stride))\n",
    "            # Reset the in planes to preserve in_channels of the next blocks\n",
    "            self.in_planes = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        logits = self.image_input_layer(x)\n",
    "\n",
    "        logits = self.stages(logits)\n",
    "\n",
    "        logits = F.avg_pool2d(logits, 8)\n",
    "\n",
    "        logits = logits.view(logits.size(0), -1)\n",
    "\n",
    "        logits = self.classifier(logits)\n",
    "\n",
    "        return logits\n",
    "\n"
   ],
   "id": "fc4fe148e9a5bebf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Setup and ResNet Model Training Loop",
   "id": "986cfdb3b958e8c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "epoch_over_training_loss_CIFAR10 = []\n",
    "epoch_over_testing_loss_CIFAR10 = []\n",
    "\n",
    "# Hyperparameter setup\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "decay_rate = 5e-4\n",
    "\n",
    "f_dropout = 0.50\n",
    "\n",
    "print('######## Beginning training for CIFAR10 ResNet classifier ##########')\n",
    "\n",
    "# Setup data loaders\n",
    "trainset_loader_CIFAR10 = data.DataLoader(trainset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=8,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "testset_loader_CIFAR10 = data.DataLoader(testset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   num_workers=8,\n",
    "                                   shuffle=False,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "model = CIFAR10_ResNet(num_blocks=[3, 3, 3], num_classes=10, linear_dropout=f_dropout)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                       lr=learning_rate,\n",
    "                       weight_decay=decay_rate\n",
    "                       )\n",
    "\n",
    "# Have references to variables outside of the epoch loop\n",
    "avg_training_loss = 0\n",
    "avg_testing_loss = 0\n",
    "\n",
    "# Epoch Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for x, Y in tqdm(trainset_loader_CIFAR10, desc='Training', unit=' batch'):\n",
    "        # Transfer images to GPU\n",
    "        x = x.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Send images to model\n",
    "        x_pred = model(x)\n",
    "\n",
    "        # Calc loss\n",
    "        loss = loss_function(x_pred, Y)\n",
    "\n",
    "        # Calc gradient and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_training_loss += loss.item()\n",
    "\n",
    "    # Switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, Y in tqdm(testset_loader_CIFAR10, desc='Testing', unit=' batches'):\n",
    "            # Move the images to the GPU\n",
    "            x = x.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            # Get logits and sum up total loss\n",
    "            x_pred = model(x)\n",
    "            avg_testing_loss += loss_function(x_pred, Y).item()\n",
    "\n",
    "    # Get training loss\n",
    "    avg_training_loss /= len(trainset_loader_CIFAR10)\n",
    "\n",
    "     # Get testing loss\n",
    "    avg_testing_loss /= len(testset_loader_CIFAR10)\n",
    "\n",
    "    # Switch model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    epoch_over_training_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"training_loss\": avg_training_loss\n",
    "        })\n",
    "\n",
    "    epoch_over_testing_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"testing_loss\": avg_testing_loss\n",
    "        })\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "    print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n"
   ],
   "id": "f6c30184c0bec3a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ResNet Model Performance Data Collection",
   "id": "a15866fba5c2a6eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "\n",
    "correct = total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in testset_loader_CIFAR10:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total += yb.numel()\n",
    "\n",
    "final_accuracy = float(correct / total)\n",
    "\n",
    "print(f\"Final Accuracy: {final_accuracy}\")\n",
    "\n",
    "\n",
    "train_loss = [d[\"training_loss\"] for d in epoch_over_training_loss_CIFAR10]\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "test_loss = [d[\"testing_loss\"] for d in epoch_over_testing_loss_CIFAR10]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_loss, label=\"Training Loss\")\n",
    "plt.plot(epochs, test_loss, label=\"Testing Loss\")\n",
    "\n",
    "plt.xlim(0.9, len(train_loss) + 0.1)\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"CIFAR10 ResNet Classifer: Training and Testing Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "2fc4a8beb273497c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Homework 4",
   "id": "4bc89c27d1be5595"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Objective: Get the lowest loss on a CIFAR10 Classifier\n",
    "\n",
    "After taking the entirety of the Deep Learning course, I have had the opportunity to learn various of techniques to solve different problems using classical deep learning techniques. However, for this homework, I decided that the two most important things that will be helpful for me to get a lower loss on the CIFAR image classification task are Batch/Layer Normalization and ResNets. As such, I first decided to focus on making the best model I got in homework 2 better by introducing normalization and also trying different model architectures to lower the loss. Finally, I will showcase the ResNet I made to see if it can beat the optimized model from homework 2."
   ],
   "id": "740e12cb939ceca8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Route 1: Optimization of HW2 Model\n",
    "\n",
    "#### Initial Model Architecture\n",
    "\n",
    "To start, I decided to take a look at the model from the last homework that worked best for this task. Before doing anything, this model had 4 CNN layers with channels (30 -> 64 -> 128 -> 256), kernel sizes (5x5 -> 3x3 -> 3x3 -> 3x3), and a constant stride of 1, a Max Pooling layer with kernel 2x2 and stride 2, and finally a classification head with linear layers (1000 -> 500 -> 250 -> 10). Of course, dropout was placed between every layer when possible. Looking at the model, I saw that it was not currently using any form of normalization, so I thought to add batch normalization between the CNN layers and layer normalization between the linear layers. Furthermore, I decided to do this not just because it was a new tool but also since I saw that it was effective when used for the models in Homework 3.\n",
    "\n",
    "#### Model Training\n",
    "\n",
    "For the first training loop, I decided to use the hyperparameters that were kept for the original model in Homework 2 since the new architecture is very similar to the old architecture. For reference the hyperparameters used to train the new model are...\n",
    "\n",
    "---\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 5e-4\n",
    "\n",
    "decay_rate = 4e-4\n",
    "\n",
    "c_dropout = 0.30\n",
    "\n",
    "f_dropout = 0.30\n",
    "\n",
    "---\n",
    "\n",
    "After training the model, I noticed large improvements in training and testing loss being 0.6250 and 0.6327 at the 20th epoch which is better than the ~0.80 training and testing loss for the architecture from homework 2. From here, I tried to tinker with learning rate by setting it to 1e-4 but the model not only took longer to get to an optimal training and testing loss, around the 35th epoch, but could only get a loss around ~0.64. Fiddling with the dropout was also not successful and would only make the model take longer to train but not get losses lower than ~0.70.\n",
    "\n",
    "#### Second Model Architecture(s)\n",
    "\n",
    "After exhausting all of my options for the first model I made, I decided to instead try and make the model more complex, I noticed that the CNN Layers would expand the number of channels in a reverse funnel, but I never thought to just try and keep the channels constant. Originally, I used a reverse funnel since I wanted the model to be able to get a few base features in the first layer and then use those to create more and more complex features in subseqeunt layers. However, if I tried keeping the same, I could achieve the same effect but instead of tying to just repeatetly getting more and more complex features, I would be building more and more complex features in a more controlled way. As such, I decided to keep the number of channels to 64 for all four CNN layers.\n",
    "\n",
    "So, so the architecture for this model is now...\n",
    "\n",
    "4x CNN layers (64 -> 64 -> 64 -> 64) with kernels 3x3 and stride 1 into a Max Pool of kernel 2x2 and stride 2 finally into a Linear Classifier (1000 -> 500 -> 250 -> 10).\n",
    "\n",
    "Also you might notice that this section is suffixed with \"Architecture(s).\" This is because I experimented with various constant sizes for the CNN Layers which will be explained in the next section\n",
    "\n",
    "#### Second Model Training\n",
    "\n",
    "Once again, I decided to keep the hyperparameters that were previously listed since they seem to be the most optimal for the current model. By the 62th epoch, the model was able to get a new training and testing loss of ~0.60 around the 60th epoch. Knowing that it would be best to keep the hyperparameters the same, I decided that the only way forward would be to just adjust the width of the CNN layers, so I decided to go from 64 channels per layer to 128 channels per layer which allowed me to get a lower training and testing loss of ~0.57. For my next change, I decided to go even further and try using a constant size of 256 for the CNN channels and got a testing and training loss ~0.50. From this, we can see that increasing the channels in the CNN layers in this way allows the model to reach better and better losses for the most part, but of course, this comes at the cost of longer training times. For one final push, I tried increasing the channels to 512 but not only did it take a while to train the lowest loss it got was around ~0.54 at the 17th epoch.\n",
    "\n",
    "#### Results\n",
    "\n",
    "Refer to Figure 1 for the loss graph.\n",
    "\n",
    "---\n",
    "\n",
    "Final Accuracy:\n",
    "\n",
    "Final Training Loss:\n",
    "\n",
    "Final Testing Loss:\n",
    "\n",
    "Best Model Architecture: 4x CNN Layers (256 -> 256 -> 256 -> 256) of kernels 3x3 and stride 1 into MaxPool Layer of kernel 2x2 and stride 2 into Linear Classifier with layers (1000 -> 500 -> 250 -> 100 -> 10)\n",
    "\n",
    "---\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "decay_rate = 4e-4\n",
    "\n",
    "c_dropout = 0.30\n",
    "\n",
    "f_dropout = 0.30"
   ],
   "id": "aeb0ff93c2edbdb1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Route 1: ResNet Classifier\n",
    "\n",
    "#### ResNet Design\n",
    "\n",
    "To start, I decided that I wanted to make ResNet blocks out of purely CNN layers. This is because the original ResNet paper which used a ResNet on image classification also used a similar architecture, so I wanted to see if making a NN like it would be benefitital. To start, I decided to define a CNN block with two CNN layers that keep constant planes (another terminology meaning channels) based on user specification. The block keeps the size of the out planes constant so that we can perform the math of adding the logits processed from the block back to the original input. In addition, there are batch normalization layers in between the CNN layers. For the final ResNet, I made it so that it can make stages with a number of blocks per stages as specified by user. For the first stage, the NN keeps the dimensionality of the image the same, however, subsequent stages will downsample the image. After all the stages, the output is given to a Linear Classifier with dropout layers.\n",
    "\n",
    "#### Initial Model Architecture\n",
    "\n",
    "In the beginning, I decided to make the NN start with three stages each with 3 blocks. Additionally, I decided to start the model with 32 planes since I wanted a baseline to see how well the model can perform. Lastly, the Linear Classifier was made of four layers of sizes (2000 -> 1500 -> 1000 -> 500) and had dropout.\n",
    "\n",
    "For this trial, it was mearly a test run to see where I stood and what could be improved.\n",
    "\n",
    "#### Initial Model Training\n",
    "\n",
    "To start, I decided to use the hyperparameters...\n",
    "\n",
    "---\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "decay_rate = 1e-4\n",
    "\n",
    "f_dropout = 0.5\n",
    "\n",
    "---\n",
    "\n",
    "I wanted to keep use a higher learning rate and dropout as a baseline to see where I needed to adjust. Though the weight decay is also higher, I chose this not as a baseline but rather as another measure to further combat any overfitting since the model is not using dropout in the CNN blocks or layer normalization in the Linear Classifier. After training, the model was able to get a training loss of ~0.55 and testing loss of ~0.59 at the 11th epoch. Afterwards, the model would continue to overtrain severally. Though I wasn't able to immediately beat the best loss of the model in first half of the homework, the model is close to it without immediate tuning."
   ],
   "id": "cdc64873417cfc7d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-11T03:42:43.514496Z",
     "start_time": "2025-12-11T03:42:41.038410Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:42:59.175291Z",
     "start_time": "2025-12-11T03:42:44.885626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Grab the MNIST dataset\n",
    "training_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testing_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "tfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset_full_CIFAR10 = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=tfm)\n",
    "testset_full_CIFAR10  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=tfm)"
   ],
   "id": "fffd1952ab91cd32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.04MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 6.77MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.82MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:09<00:00, 17.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:43:07.476914Z",
     "start_time": "2025-12-11T03:43:07.396411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verify that GPU is connected and available\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(torch.cuda.get_device_name(0))"
   ],
   "id": "62c84a2afc22de88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:43:09.452173Z",
     "start_time": "2025-12-11T03:43:09.442082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CIFAR10_Classifier(nn.Module):\n",
    "    def __init__(self, C_dropout, F_dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        conv2d_dropout = C_dropout\n",
    "\n",
    "        conv_layer_1 = 512\n",
    "        conv_layer_2 = 512\n",
    "\n",
    "        conv_layer_3 = 512\n",
    "        conv_layer_4 = 512\n",
    "\n",
    "        self.forward_funnel_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=conv_layer_1, kernel_size=3),   # Extract useful features from the beginning\n",
    "            nn.BatchNorm2d(num_features=conv_layer_1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=conv_layer_1, out_channels=conv_layer_2, kernel_size=3),  # Extract useful features from the learned features\n",
    "            nn.BatchNorm2d(num_features=conv_layer_2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                       # Reduce dimensionality\n",
    "        )\n",
    "\n",
    "        self.forward_funnel_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=conv_layer_2, out_channels=conv_layer_3, kernel_size=3),   # Extract useful features from the beginning\n",
    "            nn.BatchNorm2d(num_features=conv_layer_3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=conv_layer_3, out_channels=conv_layer_4, kernel_size=3),  # Extract useful features from the learned features\n",
    "            nn.BatchNorm2d(num_features=conv_layer_4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Compute the number of features after the input has passed the funnel\n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, 3, 32, 32)\n",
    "\n",
    "            test_input.to(device)\n",
    "\n",
    "            features = self.forward_funnel_1(test_input)\n",
    "            features = self.forward_funnel_2(features)\n",
    "\n",
    "            total_count = features.view(1, -1).size(1)\n",
    "\n",
    "        full_node_dropout = F_dropout\n",
    "\n",
    "\n",
    "        lin_layer_1_size = 1000\n",
    "        lin_layer_2_size = 500\n",
    "        lin_layer_3_size = 250\n",
    "\n",
    "        self.output_nodes = 100\n",
    "\n",
    "        self.classifer = nn.Sequential(\n",
    "            nn.Flatten(),                                           # Flatten the image from the funnel\n",
    "            nn.Linear(in_features=total_count, out_features=lin_layer_1_size),\n",
    "            nn.LayerNorm(lin_layer_1_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_1_size, out_features=lin_layer_2_size),\n",
    "            nn.LayerNorm(lin_layer_2_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_2_size, out_features=lin_layer_3_size),\n",
    "            nn.LayerNorm(lin_layer_3_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_3_size, out_features=self.output_nodes),\n",
    "            nn.LayerNorm(self.output_nodes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(in_features=self.output_nodes, out_features=10)\n",
    "\n",
    "    def partial_forward(self, x):\n",
    "        x = self.forward_funnel_1(x)\n",
    "        x = self.forward_funnel_2(x)\n",
    "        x = self.classifer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.partial_forward(x)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        return logits"
   ],
   "id": "9eda8e70dd5aafa0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T04:35:49.864525Z",
     "start_time": "2025-12-11T04:35:49.862067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epoch_over_training_loss_CIFAR10 = []\n",
    "epoch_over_testing_loss_CIFAR10 = []"
   ],
   "id": "411db29028bfd083",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Hyperparameter setup\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "decay_rate = 4e-4\n",
    "\n",
    "c_dropout = 0.30\n",
    "f_dropout = 0.30\n",
    "\n",
    "print('######## Begining training for CIFAR10 classifier ##########')\n",
    "\n",
    "# Setup data loaders\n",
    "trainset_loader_CIFAR10 = data.DataLoader(trainset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=8,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "testset_loader_CIFAR10 = data.DataLoader(testset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   num_workers=8,\n",
    "                                   shuffle=False,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "model = CIFAR10_Classifier(c_dropout, f_dropout)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                       lr=learning_rate,\n",
    "                       weight_decay=decay_rate\n",
    "                       )\n",
    "\n",
    "# Have references to variables outside of the epoch loop\n",
    "avg_training_loss = 0\n",
    "avg_testing_loss = 0\n",
    "\n",
    "# Epoch Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for x, Y in tqdm(trainset_loader_CIFAR10, desc='Training', unit=' batch'):\n",
    "        # Transfer images to GPU\n",
    "        x = x.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Send images to model\n",
    "        x_pred = model(x)\n",
    "\n",
    "        # Calc loss\n",
    "        loss = loss_function(x_pred, Y)\n",
    "\n",
    "        # Calc gradient and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_training_loss += loss.item()\n",
    "\n",
    "    # Switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, Y in tqdm(testset_loader_CIFAR10, desc='Testing', unit=' batches'):\n",
    "            # Move the images to the GPU\n",
    "            x = x.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            # Get logits and sum up total loss\n",
    "            x_pred = model(x)\n",
    "            avg_testing_loss += loss_function(x_pred, Y).item()\n",
    "\n",
    "    # Get training loss\n",
    "    avg_training_loss /= len(trainset_loader_CIFAR10)\n",
    "\n",
    "     # Get testing loss\n",
    "    avg_testing_loss /= len(testset_loader_CIFAR10)\n",
    "\n",
    "    # Switch model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    epoch_over_training_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"training_loss\": avg_training_loss\n",
    "        })\n",
    "\n",
    "    epoch_over_testing_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"testing_loss\": avg_testing_loss\n",
    "        })\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "    print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n"
   ],
   "id": "ef78fbe91c4a187d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:01:41.460297Z",
     "start_time": "2025-12-11T05:01:41.450631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNN_Block(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.cnn_dropout = cnn_dropout\n",
    "\n",
    "        self.skip = nn.Sequential()\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_planes, out_channels=planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "\n",
    "            nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "        )\n",
    "\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            # Use a 1x1 convolution to match the dimensions (channels and spatial size)\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Pass the input through the block\n",
    "        logits = self.conv_block(x)\n",
    "\n",
    "        # Skip the original data\n",
    "        logits += self.skip(x)\n",
    "\n",
    "        # Activation Function\n",
    "        logits = F.relu(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "class CIFAR10_ResNet(nn.Module):\n",
    "    def __init__(self, num_blocks:list, num_classes=10, linear_dropout=0.25):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initial size of the CNN layer that accepts the image\n",
    "        # Also used when creating stages of blocks self.stage_layer\n",
    "        self.in_planes = 48\n",
    "\n",
    "        self.image_input_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.in_planes),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        range_beginning = 48\n",
    "        range_end = 144\n",
    "        range_step = range_beginning\n",
    "\n",
    "        self.cnn_plane_range = range(range_beginning, range_end + 1, range_step)\n",
    "\n",
    "        self.stages = nn.Sequential(\n",
    "            *[self.make_stage(planes, num_block, 1 if idx == 0 else 2)\n",
    "                for idx, (planes, num_block) in enumerate(zip(self.cnn_plane_range, num_blocks))]\n",
    "        )\n",
    "\n",
    "        self.lin_layer_1_size = 2000\n",
    "        self.lin_layer_2_size = 1500\n",
    "        self.lin_layer_3_size = 1000\n",
    "        self.lin_layer_4_size = 500\n",
    "\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(range_end, self.lin_layer_1_size),\n",
    "            # nn.LayerNorm(self.lin_layer_1_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_1_size, self.lin_layer_2_size),\n",
    "            # nn.LayerNorm(self.lin_layer_2_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_2_size, self.lin_layer_3_size),\n",
    "            # nn.LayerNorm(self.lin_layer_3_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_3_size, self.lin_layer_4_size),\n",
    "            nn.LayerNorm(self.lin_layer_4_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_4_size, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "    def make_stage(self, planes, num_blocks, stride):\n",
    "\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        for stride in strides:\n",
    "            # Add ResBlock to list\n",
    "            layers.append(CNN_Block(self.in_planes, planes, stride))\n",
    "            # Reset the in planes to preserve in_channels of the next blocks\n",
    "            self.in_planes = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        logits = self.image_input_layer(x)\n",
    "\n",
    "        logits = self.stages(logits)\n",
    "\n",
    "        logits = F.avg_pool2d(logits, 8)\n",
    "\n",
    "        logits = logits.view(logits.size(0), -1)\n",
    "\n",
    "        logits = self.classifier(logits)\n",
    "\n",
    "        return logits\n",
    "\n"
   ],
   "id": "fc4fe148e9a5bebf",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:05:23.627575Z",
     "start_time": "2025-12-11T05:01:42.523881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameter setup\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "decay_rate = 1e-4\n",
    "\n",
    "f_dropout = 0.5\n",
    "\n",
    "print('######## Beginning training for CIFAR10 ResNet classifier ##########')\n",
    "\n",
    "# Setup data loaders\n",
    "trainset_loader_CIFAR10 = data.DataLoader(trainset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=8,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "testset_loader_CIFAR10 = data.DataLoader(testset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   num_workers=8,\n",
    "                                   shuffle=False,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "model = CIFAR10_ResNet(num_blocks=[3, 3, 3], num_classes=10, linear_dropout=f_dropout)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                       lr=learning_rate,\n",
    "                       weight_decay=decay_rate\n",
    "                       )\n",
    "\n",
    "# Have references to variables outside of the epoch loop\n",
    "avg_training_loss = 0\n",
    "avg_testing_loss = 0\n",
    "\n",
    "# Epoch Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for x, Y in tqdm(trainset_loader_CIFAR10, desc='Training', unit=' batch'):\n",
    "        # Transfer images to GPU\n",
    "        x = x.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Send images to model\n",
    "        x_pred = model(x)\n",
    "\n",
    "        # Calc loss\n",
    "        loss = loss_function(x_pred, Y)\n",
    "\n",
    "        # Calc gradient and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_training_loss += loss.item()\n",
    "\n",
    "    # Switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, Y in tqdm(testset_loader_CIFAR10, desc='Testing', unit=' batches'):\n",
    "            # Move the images to the GPU\n",
    "            x = x.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            # Get logits and sum up total loss\n",
    "            x_pred = model(x)\n",
    "            avg_testing_loss += loss_function(x_pred, Y).item()\n",
    "\n",
    "    # Get training loss\n",
    "    avg_training_loss /= len(trainset_loader_CIFAR10)\n",
    "\n",
    "     # Get testing loss\n",
    "    avg_testing_loss /= len(testset_loader_CIFAR10)\n",
    "\n",
    "    # Switch model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    epoch_over_training_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"training_loss\": avg_training_loss\n",
    "        })\n",
    "\n",
    "    epoch_over_testing_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"testing_loss\": avg_testing_loss\n",
    "        })\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "    print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n"
   ],
   "id": "f6c30184c0bec3a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Beginning training for CIFAR10 ResNet classifier ##########\n",
      "----- Epoch: 1/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:24<00:00, 32.17 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 101.50 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.8090\n",
      "\n",
      "   -> Testing Loss:  1.7175\n",
      "\n",
      "----- Epoch: 2/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:25<00:00, 31.08 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.40 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.5498\n",
      "\n",
      "   -> Testing Loss:  1.4117\n",
      "\n",
      "----- Epoch: 3/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:29<00:00, 26.86 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.86 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.3506\n",
      "\n",
      "   -> Testing Loss:  1.3228\n",
      "\n",
      "----- Epoch: 4/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:29<00:00, 26.75 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.54 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.1645\n",
      "\n",
      "   -> Testing Loss:  1.1289\n",
      "\n",
      "----- Epoch: 5/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:29<00:00, 26.63 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 87.56 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.0366\n",
      "\n",
      "   -> Testing Loss:  0.9792\n",
      "\n",
      "----- Epoch: 6/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:29<00:00, 26.53 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 86.20 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.9301\n",
      "\n",
      "   -> Testing Loss:  0.9060\n",
      "\n",
      "----- Epoch: 7/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:36<00:00, 21.64 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:06<00:00, 24.00 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.8541\n",
      "\n",
      "   -> Testing Loss:  0.9767\n",
      "\n",
      "----- Epoch: 8/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 5/782 [00:00<02:32,  5.09 batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 65\u001B[39m\n\u001B[32m     62\u001B[39m     optimizer.step()\n\u001B[32m     64\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m---> \u001B[39m\u001B[32m65\u001B[39m         avg_training_loss += \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[38;5;66;03m# Switch to eval mode\u001B[39;00m\n\u001B[32m     68\u001B[39m model.eval()\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2fc4a8beb273497c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

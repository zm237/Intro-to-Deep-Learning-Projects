{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Homework 4",
   "id": "4bc89c27d1be5595"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Objective: Get the lowest loss on a CIFAR10 Classifier\n",
    "\n",
    "After taking the entirety of the Deep Learning course, I have had the opportunity to learn various of techniques to solve different problems using classical deep learning techniques. However, for this homework, I decided that the two most important things that will be helpful for me to get a lower loss on the CIFAR image classification task are Batch/Layer Normalization and ResNets. As such, I first decided to focus on making the best model I got in homework 2 better by introducing normalization and also trying different model architectures to lower the loss. Finally, I will showcase the ResNet I made to see if it can beat the optimized model from homework 2."
   ],
   "id": "740e12cb939ceca8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Route 1: Optimization of HW2 Model\n",
    "\n",
    "#### Initial Model Architecture\n",
    "\n",
    "To start, I decided to take a look at the model from the last homework that worked best for this task. Before doing anything, this model had 4 CNN layers with channels (30 -> 64 -> 128 -> 256), kernel sizes (5x5 -> 3x3 -> 3x3 -> 3x3), and a constant stride of 1, a Max Pooling layer with kernel 2x2 and stride 2, and finally a classification head with linear layers (1000 -> 500 -> 250 -> 10). Of course, dropout was placed between every layer when possible. Looking at the model, I saw that it was not currently using any form of normalization, so I thought to add batch normalization between the CNN layers and layer normalization between the linear layers. Furthermore, I decided to do this not just because it was a new tool but also since I saw that it was effective when used for the models in Homework 3.\n",
    "\n",
    "#### Model Training\n",
    "\n",
    "For the first training loop, I decided to use the hyperparameters that were kept for the original model in Homework 2 since the new architecture is very similar to the old architecture. For reference the hyperparameters used to train the new model are...\n",
    "\n",
    "---\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 5e-4\n",
    "\n",
    "decay_rate = 4e-4\n",
    "\n",
    "c_dropout = 0.30\n",
    "\n",
    "f_dropout = 0.30\n",
    "\n",
    "---\n",
    "\n",
    "After training the model, I noticed large improvements in training and testing loss being 0.6250 and 0.6327 at the 20th epoch which is better than the ~0.80 training and testing loss for the architecture from homework 2. From here, I tried to tinker with learning rate by setting it to 1e-4 but the model not only took longer to get to an optimal training and testing loss, around the 35th epoch, but could only get a loss around ~0.64. Fiddling with the dropout was also not successful and would only make the model take longer to train but not get losses lower than ~0.70.\n",
    "\n",
    "#### Second Model Architecture(s)\n",
    "\n",
    "After exhausting all of my options for the first model I made, I decided to instead try and make the model more complex, I noticed that the CNN Layers would expand the number of channels in a reverse funnel, but I never thought to just try and keep the channels constant. Originally, I used a reverse funnel since I wanted the model to be able to get a few base features in the first layer and then use those to create more and more complex features in subseqeunt layers. However, if I tried keeping the same, I could achieve the same effect but instead of tying to just repeatetly getting more and more complex features, I would be building more and more complex features in a more controlled way. As such, I decided to keep the number of channels to 64 for all four CNN layers.\n",
    "\n",
    "So, so the architecture for this model is now...\n",
    "\n",
    "4x CNN layers (64 -> 64 -> 64 -> 64) with kernels 3x3 and stride 1 into a Max Pool of kernel 2x2 and stride 2 finally into a Linear Classifier (1000 -> 500 -> 250 -> 10).\n",
    "\n",
    "Also you might notice that this section is suffixed with \"Architecture(s).\" This is because I experimented with various constant sizes for the CNN Layers which will be explained in the next section\n",
    "\n",
    "#### Second Model Training\n",
    "\n",
    "Once again, I decided to keep the hyperparameters that were previously listed since they seem to be the most optimal for the current model. By the 62th epoch, the model was able to get a new training and testing loss of ~0.60 around the 60th epoch. Knowing that it would be best to keep the hyperparameters the same, I decided that the only way forward would be to just adjust the width of the CNN layers, so I decided to go from 64 channels per layer to 128 channels per layer which allowed me to get a lower training and testing loss of ~0.57. For my next change, I decided to go even further and try using a constant size of 256 for the CNN channels and got a testing and training loss ~0.50. From this, we can see that increasing the channels in the CNN layers in this way allows the model to reach better and better losses for the most part, but of course, this comes at the cost of longer training times. For one final push, I tried increasing the channels to 512 but not only did it take a while to train the lowest loss it got was around ~0.54 at the 17th epoch.\n",
    "\n",
    "#### Results\n",
    "\n",
    "Refer to Figure 1 for the loss graph.\n",
    "\n",
    "---\n",
    "\n",
    "Final Accuracy:\n",
    "\n",
    "Final Training Loss:\n",
    "\n",
    "Final Testing Loss:\n",
    "\n",
    "Best Model Architecture: 4x CNN Layers (256 -> 256 -> 256 -> 256) of kernels 3x3 and stride 1 into MaxPool Layer of kernel 2x2 and stride 2 into Linear Classifier with layers (1000 -> 500 -> 250 -> 100 -> 10)\n",
    "\n",
    "---\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "decay_rate = 4e-4\n",
    "\n",
    "c_dropout = 0.30\n",
    "\n",
    "f_dropout = 0.30"
   ],
   "id": "aeb0ff93c2edbdb1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Route 1: ResNet Classifier\n",
    "\n",
    "#### Initial Model Architecture\n",
    "\n",
    "To start, I decided that I wanted to make ResNet blocks out of purely CNN layers. This is because the original ResNet paper which used a ResNet on image classification also used a similar architecture, so I wanted to see if making a NN like it would be benefitial.\n"
   ],
   "id": "cdc64873417cfc7d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-10T22:14:51.176413Z",
     "start_time": "2025-12-10T22:14:51.173620Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T19:41:14.447440Z",
     "start_time": "2025-12-10T19:41:13.016546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Grab the MNIST dataset\n",
    "training_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testing_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "tfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset_full_CIFAR10 = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=tfm)\n",
    "testset_full_CIFAR10  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=tfm)"
   ],
   "id": "fffd1952ab91cd32",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T19:41:14.634646Z",
     "start_time": "2025-12-10T19:41:14.479562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verify that GPU is connected and available\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(torch.cuda.get_device_name(0))"
   ],
   "id": "62c84a2afc22de88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu128\n",
      "NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T23:33:51.098449Z",
     "start_time": "2025-12-10T23:33:51.089616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CIFAR10_Classifier(nn.Module):\n",
    "    def __init__(self, C_dropout, F_dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        conv2d_dropout = C_dropout\n",
    "\n",
    "        conv_layer_1 = 512\n",
    "        conv_layer_2 = 512\n",
    "\n",
    "        conv_layer_3 = 512\n",
    "        conv_layer_4 = 512\n",
    "\n",
    "        self.forward_funnel_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=conv_layer_1, kernel_size=3),   # Extract useful features from the beginning\n",
    "            nn.BatchNorm2d(num_features=conv_layer_1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=conv_layer_1, out_channels=conv_layer_2, kernel_size=3),  # Extract useful features from the learned features\n",
    "            nn.BatchNorm2d(num_features=conv_layer_2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                       # Reduce dimensionality\n",
    "        )\n",
    "\n",
    "        self.forward_funnel_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=conv_layer_2, out_channels=conv_layer_3, kernel_size=3),   # Extract useful features from the beginning\n",
    "            nn.BatchNorm2d(num_features=conv_layer_3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=conv_layer_3, out_channels=conv_layer_4, kernel_size=3),  # Extract useful features from the learned features\n",
    "            nn.BatchNorm2d(num_features=conv_layer_4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Compute the number of features after the input has passed the funnel\n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, 3, 32, 32)\n",
    "\n",
    "            test_input.to(device)\n",
    "\n",
    "            features = self.forward_funnel_1(test_input)\n",
    "            features = self.forward_funnel_2(features)\n",
    "\n",
    "            total_count = features.view(1, -1).size(1)\n",
    "\n",
    "        full_node_dropout = F_dropout\n",
    "\n",
    "\n",
    "        lin_layer_1_size = 1000\n",
    "        lin_layer_2_size = 500\n",
    "        lin_layer_3_size = 250\n",
    "\n",
    "        self.output_nodes = 100\n",
    "\n",
    "        self.classifer = nn.Sequential(\n",
    "            nn.Flatten(),                                           # Flatten the image from the funnel\n",
    "            nn.Linear(in_features=total_count, out_features=lin_layer_1_size),\n",
    "            nn.LayerNorm(lin_layer_1_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_1_size, out_features=lin_layer_2_size),\n",
    "            nn.LayerNorm(lin_layer_2_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_2_size, out_features=lin_layer_3_size),\n",
    "            nn.LayerNorm(lin_layer_3_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=lin_layer_3_size, out_features=self.output_nodes),\n",
    "            nn.LayerNorm(self.output_nodes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(in_features=self.output_nodes, out_features=10)\n",
    "\n",
    "    def partial_forward(self, x):\n",
    "        x = self.forward_funnel_1(x)\n",
    "        x = self.forward_funnel_2(x)\n",
    "        x = self.classifer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.partial_forward(x)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        return logits"
   ],
   "id": "9eda8e70dd5aafa0",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T23:33:51.467734Z",
     "start_time": "2025-12-10T23:33:51.465469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epoch_over_training_loss_CIFAR10 = []\n",
    "epoch_over_testing_loss_CIFAR10 = []"
   ],
   "id": "411db29028bfd083",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T23:43:39.314978Z",
     "start_time": "2025-12-10T23:33:51.725595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameter setup\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "decay_rate = 4e-4\n",
    "\n",
    "c_dropout = 0.30\n",
    "f_dropout = 0.30\n",
    "\n",
    "print('######## Begining training for CIFAR10 classifier ##########')\n",
    "\n",
    "# Setup data loaders\n",
    "trainset_loader_CIFAR10 = data.DataLoader(trainset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=8,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "testset_loader_CIFAR10 = data.DataLoader(testset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   num_workers=8,\n",
    "                                   shuffle=False,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "model = CIFAR10_Classifier(c_dropout, f_dropout)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                       lr=learning_rate,\n",
    "                       weight_decay=decay_rate\n",
    "                       )\n",
    "\n",
    "# Have references to variables outside of the epoch loop\n",
    "avg_training_loss = 0\n",
    "avg_testing_loss = 0\n",
    "\n",
    "# Epoch Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for x, Y in tqdm(trainset_loader_CIFAR10, desc='Training', unit=' batch'):\n",
    "        # Transfer images to GPU\n",
    "        x = x.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Send images to model\n",
    "        x_pred = model(x)\n",
    "\n",
    "        # Calc loss\n",
    "        loss = loss_function(x_pred, Y)\n",
    "\n",
    "        # Calc gradient and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_training_loss += loss.item()\n",
    "\n",
    "    # Switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, Y in tqdm(testset_loader_CIFAR10, desc='Testing', unit=' batches'):\n",
    "            # Move the images to the GPU\n",
    "            x = x.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            # Get logits and sum up total loss\n",
    "            x_pred = model(x)\n",
    "            avg_testing_loss += loss_function(x_pred, Y).item()\n",
    "\n",
    "    # Get training loss\n",
    "    avg_training_loss /= len(trainset_loader_CIFAR10)\n",
    "\n",
    "     # Get testing loss\n",
    "    avg_testing_loss /= len(testset_loader_CIFAR10)\n",
    "\n",
    "    # Switch model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    epoch_over_training_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"training_loss\": avg_training_loss\n",
    "        })\n",
    "\n",
    "    epoch_over_testing_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"testing_loss\": avg_testing_loss\n",
    "        })\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "    print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n"
   ],
   "id": "ef78fbe91c4a187d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Begining training for CIFAR10 classifier ##########\n",
      "----- Epoch: 1/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.52 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 84.68 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.7892\n",
      "\n",
      "   -> Testing Loss:  1.3688\n",
      "\n",
      "----- Epoch: 2/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.53 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.57 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.4115\n",
      "\n",
      "   -> Testing Loss:  1.1577\n",
      "\n",
      "----- Epoch: 3/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.63 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.21 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.2225\n",
      "\n",
      "   -> Testing Loss:  0.9990\n",
      "\n",
      "----- Epoch: 4/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.64 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 84.88 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.0942\n",
      "\n",
      "   -> Testing Loss:  0.9022\n",
      "\n",
      "----- Epoch: 5/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.64 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 84.84 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.9909\n",
      "\n",
      "   -> Testing Loss:  0.7971\n",
      "\n",
      "----- Epoch: 6/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.62 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.25 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.9201\n",
      "\n",
      "   -> Testing Loss:  0.7562\n",
      "\n",
      "----- Epoch: 7/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.64 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.55 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.8580\n",
      "\n",
      "   -> Testing Loss:  0.7360\n",
      "\n",
      "----- Epoch: 8/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.63 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.18 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.8178\n",
      "\n",
      "   -> Testing Loss:  0.6992\n",
      "\n",
      "----- Epoch: 9/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.63 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.18 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.7738\n",
      "\n",
      "   -> Testing Loss:  0.6415\n",
      "\n",
      "----- Epoch: 10/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.62 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.10 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.7321\n",
      "\n",
      "   -> Testing Loss:  0.6350\n",
      "\n",
      "----- Epoch: 11/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.62 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.25 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.6978\n",
      "\n",
      "   -> Testing Loss:  0.6261\n",
      "\n",
      "----- Epoch: 12/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.64 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.46 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.6731\n",
      "\n",
      "   -> Testing Loss:  0.6068\n",
      "\n",
      "----- Epoch: 13/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.64 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.09 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.6434\n",
      "\n",
      "   -> Testing Loss:  0.5839\n",
      "\n",
      "----- Epoch: 14/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.64 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.31 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.6163\n",
      "\n",
      "   -> Testing Loss:  0.5604\n",
      "\n",
      "----- Epoch: 15/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.63 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.42 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.5885\n",
      "\n",
      "   -> Testing Loss:  0.5866\n",
      "\n",
      "----- Epoch: 16/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.66 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.39 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.5666\n",
      "\n",
      "   -> Testing Loss:  0.5630\n",
      "\n",
      "----- Epoch: 17/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.59 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 85.16 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.5440\n",
      "\n",
      "   -> Testing Loss:  0.5432\n",
      "\n",
      "----- Epoch: 18/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:30<00:00, 25.42 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 83.05 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.5216\n",
      "\n",
      "   -> Testing Loss:  0.5575\n",
      "\n",
      "----- Epoch: 19/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 99/782 [00:04<00:31, 21.97 batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[67], line 66\u001B[0m\n\u001B[1;32m     63\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 66\u001B[0m         avg_training_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;66;03m# Switch to eval mode\u001B[39;00m\n\u001B[1;32m     69\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T02:38:28.240279Z",
     "start_time": "2025-12-10T02:38:28.228175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CIFAR_ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(CIFAR_ResNet, self).__init__()\n",
    "\n",
    "        self.in_planes = 16  # Reduced initial channel size (Standard ResNet uses 64)\n",
    "\n",
    "        # Initial Conv Layer (Key modification for CIFAR 32x32 input)\n",
    "        # Use 3x3 Conv with stride=1 to avoid downsampling too quickly\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # ResNet Stages (Downsampling happens via stride=2 in the *first* block of each stage)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1) # No downsampling here (32x32 -> 32x32)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2) # Downsample to 16x16\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2) # Downsample to 8x8\n",
    "\n",
    "        # Final Classification Layer\n",
    "        self.linear = nn.Linear(64 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        \"\"\"Creates one stage (group of residual blocks)\"\"\"\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "\n",
    "        for stride_val in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride_val))\n",
    "            self.in_planes = planes * block.expansion # Update in_planes for the next block\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial Block\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        # Residual Stages\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "\n",
    "        # Global Average Pooling (8x8 -> 1x1)\n",
    "        out = F.avg_pool2d(out, out.size(3))\n",
    "\n",
    "        # Final Classification\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ],
   "id": "9dac75332fca018",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T00:18:24.948795Z",
     "start_time": "2025-12-11T00:18:24.938109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNN_Block(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.cnn_dropout = cnn_dropout\n",
    "\n",
    "        self.skip = nn.Sequential()\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_planes, out_channels=planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "\n",
    "            nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "        )\n",
    "\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            # Use a 1x1 convolution to match the dimensions (channels and spatial size)\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Pass the input through the block\n",
    "        logits = self.conv_block(x)\n",
    "\n",
    "        # Skip the original data\n",
    "        logits += self.skip(x)\n",
    "\n",
    "        # Activation Function\n",
    "        logits = F.relu(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "class CIFAR10_ResNet(nn.Module):\n",
    "    def __init__(self, num_blocks:list, num_classes=10, linear_dropout=0.25):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initial size of the CNN layer that accepts the image\n",
    "        # Also used when creating stages of blocks self.stage_layer\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.image_input_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.in_planes),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        range_beginning = 16\n",
    "        range_end = 48\n",
    "        range_step = range_beginning\n",
    "\n",
    "        self.cnn_plane_range = range(range_beginning, range_end + 1, range_step)\n",
    "\n",
    "        self.stages = nn.Sequential(\n",
    "            *[self.make_stage(planes, num_block, 1 if idx == 0 else 2)\n",
    "                for idx, (planes, num_block) in enumerate(zip(self.cnn_plane_range, num_blocks))]\n",
    "        )\n",
    "\n",
    "        self.lin_layer_1_size = 2000\n",
    "        self.lin_layer_2_size = 1500\n",
    "        self.lin_layer_3_size = 1000\n",
    "        self.lin_layer_4_size = 500\n",
    "\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(range_end, self.lin_layer_1_size),\n",
    "            # nn.LayerNorm(self.lin_layer_1_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_1_size, self.lin_layer_2_size),\n",
    "            # nn.LayerNorm(self.lin_layer_2_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_2_size, self.lin_layer_3_size),\n",
    "            # nn.LayerNorm(self.lin_layer_3_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_3_size, self.lin_layer_4_size),\n",
    "            nn.LayerNorm(self.lin_layer_4_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(linear_dropout),\n",
    "\n",
    "            nn.Linear(self.lin_layer_4_size, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "    def make_stage(self, planes, num_blocks, stride):\n",
    "\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        for stride in strides:\n",
    "            # Add ResBlock to list\n",
    "            layers.append(CNN_Block(self.in_planes, planes, stride))\n",
    "            # Reset the in planes to preserve in_channels of the next blocks\n",
    "            self.in_planes = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        logits = self.image_input_layer(x)\n",
    "\n",
    "        logits = self.stages(logits)\n",
    "\n",
    "        logits = F.avg_pool2d(logits, 8)\n",
    "\n",
    "        logits = logits.view(logits.size(0), -1)\n",
    "\n",
    "        logits = self.classifier(logits)\n",
    "\n",
    "        return logits\n",
    "\n"
   ],
   "id": "fc4fe148e9a5bebf",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T00:24:30.311869Z",
     "start_time": "2025-12-11T00:21:40.168179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameter setup\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "decay_rate = 1e-4\n",
    "\n",
    "f_dropout = 0.5\n",
    "\n",
    "print('######## Begining training for CIFAR10 ResNet classifier ##########')\n",
    "\n",
    "# Setup data loaders\n",
    "trainset_loader_CIFAR10 = data.DataLoader(trainset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=8,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "testset_loader_CIFAR10 = data.DataLoader(testset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   num_workers=8,\n",
    "                                   shuffle=False,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "model = CIFAR10_ResNet(num_blocks=[5, 5, 5], num_classes=10, linear_dropout=f_dropout)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                       lr=learning_rate,\n",
    "                       weight_decay=decay_rate\n",
    "                       )\n",
    "\n",
    "# Have references to variables outside of the epoch loop\n",
    "avg_training_loss = 0\n",
    "avg_testing_loss = 0\n",
    "\n",
    "# Epoch Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for x, Y in tqdm(trainset_loader_CIFAR10, desc='Training', unit=' batch'):\n",
    "        # Transfer images to GPU\n",
    "        x = x.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Send images to model\n",
    "        x_pred = model(x)\n",
    "\n",
    "        # Calc loss\n",
    "        loss = loss_function(x_pred, Y)\n",
    "\n",
    "        # Calc gradient and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_training_loss += loss.item()\n",
    "\n",
    "    # Switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, Y in tqdm(testset_loader_CIFAR10, desc='Testing', unit=' batches'):\n",
    "            # Move the images to the GPU\n",
    "            x = x.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            # Get logits and sum up total loss\n",
    "            x_pred = model(x)\n",
    "            avg_testing_loss += loss_function(x_pred, Y).item()\n",
    "\n",
    "    # Get training loss\n",
    "    avg_training_loss /= len(trainset_loader_CIFAR10)\n",
    "\n",
    "     # Get testing loss\n",
    "    avg_testing_loss /= len(testset_loader_CIFAR10)\n",
    "\n",
    "    # Switch model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    epoch_over_training_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"training_loss\": avg_training_loss\n",
    "        })\n",
    "\n",
    "    epoch_over_testing_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"testing_loss\": avg_testing_loss\n",
    "        })\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "    print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n"
   ],
   "id": "f6c30184c0bec3a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Begining training for CIFAR10 ResNet classifier ##########\n",
      "----- Epoch: 1/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 106.21 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 231.79 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.9183\n",
      "\n",
      "   -> Testing Loss:  1.8173\n",
      "\n",
      "----- Epoch: 2/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 106.62 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 240.04 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.6320\n",
      "\n",
      "   -> Testing Loss:  1.5756\n",
      "\n",
      "----- Epoch: 3/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 104.68 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 242.36 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.4272\n",
      "\n",
      "   -> Testing Loss:  1.3211\n",
      "\n",
      "----- Epoch: 4/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 102.10 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 237.67 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.2804\n",
      "\n",
      "   -> Testing Loss:  1.2256\n",
      "\n",
      "----- Epoch: 5/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 107.34 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 231.58 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.1400\n",
      "\n",
      "   -> Testing Loss:  1.0170\n",
      "\n",
      "----- Epoch: 6/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 106.64 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 232.62 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.0144\n",
      "\n",
      "   -> Testing Loss:  0.9493\n",
      "\n",
      "----- Epoch: 7/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 104.84 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 236.51 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.9408\n",
      "\n",
      "   -> Testing Loss:  0.9307\n",
      "\n",
      "----- Epoch: 8/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 107.20 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 237.59 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.8728\n",
      "\n",
      "   -> Testing Loss:  0.8532\n",
      "\n",
      "----- Epoch: 9/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 106.70 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 224.45 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.8196\n",
      "\n",
      "   -> Testing Loss:  0.8461\n",
      "\n",
      "----- Epoch: 10/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 106.73 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 229.68 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.7807\n",
      "\n",
      "   -> Testing Loss:  0.9656\n",
      "\n",
      "----- Epoch: 11/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 106.05 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 233.38 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.7423\n",
      "\n",
      "   -> Testing Loss:  0.7645\n",
      "\n",
      "----- Epoch: 12/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 103.58 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 241.85 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.7098\n",
      "\n",
      "   -> Testing Loss:  0.7758\n",
      "\n",
      "----- Epoch: 13/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 107.33 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 236.47 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.6807\n",
      "\n",
      "   -> Testing Loss:  0.7530\n",
      "\n",
      "----- Epoch: 14/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 107.03 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 229.81 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.6518\n",
      "\n",
      "   -> Testing Loss:  0.6991\n",
      "\n",
      "----- Epoch: 15/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 110.91 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 236.89 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.6288\n",
      "\n",
      "   -> Testing Loss:  0.7431\n",
      "\n",
      "----- Epoch: 16/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 103.29 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 236.95 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.6078\n",
      "\n",
      "   -> Testing Loss:  0.6668\n",
      "\n",
      "----- Epoch: 17/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 104.60 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 233.51 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.5779\n",
      "\n",
      "   -> Testing Loss:  0.7086\n",
      "\n",
      "----- Epoch: 18/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 102.92 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 239.18 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.5612\n",
      "\n",
      "   -> Testing Loss:  0.6906\n",
      "\n",
      "----- Epoch: 19/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 108.24 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 237.31 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.5474\n",
      "\n",
      "   -> Testing Loss:  0.6796\n",
      "\n",
      "----- Epoch: 20/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 105.31 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 234.10 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.5278\n",
      "\n",
      "   -> Testing Loss:  0.6564\n",
      "\n",
      "----- Epoch: 21/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:07<00:00, 105.22 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:00<00:00, 236.73 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.5046\n",
      "\n",
      "   -> Testing Loss:  0.6604\n",
      "\n",
      "----- Epoch: 22/100 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 58/782 [00:00<00:08, 84.51 batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[86], line 55\u001B[0m\n\u001B[1;32m     52\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     54\u001B[0m \u001B[38;5;66;03m# Send images to model\u001B[39;00m\n\u001B[0;32m---> 55\u001B[0m x_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# Calc loss\u001B[39;00m\n\u001B[1;32m     58\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_function(x_pred, Y)\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1774\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1775\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1782\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1783\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1784\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1785\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1786\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1788\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1789\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[0;32mIn[84], line 113\u001B[0m, in \u001B[0;36mCIFAR10_ResNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    111\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_input_layer(x)\n\u001B[0;32m--> 113\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstages\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    115\u001B[0m     logits \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mavg_pool2d(logits, \u001B[38;5;241m8\u001B[39m)\n\u001B[1;32m    117\u001B[0m     logits \u001B[38;5;241m=\u001B[39m logits\u001B[38;5;241m.\u001B[39mview(logits\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1774\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1775\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1782\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1783\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1784\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1785\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1786\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1788\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1789\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;124;03mRuns the forward pass.\u001B[39;00m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 250\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1774\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1775\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1782\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1783\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1784\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1785\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1786\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1788\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1789\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;124;03mRuns the forward pass.\u001B[39;00m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 250\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1774\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1775\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1782\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1783\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1784\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1785\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1786\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1788\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1789\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[0;32mIn[84], line 28\u001B[0m, in \u001B[0;36mCNN_Block.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     26\u001B[0m \n\u001B[1;32m     27\u001B[0m     \u001B[38;5;66;03m# Pass the input through the block\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv_block\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;66;03m# Skip the original data\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     logits \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip(x)\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1774\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1775\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1782\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1783\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1784\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1785\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1786\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1788\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1789\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;124;03mRuns the forward pass.\u001B[39;00m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 250\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1774\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1775\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1782\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1783\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1784\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1785\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1786\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1788\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1789\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:548\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    547\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 548\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/Intro-to-Deep-Learning-Projects/Project 4/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:543\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\n\u001B[1;32m    533\u001B[0m         F\u001B[38;5;241m.\u001B[39mpad(\n\u001B[1;32m    534\u001B[0m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    541\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups,\n\u001B[1;32m    542\u001B[0m     )\n\u001B[0;32m--> 543\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2fc4a8beb273497c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

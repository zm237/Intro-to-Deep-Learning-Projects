{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3234c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for this project\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ea66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the MNIST dataset\n",
    "training_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testing_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040f5af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "The system GPU | NVIDIA GeForce RTX 4080 | is AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "# Verify that GPU is connected and available\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'The system GPU | {torch.cuda.get_device_name(0) if not None else 'Error'} | is {'AVAILABLE' if torch.cuda.is_available() else 'NOT AVAILABLE' }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c0c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Auto_Encoder(nn.Module):\n",
    "    def __init__(self, bottleneck, hidden_layer_size=784):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Defined number of features for the image\n",
    "        input_size=784\n",
    "\n",
    "        # Encoder section\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size, out_features=hidden_layer_size), # Input to hidden\n",
    "            nn.ReLU(inplace=True),                                             # Activation Function\n",
    "            nn.Linear(in_features=hidden_layer_size, out_features=bottleneck)  # Hidden to bottleneck\n",
    "        )\n",
    "\n",
    "        # Decoder Section\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=bottleneck, out_features=hidden_layer_size), # Bottleneck to hidden\n",
    "            nn.ReLU(inplace=True),                                             # Activation Function\n",
    "            nn.Linear(in_features=hidden_layer_size, out_features=input_size), # Hidden to output\n",
    "            nn.Sigmoid(inplace=True)                                           # Force output pixels to be between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        \n",
    "        # Extract batch size and resize input into the nn\n",
    "        batch_size = x.size(0)\n",
    "        x_flattened = x.view(batch_size, -1)\n",
    "\n",
    "        # Encode then decode the input\n",
    "        x_encoded = self.encoder(x_flattened)\n",
    "        x_decoded = self.decoder(x_encoded)\n",
    "\n",
    "        # Reshape decoded x for final result\n",
    "        x_predicted = x_decoded.view(batch_size, 1, 28, 28)\n",
    "        \n",
    "        return x_predicted\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63aac2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the data for this test\n",
    "k_over_training_loss = []\n",
    "k_over_testing_loss = [] \n",
    "\n",
    "\n",
    "epoch_over_training_loss = []\n",
    "epoch_over_testing_loss = []\n",
    "\n",
    "'''\n",
    "Data for the graph will be in the form of\n",
    "{\n",
    "    k: int\n",
    "    final_training/testing_loss: float\n",
    "}\n",
    "'''\n",
    "\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144822a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Question specific hyperparameters\n",
    "hidden_layer_size = 1000\n",
    "k_start = 748\n",
    "k_end = 0\n",
    "k_step = 160\n",
    "\n",
    "# Loop through each bottlenecks\n",
    "for k in range(k_start, k_end, k_step):\n",
    "    \n",
    "    print(f'########## With bottleneck = {k} ############')\n",
    "    \n",
    "    train_loader = data.DataLoader(training_set, \n",
    "                                    batch_size=batch_size, \n",
    "                                    shuffle=True,\n",
    "                                    num_workers=5, \n",
    "                                    pin_memory=True\n",
    "                               )\n",
    "    \n",
    "    test_loader = data.DataLoader(testing_set, \n",
    "                                    batch_size=batch_size, \n",
    "                                    shuffle=False,\n",
    "                                    num_workers=5, \n",
    "                                    pin_memory=True\n",
    "                               )\n",
    "\n",
    "    model = MNIST_Auto_Encoder(k, hidden_layer_size=hidden_layer_size)\n",
    "    model.to(device)\n",
    "\n",
    "    total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "    print(f' ~~ Total/Trainable Parameters: {total_params}')\n",
    "\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Have references to variables outside of the epoch loop\n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    # Epoch Loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "        # Per epoch reset accumulated loss\n",
    "        avg_training_loss = 0\n",
    "        avg_testing_loss = 0\n",
    "\n",
    "        # Run through each batch\n",
    "        for images, _ in tqdm(train_loader, desc='Training', unit=' batch'):\n",
    "            # Move data into the GPU\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calc loss\n",
    "            generated_images = model(images)\n",
    "            loss = loss_function(generated_images, images)\n",
    "\n",
    "            # Calc gradient and step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                avg_training_loss += loss.item()\n",
    "\n",
    "        # Set up for calculating testing loss\n",
    "        avg_training_loss /=  len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        # Calc training loss\n",
    "        with torch.no_grad():\n",
    "            for test_images, _ in tqdm(test_loader, desc='Testing', unit=' batch'):\n",
    "                test_images = test_images.to(device)\n",
    "                generated_test_images = model(test_images)\n",
    "                \n",
    "                avg_testing_loss += loss_function(generated_test_images, test_images).item()\n",
    "\n",
    "        avg_testing_loss /=  len(test_loader)\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        print(\"\")\n",
    "\n",
    "        print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "        print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n",
    "\n",
    "    # Add end results to the lists\n",
    "    k_over_training_loss.append({\n",
    "        \"k\": k,\n",
    "        \"training_loss\": avg_training_loss \n",
    "    })\n",
    "\n",
    "    k_over_testing_loss.append({\n",
    "        \"k\": k,\n",
    "        \"testing_loss\": avg_testing_loss\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [d[\"k\"] for d in k_over_training_loss]\n",
    "train_loss = [d[\"training_loss\"] for d in k_over_training_loss]\n",
    "test_loss = [d[\"testing_loss\"] for d in k_over_testing_loss]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(ks, train_loss, label=\"Training Loss\")\n",
    "plt.plot(ks, test_loss, label=\"Testing Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"MNIST AutoEncoder: Bottleneck vs. Training/Testing Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47bdb94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor of the data will be....\\n\\ndata = {\\n    epoch: int\\n    training/testing loss: float\\n    model_name: str\\n}\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def freeze_module(m):\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "def unfreeze_module(m):\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "epoch_over_training_loss_per_model = []\n",
    "epoch_over_testing_loss_per_model = []\n",
    "\n",
    "'''\n",
    "For of the data will be....\n",
    "\n",
    "data = {\n",
    "    epoch: int\n",
    "    training/testing loss: float\n",
    "    model_name: str\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262febb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m optimal_k = \u001b[32m10\u001b[39m \u001b[38;5;66;03m# PLACEHOLDER\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Have reference\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m src_model = \u001b[43mmodel\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1. Untrained encoder not frozen\u001b[39;00m\n\u001b[32m      7\u001b[39m encoder_clean_unfrozen = MNIST_Auto_Encoder(optimal_k, hidden_layer_size=hidden_layer_size).to(device).encoder\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimal_k = 10 # PLACEHOLDER\n",
    "\n",
    "# Have reference\n",
    "src_model = model\n",
    "\n",
    "# 1. Untrained encoder not frozen\n",
    "encoder_clean_unfrozen = MNIST_Auto_Encoder(optimal_k, hidden_layer_size=hidden_layer_size).to(device).encoder\n",
    "\n",
    "# 2. Untrained encoder but frozen\n",
    "encoder_clean_frozen = MNIST_Auto_Encoder(optimal_k, hidden_layer_size=hidden_layer_size).to(device).encoder\n",
    "freeze_module(encoder_clean_frozen)\n",
    "unfreeze_module(encoder_clean_frozen[-1])\n",
    "\n",
    "# 3. Trained encoder not frozen\n",
    "encoder_trained_unfrozen = MNIST_Auto_Encoder(optimal_k, hidden_layer_size=hidden_layer_size).to(device).encoder\n",
    "encoder_trained_unfrozen.load_state_dict(src_model.encoder.state_dict())\n",
    "\n",
    "# 4. Trained encoder but frozen\n",
    "encoder_trained_frozen = MNIST_Auto_Encoder(optimal_k, hidden_layer_size=hidden_layer_size).to(device).encoder\n",
    "encoder_trained_frozen.load_state_dict(src_model.encoder.state_dict())\n",
    "\n",
    "freeze_module(encoder_trained_frozen)\n",
    "unfreeze_module(encoder_trained_frozen[-1])\n",
    "\n",
    "models = [encoder_clean_unfrozen, encoder_clean_unfrozen, encoder_trained_unfrozen, encoder_trained_frozen]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ceeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "\n",
    "print(f'######## Begin Training Encoders on bottleneck={optimal_k} ########')\n",
    "\n",
    "\n",
    "train_loader = data.DataLoader(training_set, \n",
    "                                batch_size=batch_size, \n",
    "                                shuffle=True,\n",
    "                                num_workers=5, \n",
    "                                pin_memory=True\n",
    "                            )\n",
    "\n",
    "test_loader = data.DataLoader(testing_set, \n",
    "                                batch_size=batch_size, \n",
    "                                shuffle=False,\n",
    "                                num_workers=5, \n",
    "                                pin_memory=True\n",
    "                            )\n",
    "\n",
    "for sample_model, model_name in zip(models, ['Unfrozen Clean Encoder', 'Frozen Clean Encoder', 'Unfrozen Pretrained Encoder', 'Frozen Pretrained Encoder']):\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(sample_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "        # Per epoch reset accumulated loss\n",
    "        avg_training_loss = 0\n",
    "        avg_testing_loss = 0\n",
    "\n",
    "        # Run through each batch\n",
    "        for images, labels in tqdm(train_loader, desc='Training', unit=' batch'):\n",
    "            # Move data into the GPU\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calc loss\n",
    "            logits = sample_model(images)\n",
    "            loss = loss_function(logits, labels)\n",
    "\n",
    "            # Calc gradient and step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                avg_training_loss += loss.item()\n",
    "\n",
    "        # Set up for calculating testing loss\n",
    "        avg_training_loss /=  len(train_loader)\n",
    "\n",
    "        sample_model.eval()\n",
    "\n",
    "        # Calc training loss\n",
    "        with torch.no_grad():\n",
    "            for test_images, labels in tqdm(test_loader, desc='Testing', unit=' batch'):\n",
    "                test_images = test_images.to(device)\n",
    "                logits = sample_model(test_images)\n",
    "                \n",
    "                avg_testing_loss += loss_function(logits, labels).item()\n",
    "\n",
    "        avg_testing_loss /=  len(test_loader)\n",
    "\n",
    "        sample_model.train()\n",
    "        \n",
    "        print(\"\")\n",
    "\n",
    "        print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "        print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n",
    "\n",
    "        # Add end results to the lists\n",
    "        epoch_over_training_loss_per_model.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"training_loss\": avg_training_loss,\n",
    "            \"model_name\": model_name\n",
    "        })\n",
    "\n",
    "        epoch_over_testing_loss_per_model.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"training_loss\": avg_training_loss,\n",
    "            \"model_name\": model_name\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2150c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f663ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset_full_CIFAR10 = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=tfm)\n",
    "testset_full_CIFAR10  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8295131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_Classifier(nn.Module):\n",
    "    def __init__(self, C_dropout, F_dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        conv2d_dropout = C_dropout\n",
    "\n",
    "        conv_layer_1 = 30\n",
    "        conv_layer_2 = 64\n",
    "        \n",
    "        conv_layer_3 = 128\n",
    "        conv_layer_4 = 256\n",
    "\n",
    "        self.forward_funnel_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=conv_layer_1, kernel_size=5),   # Extract useful features from the beginning\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=conv_layer_1, out_channels=conv_layer_2, kernel_size=3),  # Extract useful features from the learned features\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                       # Reduce dimensionality\n",
    "        )\n",
    "\n",
    "        self.forward_funnel_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=conv_layer_2, out_channels=conv_layer_3, kernel_size=3),   # Extract useful features from the beginning\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=conv_layer_3, out_channels=conv_layer_4, kernel_size=3),  # Extract useful features from the learned features\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Compute the number of features after the input has passed the funnel\n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, 3, 32, 32)\n",
    "\n",
    "            test_input.to(device)\n",
    "\n",
    "            features = self.forward_funnel_1(test_input)\n",
    "            features = self.forward_funnel_2(features)\n",
    "\n",
    "            total_count = features.view(1, -1).size(1)\n",
    "\n",
    "        full_node_dropout = F_dropout\n",
    "        self.output_nodes = 100\n",
    "\n",
    "        self.classifer = nn.Sequential(\n",
    "            nn.Flatten(),                                           # Flatten the image from the funnel\n",
    "            nn.Linear(in_features=total_count, out_features=1000), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=1000, out_features=500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=500, out_features=250),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=250, out_features=self.output_nodes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(in_features=self.output_nodes, out_features=10)\n",
    "    \n",
    "    def partial_forward(self, x):\n",
    "        x = self.forward_funnel_1(x)\n",
    "        x = self.forward_funnel_2(x)\n",
    "        x = self.classifer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.partial_forward(x)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d588522c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nForm of the data\\n\\ndata = \\n{\\n    epoch: int\\n    training/testing loss: float\\n}\\n'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_over_training_loss_CIFAR10 = []\n",
    "epoch_over_testing_loss_CIFAR10 = []\n",
    "\n",
    "'''\n",
    "Form of the data\n",
    "\n",
    "data = \n",
    "{\n",
    "    epoch: int\n",
    "    training/testing loss: float\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b6d8d1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Begining training for CIFAR10 classifier ##########\n",
      "----- Epoch: 1/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 73.15 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 113.78 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.9835\n",
      "\n",
      "   -> Testing Loss:  1.6358\n",
      "\n",
      "----- Epoch: 2/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 71.95 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 121.53 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.6406\n",
      "\n",
      "   -> Testing Loss:  1.4000\n",
      "\n",
      "----- Epoch: 3/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 77.58 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 121.37 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.4772\n",
      "\n",
      "   -> Testing Loss:  1.2939\n",
      "\n",
      "----- Epoch: 4/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 74.20 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 114.75 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.3731\n",
      "\n",
      "   -> Testing Loss:  1.2180\n",
      "\n",
      "----- Epoch: 5/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 76.93 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 122.03 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.2839\n",
      "\n",
      "   -> Testing Loss:  1.1045\n",
      "\n",
      "----- Epoch: 6/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 77.05 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 119.01 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.2103\n",
      "\n",
      "   -> Testing Loss:  1.0442\n",
      "\n",
      "----- Epoch: 7/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 75.09 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 120.31 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.1515\n",
      "\n",
      "   -> Testing Loss:  1.0042\n",
      "\n",
      "----- Epoch: 8/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 75.91 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 120.32 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.0890\n",
      "\n",
      "   -> Testing Loss:  0.9703\n",
      "\n",
      "----- Epoch: 9/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 77.46 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 122.87 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  1.0346\n",
      "\n",
      "   -> Testing Loss:  0.9094\n",
      "\n",
      "----- Epoch: 10/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 77.76 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 119.10 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.9870\n",
      "\n",
      "   -> Testing Loss:  0.8829\n",
      "\n",
      "----- Epoch: 11/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 77.17 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 117.74 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.9384\n",
      "\n",
      "   -> Testing Loss:  0.8758\n",
      "\n",
      "----- Epoch: 12/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 75.07 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 113.31 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.9021\n",
      "\n",
      "   -> Testing Loss:  0.8511\n",
      "\n",
      "----- Epoch: 13/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 74.11 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 113.70 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.8649\n",
      "\n",
      "   -> Testing Loss:  0.8256\n",
      "\n",
      "----- Epoch: 14/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 77.53 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 122.93 batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.8303\n",
      "\n",
      "   -> Testing Loss:  0.8115\n",
      "\n",
      "----- Epoch: 15/15 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [00:10<00:00, 78.07 batch/s]\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 122.39 batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   -> Training Loss:  0.7996\n",
      "\n",
      "   -> Testing Loss:  0.8072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter setup\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "learning_rate = 5e-4\n",
    "decay_rate = 4e-4\n",
    "\n",
    "c_dropout = 0.25\n",
    "f_dropout = 0.25\n",
    "\n",
    "print('######## Begining training for CIFAR10 classifier ##########')\n",
    "\n",
    "# Setup data loaders\n",
    "trainset_loader_CIFAR10 = data.DataLoader(trainset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   # num_workers=5,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "testset_loader_CIFAR10 = data.DataLoader(testset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   # num_workers=5,\n",
    "                                   shuffle=False,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "model = CIFAR10_Classifier(c_dropout, f_dropout)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), \n",
    "                       lr=learning_rate, \n",
    "                       weight_decay=decay_rate\n",
    "                       )\n",
    "\n",
    "# Have references to variables outside of the epoch loop\n",
    "avg_training_loss = 0\n",
    "avg_testing_loss = 0\n",
    "\n",
    "# Epoch Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "    \n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for x, Y in tqdm(trainset_loader_CIFAR10, desc='Training', unit=' batch'):\n",
    "        # Transfer images to GPU\n",
    "        x = x.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Send images to model\n",
    "        x_pred = model(x)\n",
    "\n",
    "        # Calc loss\n",
    "        loss = loss_function(x_pred, Y)\n",
    "\n",
    "        # Calc gradient and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_training_loss += loss.item()\n",
    "\n",
    "    # Switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, Y in tqdm(testset_loader_CIFAR10, desc='Testing', unit=' batches'):\n",
    "            # Move the images to the GPU\n",
    "            x = x.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            # Get logits and sum up total loss\n",
    "            x_pred = model(x)\n",
    "            avg_testing_loss += loss_function(x_pred, Y).item()\n",
    "\n",
    "    # Get training loss\n",
    "    avg_training_loss /= len(trainset_loader_CIFAR10)\n",
    "\n",
    "     # Get testing loss\n",
    "    avg_testing_loss /= len(testset_loader_CIFAR10)\n",
    "\n",
    "    # Switch model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    epoch_over_training_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"training_loss\": avg_training_loss\n",
    "        })\n",
    "    \n",
    "    epoch_over_testing_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"testing_loss\": avg_testing_loss\n",
    "        })\n",
    "    \n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "    print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "75e63add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.7297\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in testset_loader_CIFAR10:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total += yb.numel()\n",
    "\n",
    "final_accuracy = float(correct / total)\n",
    "\n",
    "print(f\"Final Accuracy: {final_accuracy}\")\n",
    "\n",
    "epochs = [d[\"epoch\"] for d in epoch_over_training_loss_CIFAR10]\n",
    "train_loss = [d[\"training_loss\"] for d in epoch_over_training_loss_CIFAR10]\n",
    "test_loss = [d[\"testing_loss\"] for d in epoch_over_testing_loss_CIFAR10]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_loss, label=\"Training Loss\")\n",
    "plt.plot(epochs, test_loss, label=\"Testing Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"CIFAR10 Classifer: Training and Testing Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a605f5ad",
   "metadata": {},
   "source": [
    "#### Results \n",
    "\n",
    "Testing Accuracy: 72.97%\n",
    "\n",
    "Training Loss: 0.7996\n",
    "\n",
    "Testing Loss: 0.8072\n",
    "\n",
    "#### Final Model Hyperparameters\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 5e-4\n",
    "\n",
    "decay_rate = 4e-4\n",
    "\n",
    "c_dropout = 0.25\n",
    "\n",
    "f_dropout = 0.25\n",
    "\n",
    "\n",
    "#### Model Architecture 1\n",
    "\n",
    "In the beginning, I decided that I wanted to have two convolutional layers, one that extracted a lot of features from the image data and one that found more advanced features. Since the first layer would find as many initial features to start, I decided to make the out channel 128 and kernel size 5x5. Then, the second layer would condense those features, so I chose an out channel size of 64 and kernel size of 3x3. Additionally, I stacked 4 decreasing, funneling, fully-connected layers, 1000 -> 1000 -> 500 -> 100, that finally connected to the output layer. My reasoning was that doing this would allow me to find complex features that would become more and more concentrated and meaningful. Finally, I added a max pooling layer after the convolutional layers to help reduce dimensionality of the data and dropout layers after every layer to prevent overfitting. \n",
    "\n",
    "#### Optimizer\n",
    "I went with Adam since I wanted to experiment with using different options. Furthermore, I wanted my loss to be as low as possible, so I wanted to use weight decay. As such, the final optimizer I used was AdamW since it handles weight decay better.\n",
    "\n",
    "#### Initial training\n",
    "\n",
    "I started with initial hyperparamters of batch_size = 64, learning_rate = 1e-3, decay_rate = 5e-4 (weight decay), c_dropout = 0.40 (the dropout probability for each convolutional layer), and f_dropout = 0.60 (the dropout probability for each fully-connected layer). After the first training, I noticed that my losses were not really good for this data set, training loss ~= 1.3 and testing loss ~= 1.25. Specially, they could never get past the 1.2 barrier and started to stagnate at the 14th epoch. Since I did not think overfitting was an issue yet, I decided to tweak the learning rate from 1e-3 to 5e-4.\n",
    "\n",
    "In the second trial, I noticed that the issue of the model not being able to learn was still present, losses similar to the first trial, so I thought the maybe my dropout p's were a bit too high. This caused me to set both of them to 0.4.\n",
    "\n",
    "In my next training attempt, I saw I was able to break past the 1.2 loss barrier by the 10th epoch which solidified my reasoning that my p's were too high, but I was unable to get a testing loss lower than ~1.10 after the 15th epoch. However, I did notice that model was still learning well, it was able to get training loss lower than 1.10, so I decided that I should try changing the weight decay to 4e-4 to see if it would help. I did not increase the weight decay since I thought that would cause my losses to be greater since I was already using a good amount of dropout.\n",
    "\n",
    "For the fourth trial, I saw that I got similar testing loss, ~1.08, so I decided to try changing the other hyperparameters. Yet, no matter which ones I tried to change, I was unable to break the testing loss = 1.00 barrier, even though the model was learning well beyond that point. This led me to think that my architecture was a bit too complex, so I decided to rethink of what I was doing and change my model.\n",
    "\n",
    "#### Model Architecture 2\n",
    "\n",
    "For this iteration of the model, I decided to change the number of channels in my convolutional layers from 128 -> 64 to 30 -> 64. This happened because I decided to look at the image size which is 32x32 and realized that I might be trying to find too many features in the beginning but then sampling them down too much in the second layer. Instead, it would probably be better to find fewer initial features and then find complex relationships between them in the second convolutional layer. The second major change I made was making the fully-connected layers continously decreasing from 1000 -> 1000 -> 500 -> 100 to 1000 -> 500 -> 250 -> 100 since I wanted to downscale the model.\n",
    "\n",
    "#### Training for Second Model\n",
    "\n",
    "I decided to keep the hyperparameters that I obtained from the initial model since I thought they might work well with this new model, batch_size = 64, learning_rate = 5e-4, and decay_rate = 4e-4. However, I chose to decrease the dropouts both to 0.25 since I wanted to start at a new, lower point and tweak the dropout as I trained this new model.\n",
    "\n",
    "For the first training attempt, my model performed way better than the first model both in terms of speed and accuracy since it was able to get training loss ~= 0.9 and testing loss ~= 0.89 at the 5th epoch. Beyond that point though, the model started overfitting severally and could not get past the testing loss being ~0.89. From this point owards, I tried tweaking the other hyperparameters but no matter what I changed and how I changed it. I could never get a testing loss beyond 0.9. This lead me to the conclusion that my model needed to be changed once again.\n",
    "\n",
    "#### Model Architecture 3\n",
    "\n",
    "For this model, I decided to add more convolutional layers plus an additional max pooling layer since the features that they can extract would be more useful compared to just plain fully-connected layers. As such, this model mirrors the second model but the initial convolution layers were changed from 30 -> 64 to 30 -> 64 -> 128 -> 256. I chose to make the channels increase since I thought that it would be better to learn more and more complex combinations of the initial features rather than trying to funnel them down. However, the pooling layer would help with funneling the features anyways, so it would be better to not do that inside of the convolutional layers themselves. These new layers also have kernel size 3x3.\n",
    "\n",
    "#### Training for Third Model\n",
    "\n",
    "With the optimal hyperparameters from the second model, batch_size = 64, learning_rate = 5e-4, decay_rate = 4e-4, c_dropout = 0.25, and f_dropout = 0.25, I was able to finally break the loss barrier and achieve a testing loss ~= 0.80 at the 15th epoch. Sadly, tuning the hyperparameters did not result in any new finds which makes me think that to get better accuracy, I would need to append more and more convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ccfc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_Transformed_Classifier(CIFAR10_Classifier):\n",
    "    def __init__(self, C_dropout, F_dropout):\n",
    "        super().__init__(C_dropout, F_dropout)\n",
    "        \n",
    "        self.output_layer = nn.Linear(in_features=self.output_nodes, out_features=2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.partial_forward(x)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50be51ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_over_training_loss_CIFAR10_R = []\n",
    "epoch_over_testing_loss_CIFAR10_R = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bfa844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter setup\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "decay_rate = 1e-4\n",
    "\n",
    "c_dropout = 0.40\n",
    "f_dropout = 0.50\n",
    "\n",
    "\n",
    "print('######## Begining training for CIFAR10 classifier on rotated images ##########')\n",
    "\n",
    "# Setup data loaders\n",
    "trainset_loader_CIFAR10_R = data.DataLoader(trainset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   # num_workers=5,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "testset_loader_CIFAR10_R = data.DataLoader(testset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   # num_workers=5,\n",
    "                                   shuffle=False,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "model = CIFAR10_Transformed_Classifier(c_dropout, f_dropout)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), \n",
    "                       lr=learning_rate, \n",
    "                       weight_decay=decay_rate\n",
    "                       )\n",
    "\n",
    "# Have references to variables outside of the epoch loop\n",
    "avg_training_loss = 0\n",
    "avg_testing_loss = 0\n",
    "\n",
    "# Epoch Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "    \n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for x, _ in tqdm(trainset_loader_CIFAR10_R, desc='Training', unit=' batch'):\n",
    "\n",
    "        labels_upright = torch.zeros(x.size(0), dtype=torch.long)\n",
    "\n",
    "        images_rotated = torch.rot90(x, 1, [2, 3])\n",
    "        labels_rotated = torch.ones(x.size(0), dtype=torch.long)\n",
    "\n",
    "        all_images = torch.cat([x, images_rotated])\n",
    "        all_labels = torch.cat([labels_upright, labels_rotated])\n",
    "        \n",
    "        \n",
    "        # Transfer images to GPU\n",
    "        all_images = all_images.to(device)\n",
    "        all_labels = all_labels.to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Send images to model\n",
    "        x_pred = model(all_images)\n",
    "\n",
    "        # Calc loss\n",
    "        loss = loss_function(x_pred, all_labels)\n",
    "\n",
    "        # Calc gradient and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_training_loss += loss\n",
    "\n",
    "    # Switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in tqdm(testset_loader_CIFAR10_R, desc='Testing', unit=' batches'):\n",
    "            \n",
    "            labels_upright = torch.zeros(x.size(0), dtype=torch.long)\n",
    "\n",
    "            images_rotated = torch.rot90(x, 1, [2, 3])\n",
    "            labels_rotated = torch.ones(x.size(0), dtype=torch.long)\n",
    "\n",
    "            all_images = torch.cat([x, images_rotated])\n",
    "            all_labels = torch.cat([labels_upright, labels_rotated])\n",
    "            \n",
    "            # Transfer images to GPU\n",
    "            all_images = all_images.to(device)\n",
    "            all_labels = all_labels.to(device)\n",
    "            \n",
    "            # Move the images to the GPU\n",
    "            all_images = all_images.to(device)\n",
    "            all_labels = all_labels.to(device)\n",
    "\n",
    "            # Get logits and sum up total loss\n",
    "            x_pred = model(all_images)\n",
    "            avg_testing_loss += loss_function(x_pred, all_labels).item()\n",
    "\n",
    "    # Get training loss\n",
    "    avg_training_loss /= len(trainset_loader_CIFAR10)\n",
    "\n",
    "     # Get testing loss\n",
    "    avg_testing_loss /= len(testset_loader_CIFAR10)\n",
    "\n",
    "    # Switch model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    epoch_over_training_loss_CIFAR10_R.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"training_loss\": avg_training_loss\n",
    "        })\n",
    "    \n",
    "    epoch_over_testing_loss_CIFAR10_R.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"testing_loss\": avg_testing_loss\n",
    "        })\n",
    "    \n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "    print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3443e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights from problem 5\n",
    "torch.save(model.state_dict(), 'Q4_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = total = 0\n",
    "with torch.no_grad():\n",
    "    for x, _ in testset_loader_CIFAR10_R:\n",
    "        \n",
    "        labels_upright = torch.zeros(x.size(0), dtype=torch.long)\n",
    "\n",
    "        images_rotated = torch.rot90(x, 1, [2, 3])\n",
    "        labels_rotated = torch.ones(x.size(0), dtype=torch.long)\n",
    "\n",
    "        all_images = torch.cat([x, images_rotated])\n",
    "        all_labels = torch.cat([labels_upright, labels_rotated])\n",
    "        \n",
    "        # Transfer images to GPU\n",
    "        all_images = all_images.to(device)\n",
    "        all_labels = all_labels.to(device)\n",
    "        \n",
    "        # Move the images to the GPU\n",
    "        all_images = all_images.to(device)\n",
    "        all_labels = all_labels.to(device)\n",
    "\n",
    "        # Get logits and sum up total loss\n",
    "        logits = model(all_images)\n",
    "        \n",
    "        pred = logits.argmax(1)\n",
    "        \n",
    "        correct += (pred == all_labels).sum().item()\n",
    "        total += all_labels.numel()\n",
    "\n",
    "final_accuracy = float(correct / total)\n",
    "\n",
    "print(f\"Final Accuracy: {final_accuracy}\")\n",
    "\n",
    "\n",
    "epochs = [d[\"epoch\"] for d in epoch_over_training_loss_CIFAR10_R]\n",
    "train_loss = [d[\"training_loss\"] for d in epoch_over_training_loss_CIFAR10_R]\n",
    "test_loss = [d[\"testing_loss\"] for d in epoch_over_testing_loss_CIFAR10_R]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_loss, label=\"Training Loss\")\n",
    "plt.plot(epochs, test_loss, label=\"Testing Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"CIFAR10 Rotation Classifer: Training and Testing Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2396329",
   "metadata": {},
   "source": [
    "Results\n",
    "\n",
    "---\n",
    "\n",
    "Training Loss = \n",
    "\n",
    "Testing Loss = \n",
    "\n",
    "Final Testing Loss = \n",
    "\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "decay_rate = 5e-4\n",
    "\n",
    "\n",
    "c_dropout = 0.40\n",
    "\n",
    "f_dropout = 0.50\n",
    "\n",
    "---\n",
    "\n",
    "Initially, I decided to start with the same hyperparameters as the final model in Question 3 just to see what the current losses were looking like. As a result, I was able to get a training and testing loss around 0.38. Though in this run, I decided to end the training early since I noticed that the model was overtraining starting from the 14th epoch and beyond.\n",
    "\n",
    "Noticing the issue of overtraining, I decided to switch to the AdamW optimizer since it handles weight decay better. However, I still got similar results at the 14th epoch. Instead of focusining on changing the optimizer, I decided to try and change the dropout percentages. \n",
    "\n",
    "In the third trial, I changed the dropout rates from 0.3, convolutional dropout, to 0.4 which allowed me to achieve a better training loss around 0.33 and testing loss around 0.31. During this run, I noticed that the model began to learn slower by the 10th epoch and then began overtraining by the 14th epoch. \n",
    "\n",
    "For the forth attempt, I tried to increase the learning rate from 7.5e-5 to 1e-4 and sadly did not see any better results by the time the model started overtraining at the 14 epoch, however, I was able to achieve similar losses around 0.31.\n",
    "\n",
    "On the fifth trial, I decided that the model learning rate was being affected by the dropout rate on the fully connected layer, so I decreased it to 0.50. This allowed me to get a training loss around 0.301 and testing loss around 0.297 at the 14th epoch. The decrease in loss was nice, but I still needed to deal with overtraining since the model could never get past this testing loss barrier at around 0.29.\n",
    "\n",
    "On the sixth run, I wanted to experiment with a higher weight decay rate, increased from 5e-4 to 7.5e-4, but this resulted in my model starting to overtrain at the 15th epoch with a min testing loss of 0.3032. Though, I still wanted to see if it would be wise to tinker with the decay rate, so I instead decreased it to 2.5e-4 on the 7th run which gave me the same issue of overtraining past the 15th epoch and a final testing loss of around 0.29.\n",
    "\n",
    "At this point, I believed that I have found the most optimal hyperparameters for my model based on the current architecture, so I did one final training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96a5475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weights(model_final, model_src, k, is_frozen):\n",
    "    \n",
    "    for i in range(len(model_final.forward_funnel_1)):\n",
    "\n",
    "        if k == 0: return\n",
    "\n",
    "        src_layer = model_src.forward_funnel_1[i]\n",
    "        final_layer = model_final.forward_funnel_1[i]\n",
    "\n",
    "        if (hasattr(src_layer, 'weight') and hasattr(final_layer, 'weight')):\n",
    "            final_layer.weight.data = src_layer.weight.data.clone()\n",
    "            if is_frozen:\n",
    "                final_layer.weight.requires_grad = False\n",
    "            \n",
    "            # This will always run if we get here. I do not intend on making layers with biases\n",
    "            if (hasattr(src_layer, 'bias') and hasattr(final_layer, 'bias')):\n",
    "                final_layer.bias.data = src_layer.bias.data.clone()\n",
    "                if is_frozen:\n",
    "                    final_layer.bias.requires_grad = False\n",
    "\n",
    "                k -= 1\n",
    "\n",
    "    \n",
    "    for i in range(len(model_final.classifer)):\n",
    "        \n",
    "        if k == 0: return\n",
    "\n",
    "        src_layer = model_src.classifer[i]\n",
    "        final_layer = model_final.classifer[i]\n",
    "\n",
    "        if (hasattr(src_layer, 'weight') and hasattr(final_layer, 'weight')):\n",
    "            final_layer.weight.data = src_layer.weight.data.clone()\n",
    "            if is_frozen:\n",
    "                final_layer.weight.requires_grad = False\n",
    "            \n",
    "            # This will always run if we get here. I do not intend on making layers with biases\n",
    "            if (hasattr(src_layer, 'bias') and hasattr(final_layer, 'bias')):\n",
    "                final_layer.bias.data = src_layer.bias.data.clone()\n",
    "                if is_frozen:\n",
    "                    final_layer.bias.requires_grad = False\n",
    "\n",
    "                k -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da72851a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor of the data for this list is...\\n\\ndata = {\\n    k: int\\n    epoch: int\\n    training/testing loss: floats\\n    frozen: True or False\\n}\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_over_training_loss_CIFAR10_per_k = []\n",
    "epoch_over_testing_loss_CIFAR10_per_k = []\n",
    "\n",
    "'''\n",
    "For of the data for this list is...\n",
    "\n",
    "data = {\n",
    "    k: int\n",
    "    epoch: int\n",
    "    training/testing loss: floats\n",
    "    frozen: True or False\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1dea2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Q4_model_weights.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Initialize model for the sake of weight transfer\u001b[39;00m\n\u001b[32m     13\u001b[39m src_model = CIFAR10_Classifier(c_dropout, f_dropout)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m src_model.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mQ4_model_weights.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m######## Begining training for CIFAR10 classifier + transfer learning ##########\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m current_k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, k, \u001b[32m1\u001b[39m):\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Setup data loaders\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mukad\\Desktop\\Projects and Related Work\\Intro-to-Deep-Learning-Projects\\Project 2\\.venv\\Lib\\site-packages\\torch\\serialization.py:1425\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1423\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1427\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1428\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1429\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1430\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mukad\\Desktop\\Projects and Related Work\\Intro-to-Deep-Learning-Projects\\Project 2\\.venv\\Lib\\site-packages\\torch\\serialization.py:751\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    750\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mukad\\Desktop\\Projects and Related Work\\Intro-to-Deep-Learning-Projects\\Project 2\\.venv\\Lib\\site-packages\\torch\\serialization.py:732\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Q4_model_weights.pth'"
     ]
    }
   ],
   "source": [
    "# Hyperparameter setup\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "decay_rate = 1e-4\n",
    "\n",
    "c_dropout = 0.40\n",
    "f_dropout = 0.50\n",
    "\n",
    "k = 5 # Max number of layers for the current model ~~ Excluding the output layer\n",
    "\n",
    "# Initialize model for the sake of weight transfer\n",
    "src_model = CIFAR10_Transformed_Classifier(c_dropout, f_dropout)\n",
    "src_model.load_state_dict(torch.load('Q4_model_weights.pth'))\n",
    "\n",
    "\n",
    "print('######## Begining training for CIFAR10 classifier + transfer learning ##########')\n",
    "\n",
    "for i in range(2):\n",
    "    \n",
    "    is_frozen = False if i == 0 else True\n",
    "    \n",
    "    for current_k in range(1, k, 1):\n",
    "        # Setup data loaders\n",
    "        trainset_loader_CIFAR10 = data.DataLoader(trainset_full_CIFAR10,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=True,\n",
    "                                        # num_workers=5,\n",
    "                                        pin_memory=True)\n",
    "\n",
    "        testset_loader_CIFAR10 = data.DataLoader(testset_full_CIFAR10,\n",
    "                                        batch_size=batch_size,\n",
    "                                        # num_workers=5,\n",
    "                                        shuffle=False,\n",
    "                                        pin_memory=True)\n",
    "\n",
    "        model_final = CIFAR10_Classifier(c_dropout, f_dropout)\n",
    "\n",
    "        transfer_weights(model_final, src_model, k, is_frozen)\n",
    "\n",
    "        model_final.to(device)\n",
    "\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model_final.parameters(), \n",
    "                            lr=learning_rate, \n",
    "                            weight_decay=decay_rate\n",
    "                            )\n",
    "\n",
    "        # Have references to variables outside of the epoch loop\n",
    "        avg_training_loss = 0\n",
    "        avg_testing_loss = 0\n",
    "\n",
    "        # Epoch Loop\n",
    "        for epoch in range(epochs):\n",
    "            print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "            \n",
    "            avg_training_loss = 0\n",
    "            avg_testing_loss = 0\n",
    "\n",
    "            model_final.train()\n",
    "\n",
    "            for x, _ in tqdm(trainset_loader_CIFAR10, desc='Training', unit=' batch'):\n",
    "\n",
    "                labels_upright = torch.zeros(x.size(0), dtype=torch.long)\n",
    "\n",
    "                images_rotated = torch.rot90(x, 1, [2, 3])\n",
    "                labels_rotated = torch.ones(x.size(0), dtype=torch.long)\n",
    "\n",
    "                all_images = torch.cat([x, images_rotated])\n",
    "                all_labels = torch.cat([labels_upright, labels_rotated])\n",
    "                \n",
    "                \n",
    "                # Transfer images to GPU\n",
    "                all_images = all_images.to(device)\n",
    "                all_labels = all_labels.to(device)\n",
    "\n",
    "                # Zero out gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Send images to model\n",
    "                x_pred = model_final(all_images)\n",
    "\n",
    "                # Calc loss\n",
    "                loss = loss_function(x_pred, all_labels)\n",
    "\n",
    "                # Calc gradient and update weights\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    avg_training_loss += loss\n",
    "\n",
    "            # Switch to eval mode\n",
    "            model_final.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for x, _ in tqdm(testset_loader_CIFAR10, desc='Testing', unit=' batches'):\n",
    "                    \n",
    "                    labels_upright = torch.zeros(x.size(0), dtype=torch.long)\n",
    "\n",
    "                    images_rotated = torch.rot90(x, 1, [2, 3])\n",
    "                    labels_rotated = torch.ones(x.size(0), dtype=torch.long)\n",
    "\n",
    "                    all_images = torch.cat([x, images_rotated])\n",
    "                    all_labels = torch.cat([labels_upright, labels_rotated])\n",
    "                    \n",
    "                    # Transfer images to GPU\n",
    "                    all_images = all_images.to(device)\n",
    "                    all_labels = all_labels.to(device)\n",
    "                    \n",
    "                    # Move the images to the GPU\n",
    "                    all_images = all_images.to(device)\n",
    "                    all_labels = all_labels.to(device)\n",
    "\n",
    "                    # Get logits and sum up total loss\n",
    "                    x_pred = model_final(all_images)\n",
    "                    avg_testing_loss += loss_function(x_pred, all_labels).item()\n",
    "\n",
    "            # Get training loss\n",
    "            avg_training_loss /= len(trainset_loader_CIFAR10)\n",
    "\n",
    "            # Get testing loss\n",
    "            avg_testing_loss /= len(testset_loader_CIFAR10)\n",
    "\n",
    "            # Switch model back to training mode\n",
    "            model_final.train()\n",
    "\n",
    "            epoch_over_training_loss_CIFAR10_per_k.append({\n",
    "                \"k\": current_k,\n",
    "                \"epoch\": epoch,\n",
    "                \"training_loss\": avg_training_loss\n",
    "                })\n",
    "            \n",
    "            epoch_over_testing_loss_CIFAR10_per_k.append({\n",
    "                \"k\": current_k,\n",
    "                \"epoch\": epoch,\n",
    "                \"training_loss\": avg_training_loss\n",
    "                })\n",
    "            \n",
    "\n",
    "            print(\"\")\n",
    "\n",
    "            print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "            print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4754fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate frozen and unfrozen runs\n",
    "for frozen_status, title in zip([True, False], [\"Frozen Transfer Learning\", \"Unfrozen Transfer Learning\"]):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ks = sorted(set(d[\"k\"] for d in epoch_over_training_loss if d[\"frozen\"] == frozen_status))\n",
    "    for k in ks:\n",
    "        epochs = [d[\"epoch\"] for d in epoch_over_training_loss if d[\"k\"] == k and d[\"frozen\"] == frozen_status]\n",
    "        train_loss = [d[\"training_loss\"] for d in epoch_over_training_loss if d[\"k\"] == k and d[\"frozen\"] == frozen_status]\n",
    "        test_loss = [d[\"training_loss\"] for d in epoch_over_testing_loss if d[\"k\"] == k and d[\"frozen\"] == frozen_status]\n",
    "        plt.plot(epochs, train_loss, label=f\"Train k={k}\")\n",
    "        plt.plot(epochs, test_loss, '--', label=f\"Test k={k}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(title + \": Epoch vs. Loss (per k)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e40d68a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_Encoder(CIFAR10_Classifier):\n",
    "    def __init__(self, C_dropout, F_dropout, embedding_size=2):\n",
    "        super().__init__(C_dropout, F_dropout)\n",
    "\n",
    "        self.output_layer = nn.Linear(in_features=self.output_nodes, out_features=embedding_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.partial_forward(x)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d348d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveCIFAR10(data.Dataset):\n",
    "    def __init__(self, base_dataset):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.labels = np.array(self.base_dataset.targets)\n",
    "\n",
    "        # Pre-compute a dictionary mapping each class to a list of its indices\n",
    "        self.labels_to_indices = {label: np.where(self.labels == label)[0]\n",
    "                                  for label in set(self.labels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the anchor image and its label\n",
    "        img1, label1 = self.base_dataset[index]\n",
    "\n",
    "        # Decide whether to sample a positive or negative pair (50% chance)\n",
    "        is_similar = random.random() > 0.5\n",
    "\n",
    "        if is_similar:\n",
    "            # Positive pair: sample another image from the same class\n",
    "            positive_indices = self.labels_to_indices[label1]\n",
    "            # Make sure we don't pick the same image\n",
    "            positive_index = index\n",
    "            while positive_index == index:\n",
    "                positive_index = np.random.choice(positive_indices)\n",
    "            img2, _ = self.base_dataset[positive_index]\n",
    "            similarity = 1.0 # Similarity label is 1 for positive pairs\n",
    "        else:\n",
    "            # Negative pair: sample an image from a different class\n",
    "            negative_label = np.random.choice(list(set(self.labels) - {label1}))\n",
    "            negative_indices = self.labels_to_indices[negative_label]\n",
    "            negative_index = np.random.choice(negative_indices)\n",
    "            img2, _ = self.base_dataset[negative_index]\n",
    "            similarity = 0.0 # Similarity label is 0 for negative pairs\n",
    "\n",
    "        return img1, img2, torch.tensor(similarity, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf11b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, embedding1, embedding2, similarity_label):\n",
    "        # Calculate the euclidean distance squared between the embeddings\n",
    "        euclidean_distance = F.pairwise_distance(embedding1, embedding2, keepdim=True)\n",
    "        dist_sq = torch.pow(euclidean_distance, 2)\n",
    "\n",
    "        # Loss for similar pairs (S=1): we want their distance to be small\n",
    "        loss_similar = similarity_label * dist_sq\n",
    "\n",
    "        # Loss for dissimilar pairs (S=0): we want their distance to be large, at least > margin\n",
    "        # The loss is max(0, margin - distance)^2\n",
    "        loss_dissimilar = (1 - similarity_label) * torch.pow(\n",
    "            torch.clamp(self.margin - euclidean_distance, min=0.0), 2\n",
    "        )\n",
    "\n",
    "        # Combine the losses and average over the batch\n",
    "        total_loss = torch.mean(loss_similar + loss_dissimilar)\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea658b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_embeddings(model, loader):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            embs = model(images).cpu().numpy()\n",
    "            embeddings.append(embs)\n",
    "            all_labels.append(labels.numpy())\n",
    "    return np.concatenate(embeddings), np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b755285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(embeddings, labels, title=\"\"):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    class_names = trainset_full_CIFAR10.classes\n",
    "    for i in range(len(class_names)):\n",
    "        # Select embeddings that correspond to the current class\n",
    "        inds = np.where(labels == i)[0]\n",
    "        plt.scatter(embeddings[inds, 0], embeddings[inds, 1], alpha=0.5, label=class_names[i])\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae054d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Starting training of CIFAR10 embedding model ##########\n",
      "----- Epoch: 1/30 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/782 [00:00<?, ? batchs/s]"
     ]
    }
   ],
   "source": [
    "# Hyperparameter setup\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "learning_rate = 7.5e-5\n",
    "decay_rate = 5e-4\n",
    "\n",
    "c_dropout = 0.30\n",
    "f_dropout = 0.62\n",
    "\n",
    "embedding_model = CIFAR10_Encoder(c_dropout, f_dropout).to(device)\n",
    "contrastive_loss_fn = ContrastiveLoss(margin=1.0)\n",
    "optimizer = optim.Adam(embedding_model.parameters(), lr=learning_rate, weight_decay=decay_rate)\n",
    "\n",
    "contrastive_train_ds = ContrastiveCIFAR10(trainset_full_CIFAR10)\n",
    "contrastive_train_loader = data.DataLoader(contrastive_train_ds, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True)\n",
    "\n",
    "print(f'######## Starting training of CIFAR10 embedding model ##########')\n",
    "\n",
    "embedding_model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for img1, img2, sim in tqdm(contrastive_train_loader, desc='Training', unit=' batchs'):\n",
    "        img1, img2, sim = img1.to(device), img2.to(device), sim.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        emb1, emb2 = embedding_model(img1), embedding_model(img2)\n",
    "        loss = contrastive_loss_fn(emb1, emb2, sim)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"  -> [Contrastive] Epoch {epoch+1}/3 | Loss={running_loss/len(contrastive_train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d584a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_vis = data.DataLoader(testset_full_CIFAR10, batch_size=256, shuffle=False)\n",
    "\n",
    "final_embeddings, final_labels = get_all_embeddings(embedding_model, test_loader_vis)\n",
    "plot_embeddings(final_embeddings, final_labels, \"Embeddings After Training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

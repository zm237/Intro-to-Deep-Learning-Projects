{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3234c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for this project\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ea66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the MNIST dataset\n",
    "training_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testing_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "040f5af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "The system GPU | NVIDIA GeForce RTX 4060 Laptop GPU | is AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "# Verify that GPU is connected and available\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'The system GPU | {torch.cuda.get_device_name(0) if not None else 'Error'} | is {'AVAILABLE' if torch.cuda.is_available() else 'NOT AVAILABLE' }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c0c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Auto_Encoder(nn.Module):\n",
    "    def __init__(self, bottleneck, hidden_layer_size=784):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Defined number of features for the image\n",
    "        input_size=784\n",
    "\n",
    "        # Encoder section\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size, out_features=hidden_layer_size), # Input to hidden\n",
    "            nn.ReLU(inplace=True),                                             # Activation Function\n",
    "            nn.Linear(in_features=hidden_layer_size, out_features=bottleneck)  # Hidden to bottleneck\n",
    "        )\n",
    "\n",
    "        # Decoder Section\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=bottleneck, out_features=hidden_layer_size), # Bottleneck to hidden\n",
    "            nn.ReLU(inplace=True),                                             # Activation Function\n",
    "            nn.Linear(in_features=hidden_layer_size, out_features=input_size), # Hidden to output\n",
    "            nn.Sigmoid(inplace=True)                                           # Force output pixels to be between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        \n",
    "        # Extract batch size and resize input into the nn\n",
    "        batch_size = x.size(0)\n",
    "        x_flattened = x.view(batch_size, -1)\n",
    "\n",
    "        # Encode then decode the input\n",
    "        x_encoded = self.encoder(x_flattened)\n",
    "        x_decoded = self.decoder(x_encoded)\n",
    "\n",
    "        # Reshape decoded x for final result\n",
    "        x_predicted = x_decoded.view(batch_size, 1, 28, 28)\n",
    "        \n",
    "        return x_predicted\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63aac2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the data for this test\n",
    "k_over_training_loss = []\n",
    "k_over_testing_loss = [] \n",
    "\n",
    "\n",
    "epoch_over_training_loss = []\n",
    "epoch_over_testing_loss = []\n",
    "\n",
    "'''\n",
    "Data for the graph will be in the form of\n",
    "{\n",
    "    k: int\n",
    "    final_training/testing_loss: float\n",
    "}\n",
    "'''\n",
    "\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144822a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Question specific hyperparameters\n",
    "hidden_layer_size = 1000\n",
    "k_start = 748\n",
    "k_end = 0\n",
    "k_step = 160\n",
    "\n",
    "# Loop through each bottlenecks\n",
    "for k in range(k_start, k_end, k_step):\n",
    "    \n",
    "    print(f'########## With bottleneck = {k} ############')\n",
    "    \n",
    "    train_loader = data.DataLoader(training_set, \n",
    "                                    batch_size=batch_size, \n",
    "                                    shuffle=True,\n",
    "                                    num_workers=5, \n",
    "                                    pin_memory=True\n",
    "                               )\n",
    "    \n",
    "    test_loader = data.DataLoader(testing_set, \n",
    "                                    batch_size=batch_size, \n",
    "                                    shuffle=False,\n",
    "                                    num_workers=5, \n",
    "                                    pin_memory=True\n",
    "                               )\n",
    "\n",
    "    model = MNIST_Auto_Encoder(k, hidden_layer_size=hidden_layer_size)\n",
    "    model.to(device)\n",
    "\n",
    "    total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "    print(f' ~~ Total/Trainable Parameters: {total_params}')\n",
    "\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Have references to variables outside of the epoch loop\n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    # Epoch Loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "        # Per epoch reset accumulated loss\n",
    "        avg_training_loss = 0\n",
    "        avg_testing_loss = 0\n",
    "\n",
    "        # Run through each batch\n",
    "        for images, _ in tqdm(train_loader, desc='Training', unit=' batch'):\n",
    "            # Move data into the GPU\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calc loss\n",
    "            generated_images = model(images)\n",
    "            loss = loss_function(generated_images, images)\n",
    "\n",
    "            # Calc gradient and step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                avg_training_loss += loss.item()\n",
    "\n",
    "        # Set up for calculating testing loss\n",
    "        avg_training_loss /=  len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        # Calc training loss\n",
    "        with torch.no_grad():\n",
    "            for test_images, _ in tqdm(test_loader, desc='Testing', unit=' batch'):\n",
    "                test_images = test_images.to(device)\n",
    "                generated_test_images = model(test_images)\n",
    "                \n",
    "                avg_testing_loss += loss_function(generated_test_images, test_images).item()\n",
    "\n",
    "        avg_testing_loss /=  len(test_loader)\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        print(\"\")\n",
    "\n",
    "        print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "        print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n",
    "\n",
    "    # Add end results to the lists\n",
    "    k_over_training_loss.append({\n",
    "        \"k\": k,\n",
    "        \"training_loss\": avg_training_loss \n",
    "    })\n",
    "\n",
    "    k_over_testing_loss.append({\n",
    "        \"k\": k,\n",
    "        \"testing_loss\": avg_testing_loss\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [d[\"k\"] for d in k_over_training_loss]\n",
    "train_loss = [d[\"training_loss\"] for d in k_over_training_loss]\n",
    "test_loss = [d[\"testing_loss\"] for d in k_over_testing_loss]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(ks, train_loss, label=\"Training Loss\")\n",
    "plt.plot(ks, test_loss, label=\"Testing Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"MNIST AutoEncoder: Bottleneck vs. Training/Testing Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47bdb94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor of the data will be....\\n\\ndata = {\\n    epoch: int\\n    training/testing loss: float\\n    model_name: str\\n}\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def freeze_module(m):\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "def unfreeze_module(m):\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "epoch_over_training_loss_per_model = []\n",
    "epoch_over_testing_loss_per_model = []\n",
    "\n",
    "'''\n",
    "For of the data will be....\n",
    "\n",
    "data = {\n",
    "    epoch: int\n",
    "    training/testing loss: float\n",
    "    model_name: str\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262febb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m optimal_k = \u001b[32m10\u001b[39m \u001b[38;5;66;03m# PLACEHOLDER\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Have reference\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m src_model = \u001b[43mmodel\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1. Untrained encoder not frozen\u001b[39;00m\n\u001b[32m      7\u001b[39m encoder_clean_unfrozen = MNIST_Auto_Encoder(optimal_k, hidden_layer_size=hidden_layer_size).to(device).encoder\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimal_k = 10 # PLACEHOLDER\n",
    "\n",
    "# Have reference\n",
    "src_model = model\n",
    "\n",
    "# 1. Untrained encoder not frozen\n",
    "encoder_clean_unfrozen = MNIST_Auto_Encoder(optimal_k, hidden_layer_size=hidden_layer_size).to(device).encoder\n",
    "\n",
    "# 2. Untrained encoder but frozen\n",
    "encoder_clean_frozen = MNIST_Auto_Encoder(optimal_k, hidden_layer_size=hidden_layer_size).to(device).encoder\n",
    "freeze_module(encoder_clean_frozen)\n",
    "unfreeze_module(encoder_clean_frozen[-1])\n",
    "\n",
    "# 3. Trained encoder not frozen\n",
    "encoder_trained_unfrozen = MNIST_Auto_Encoder(optimal_k, hidden_layer_size=hidden_layer_size).to(device).encoder\n",
    "encoder_trained_unfrozen.load_state_dict(src_model.encoder.state_dict())\n",
    "\n",
    "# 4. Trained encoder but frozen\n",
    "encoder_trained_frozen = MNIST_Auto_Encoder(optimal_k, hidden_layer_size=hidden_layer_size).to(device).encoder\n",
    "encoder_trained_frozen.load_state_dict(src_model.encoder.state_dict())\n",
    "\n",
    "freeze_module(encoder_trained_frozen)\n",
    "unfreeze_module(encoder_trained_frozen[-1])\n",
    "\n",
    "models = [encoder_clean_unfrozen, encoder_clean_unfrozen, encoder_trained_unfrozen, encoder_trained_frozen]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ceeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "\n",
    "print(f'######## Begin Training Encoders on bottleneck={optimal_k} ########')\n",
    "\n",
    "\n",
    "train_loader = data.DataLoader(training_set, \n",
    "                                batch_size=batch_size, \n",
    "                                shuffle=True,\n",
    "                                num_workers=5, \n",
    "                                pin_memory=True\n",
    "                            )\n",
    "\n",
    "test_loader = data.DataLoader(testing_set, \n",
    "                                batch_size=batch_size, \n",
    "                                shuffle=False,\n",
    "                                num_workers=5, \n",
    "                                pin_memory=True\n",
    "                            )\n",
    "\n",
    "for sample_model, model_name in zip(models, ['Unfrozen Clean Encoder', 'Frozen Clean Encoder', 'Unfrozen Pretrained Encoder', 'Frozen Pretrained Encoder']):\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(sample_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "        # Per epoch reset accumulated loss\n",
    "        avg_training_loss = 0\n",
    "        avg_testing_loss = 0\n",
    "\n",
    "        # Run through each batch\n",
    "        for images, labels in tqdm(train_loader, desc='Training', unit=' batch'):\n",
    "            # Move data into the GPU\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calc loss\n",
    "            logits = sample_model(images)\n",
    "            loss = loss_function(logits, labels)\n",
    "\n",
    "            # Calc gradient and step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                avg_training_loss += loss.item()\n",
    "\n",
    "        # Set up for calculating testing loss\n",
    "        avg_training_loss /=  len(train_loader)\n",
    "\n",
    "        sample_model.eval()\n",
    "\n",
    "        # Calc training loss\n",
    "        with torch.no_grad():\n",
    "            for test_images, labels in tqdm(test_loader, desc='Testing', unit=' batch'):\n",
    "                test_images = test_images.to(device)\n",
    "                logits = sample_model(test_images)\n",
    "                \n",
    "                avg_testing_loss += loss_function(logits, labels).item()\n",
    "\n",
    "        avg_testing_loss /=  len(test_loader)\n",
    "\n",
    "        sample_model.train()\n",
    "        \n",
    "        print(\"\")\n",
    "\n",
    "        print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "        print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n",
    "\n",
    "        # Add end results to the lists\n",
    "        epoch_over_training_loss_per_model.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"training_loss\": avg_training_loss,\n",
    "            \"model_name\": model_name\n",
    "        })\n",
    "\n",
    "        epoch_over_testing_loss_per_model.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"training_loss\": avg_training_loss,\n",
    "            \"model_name\": model_name\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2150c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f663ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset_full_CIFAR10 = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=tfm)\n",
    "testset_full_CIFAR10  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8295131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_Classifier(nn.Module):\n",
    "    def __init__(self, C_dropout, F_dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        conv2d_dropout = C_dropout\n",
    "\n",
    "        self.forward_funnel_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=128, kernel_size=5),   # Extract useful features from the beginning\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3),  # Extract useful features from the learned features\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(conv2d_dropout),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                       # Reduce dimensionality\n",
    "        )\n",
    "\n",
    "        # self.forward_funnel_2 = nn.Sequential(\n",
    "        #     nn.Conv2d(in_channels=128, out_channels=64, kernel_size=5),   # Extract useful features from the beginning\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Dropout2d(conv2d_dropout),\n",
    "\n",
    "        #     nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3),  # Extract useful features from the learned features\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Dropout2d(conv2d_dropout),\n",
    "        #     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        # )\n",
    "\n",
    "        # Compute the number of features after the input has passed the funnel\n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, 3, 32, 32)\n",
    "\n",
    "            test_input.to(device)\n",
    "\n",
    "            features = self.forward_funnel_1(test_input)\n",
    "            # features = self.forward_funnel_2(features)\n",
    "\n",
    "            total_count = features.view(1, -1).size(1)\n",
    "\n",
    "        full_node_dropout = F_dropout\n",
    "        self.output_nodes = 100\n",
    "\n",
    "        self.classifer = nn.Sequential(\n",
    "            nn.Flatten(),                                           # Flatten the image from the funnel\n",
    "            nn.Linear(in_features=total_count, out_features=1000), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=1000, out_features=1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=1000, out_features=500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "\n",
    "            nn.Linear(in_features=500, out_features=self.output_nodes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(full_node_dropout),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(in_features=self.output_nodes, out_features=10)\n",
    "    \n",
    "    def partial_forward(self, x):\n",
    "        x = self.forward_funnel_1(x)\n",
    "        # x = self.forward_funnel_2(x)\n",
    "        x = self.classifer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.partial_forward(x)\n",
    "        logits = self.classifer(x)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d588522c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nForm of the data\\n\\ndata = \\n{\\n    epoch: int\\n    training/testing loss: float\\n}\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_over_training_loss_CIFAR10 = []\n",
    "epoch_over_testing_loss_CIFAR10 = []\n",
    "\n",
    "'''\n",
    "Form of the data\n",
    "\n",
    "data = \n",
    "{\n",
    "    epoch: int\n",
    "    training/testing loss: float\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter setup\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "learning_rate = 7.5e-5\n",
    "decay_rate = 5e-4\n",
    "\n",
    "c_dropout = 0.30\n",
    "f_dropout = 0.62\n",
    "\n",
    "\n",
    "print('######## Begining training for CIFAR10 classifier ##########')\n",
    "\n",
    "# Setup data loaders\n",
    "trainset_loader_CIFAR10 = data.DataLoader(trainset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   # num_workers=5,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "testset_loader_CIFAR10 = data.DataLoader(testset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   # num_workers=5,\n",
    "                                   shuffle=False,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "model = CIFAR10_Classifier(c_dropout, f_dropout)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=learning_rate, \n",
    "                       weight_decay=decay_rate\n",
    "                       )\n",
    "\n",
    "# Have references to variables outside of the epoch loop\n",
    "avg_training_loss = 0\n",
    "avg_testing_loss = 0\n",
    "\n",
    "# Epoch Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "    \n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for x, Y in tqdm(trainset_loader_CIFAR10, desc='Training', unit=' batch'):\n",
    "        # Transfer images to GPU\n",
    "        x = x.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Send images to model\n",
    "        x_pred = model(x)\n",
    "\n",
    "        # Calc loss\n",
    "        loss = loss_function(x_pred, Y)\n",
    "\n",
    "        # Calc gradient and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_training_loss += loss\n",
    "\n",
    "    # Switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, Y in tqdm(testset_loader_CIFAR10, desc='Testing', unit=' batches'):\n",
    "            # Move the images to the GPU\n",
    "            x = x.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            # Get logits and sum up total loss\n",
    "            x_pred = model(x)\n",
    "            avg_testing_loss += loss_function(x_pred, Y).item()\n",
    "\n",
    "    # Get training loss\n",
    "    avg_training_loss /= len(trainset_loader_CIFAR10)\n",
    "\n",
    "     # Get testing loss\n",
    "    avg_testing_loss /= len(testset_loader_CIFAR10)\n",
    "\n",
    "    # Switch model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    epoch_over_training_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"training_loss\": avg_training_loss\n",
    "        })\n",
    "    \n",
    "    epoch_over_testing_loss_CIFAR10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"testing_loss\": avg_testing_loss\n",
    "        })\n",
    "    \n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "    print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e63add",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in testset_loader_CIFAR10:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total += yb.numel()\n",
    "\n",
    "final_accuracy = float(correct / total)\n",
    "\n",
    "print(f\"Final Accuracy: {final_accuracy}\")\n",
    "\n",
    "epochs = [d[\"epoch\"] for d in epoch_over_training_loss_CIFAR10]\n",
    "train_loss = [d[\"training_loss\"] for d in epoch_over_training_loss_CIFAR10]\n",
    "test_loss = [d[\"testing_loss\"] for d in epoch_over_testing_loss_CIFAR10]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_loss, label=\"Training Loss\")\n",
    "plt.plot(epochs, test_loss, label=\"Testing Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"CIFAR10 Classifer: Training and Testing Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d202d5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ccfc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_Transformed_Classifier(CIFAR10_Classifier):\n",
    "    def __init__(self, C_dropout, F_dropout):\n",
    "        super().__init__(C_dropout, F_dropout)\n",
    "        \n",
    "        self.output_layer = nn.Linear(in_features=self.output_nodes, out_features=2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.partial_forward(x)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50be51ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_over_training_loss_CIFAR10_R = []\n",
    "epoch_over_testing_loss_CIFAR10_R = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bfa844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter setup\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "decay_rate = 1e-4\n",
    "\n",
    "c_dropout = 0.40\n",
    "f_dropout = 0.50\n",
    "\n",
    "\n",
    "print('######## Begining training for CIFAR10 classifier on rotated images ##########')\n",
    "\n",
    "# Setup data loaders\n",
    "trainset_loader_CIFAR10_R = data.DataLoader(trainset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   # num_workers=5,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "testset_loader_CIFAR10_R = data.DataLoader(testset_full_CIFAR10,\n",
    "                                   batch_size=batch_size,\n",
    "                                   # num_workers=5,\n",
    "                                   shuffle=False,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "model = CIFAR10_Transformed_Classifier(c_dropout, f_dropout)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), \n",
    "                       lr=learning_rate, \n",
    "                       weight_decay=decay_rate\n",
    "                       )\n",
    "\n",
    "# Have references to variables outside of the epoch loop\n",
    "avg_training_loss = 0\n",
    "avg_testing_loss = 0\n",
    "\n",
    "# Epoch Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "    \n",
    "    avg_training_loss = 0\n",
    "    avg_testing_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for x, _ in tqdm(trainset_loader_CIFAR10_R, desc='Training', unit=' batch'):\n",
    "\n",
    "        labels_upright = torch.zeros(x.size(0), dtype=torch.long)\n",
    "\n",
    "        images_rotated = torch.rot90(x, 1, [2, 3])\n",
    "        labels_rotated = torch.ones(x.size(0), dtype=torch.long)\n",
    "\n",
    "        all_images = torch.cat([x, images_rotated])\n",
    "        all_labels = torch.cat([labels_upright, labels_rotated])\n",
    "        \n",
    "        \n",
    "        # Transfer images to GPU\n",
    "        all_images = all_images.to(device)\n",
    "        all_labels = all_labels.to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Send images to model\n",
    "        x_pred = model(all_images)\n",
    "\n",
    "        # Calc loss\n",
    "        loss = loss_function(x_pred, all_labels)\n",
    "\n",
    "        # Calc gradient and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_training_loss += loss\n",
    "\n",
    "    # Switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in tqdm(testset_loader_CIFAR10_R, desc='Testing', unit=' batches'):\n",
    "            \n",
    "            labels_upright = torch.zeros(x.size(0), dtype=torch.long)\n",
    "\n",
    "            images_rotated = torch.rot90(x, 1, [2, 3])\n",
    "            labels_rotated = torch.ones(x.size(0), dtype=torch.long)\n",
    "\n",
    "            all_images = torch.cat([x, images_rotated])\n",
    "            all_labels = torch.cat([labels_upright, labels_rotated])\n",
    "            \n",
    "            # Transfer images to GPU\n",
    "            all_images = all_images.to(device)\n",
    "            all_labels = all_labels.to(device)\n",
    "            \n",
    "            # Move the images to the GPU\n",
    "            all_images = all_images.to(device)\n",
    "            all_labels = all_labels.to(device)\n",
    "\n",
    "            # Get logits and sum up total loss\n",
    "            x_pred = model(all_images)\n",
    "            avg_testing_loss += loss_function(x_pred, all_labels).item()\n",
    "\n",
    "    # Get training loss\n",
    "    avg_training_loss /= len(trainset_loader_CIFAR10)\n",
    "\n",
    "     # Get testing loss\n",
    "    avg_testing_loss /= len(testset_loader_CIFAR10)\n",
    "\n",
    "    # Switch model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    epoch_over_training_loss_CIFAR10_R.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"training_loss\": avg_training_loss\n",
    "        })\n",
    "    \n",
    "    epoch_over_testing_loss_CIFAR10_R.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"testing_loss\": avg_testing_loss\n",
    "        })\n",
    "    \n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "    print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3443e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights from problem 5\n",
    "torch.save(model.state_dict(), 'Q4_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = total = 0\n",
    "with torch.no_grad():\n",
    "    for x, _ in testset_loader_CIFAR10_R:\n",
    "        \n",
    "        labels_upright = torch.zeros(x.size(0), dtype=torch.long)\n",
    "\n",
    "        images_rotated = torch.rot90(x, 1, [2, 3])\n",
    "        labels_rotated = torch.ones(x.size(0), dtype=torch.long)\n",
    "\n",
    "        all_images = torch.cat([x, images_rotated])\n",
    "        all_labels = torch.cat([labels_upright, labels_rotated])\n",
    "        \n",
    "        # Transfer images to GPU\n",
    "        all_images = all_images.to(device)\n",
    "        all_labels = all_labels.to(device)\n",
    "        \n",
    "        # Move the images to the GPU\n",
    "        all_images = all_images.to(device)\n",
    "        all_labels = all_labels.to(device)\n",
    "\n",
    "        # Get logits and sum up total loss\n",
    "        logits = model(all_images)\n",
    "        \n",
    "        pred = logits.argmax(1)\n",
    "        \n",
    "        correct += (pred == all_labels).sum().item()\n",
    "        total += all_labels.numel()\n",
    "\n",
    "final_accuracy = float(correct / total)\n",
    "\n",
    "print(f\"Final Accuracy: {final_accuracy}\")\n",
    "\n",
    "\n",
    "epochs = [d[\"epoch\"] for d in epoch_over_training_loss_CIFAR10_R]\n",
    "train_loss = [d[\"training_loss\"] for d in epoch_over_training_loss_CIFAR10_R]\n",
    "test_loss = [d[\"testing_loss\"] for d in epoch_over_testing_loss_CIFAR10_R]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_loss, label=\"Training Loss\")\n",
    "plt.plot(epochs, test_loss, label=\"Testing Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"CIFAR10 Rotation Classifer: Training and Testing Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2396329",
   "metadata": {},
   "source": [
    "Results\n",
    "\n",
    "---\n",
    "\n",
    "Training Loss = \n",
    "\n",
    "Testing Loss = \n",
    "\n",
    "Final Testing Loss = \n",
    "\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "decay_rate = 5e-4\n",
    "\n",
    "\n",
    "c_dropout = 0.40\n",
    "\n",
    "f_dropout = 0.50\n",
    "\n",
    "---\n",
    "\n",
    "Initially, I decided to start with the same hyperparameters as the final model in Question 3 just to see what the current losses were looking like. As a result, I was able to get a training and testing loss around 0.38. Though in this run, I decided to end the training early since I noticed that the model was overtraining starting from the 14th epoch and beyond.\n",
    "\n",
    "Noticing the issue of overtraining, I decided to switch to the AdamW optimizer since it handles weight decay better. However, I still got similar results at the 14th epoch. Instead of focusining on changing the optimizer, I decided to try and change the dropout percentages. \n",
    "\n",
    "In the third trial, I changed the dropout rates from 0.3, convolutional dropout, to 0.4 which allowed me to achieve a better training loss around 0.33 and testing loss around 0.31. During this run, I noticed that the model began to learn slower by the 10th epoch and then began overtraining by the 14th epoch. \n",
    "\n",
    "For the forth attempt, I tried to increase the learning rate from 7.5e-5 to 1e-4 and sadly did not see any better results by the time the model started overtraining at the 14 epoch, however, I was able to achieve similar losses around 0.31.\n",
    "\n",
    "On the fifth trial, I decided that the model learning rate was being affected by the dropout rate on the fully connected layer, so I decreased it to 0.50. This allowed me to get a training loss around 0.301 and testing loss around 0.297 at the 14th epoch. The decrease in loss was nice, but I still needed to deal with overtraining since the model could never get past this testing loss barrier at around 0.29.\n",
    "\n",
    "On the sixth run, I wanted to experiment with a higher weight decay rate, increased from 5e-4 to 7.5e-4, but this resulted in my model starting to overtrain at the 15th epoch with a min testing loss of 0.3032. Though, I still wanted to see if it would be wise to tinker with the decay rate, so I instead decreased it to 2.5e-4 on the 7th run which gave me the same issue of overtraining past the 15th epoch and a final testing loss of around 0.29.\n",
    "\n",
    "At this point, I believed that I have found the most optimal hyperparameters for my model based on the current architecture, so I did one final training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96a5475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weights(model_final, model_src, k, is_frozen):\n",
    "    \n",
    "    for i in range(len(model_final.forward_funnel_1)):\n",
    "\n",
    "        if k == 0: return\n",
    "\n",
    "        src_layer = model_src.forward_funnel_1[i]\n",
    "        final_layer = model_final.forward_funnel_1[i]\n",
    "\n",
    "        if (hasattr(src_layer, 'weight') and hasattr(final_layer, 'weight')):\n",
    "            final_layer.weight.data = src_layer.weight.data.clone()\n",
    "            if is_frozen:\n",
    "                final_layer.weight.requires_grad = False\n",
    "            \n",
    "            # This will always run if we get here. I do not intend on making layers with biases\n",
    "            if (hasattr(src_layer, 'bias') and hasattr(final_layer, 'bias')):\n",
    "                final_layer.bias.data = src_layer.bias.data.clone()\n",
    "                if is_frozen:\n",
    "                    final_layer.bias.requires_grad = False\n",
    "\n",
    "                k -= 1\n",
    "\n",
    "    \n",
    "    for i in range(len(model_final.classifer)):\n",
    "        \n",
    "        if k == 0: return\n",
    "\n",
    "        src_layer = model_src.classifer[i]\n",
    "        final_layer = model_final.classifer[i]\n",
    "\n",
    "        if (hasattr(src_layer, 'weight') and hasattr(final_layer, 'weight')):\n",
    "            final_layer.weight.data = src_layer.weight.data.clone()\n",
    "            if is_frozen:\n",
    "                final_layer.weight.requires_grad = False\n",
    "            \n",
    "            # This will always run if we get here. I do not intend on making layers with biases\n",
    "            if (hasattr(src_layer, 'bias') and hasattr(final_layer, 'bias')):\n",
    "                final_layer.bias.data = src_layer.bias.data.clone()\n",
    "                if is_frozen:\n",
    "                    final_layer.bias.requires_grad = False\n",
    "\n",
    "                k -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da72851a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor of the data for this list is...\\n\\ndata = {\\n    k: int\\n    epoch: int\\n    training/testing loss: floats\\n    frozen: True or False\\n}\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_over_training_loss_CIFAR10_per_k = []\n",
    "epoch_over_testing_loss_CIFAR10_per_k = []\n",
    "\n",
    "'''\n",
    "For of the data for this list is...\n",
    "\n",
    "data = {\n",
    "    k: int\n",
    "    epoch: int\n",
    "    training/testing loss: floats\n",
    "    frozen: True or False\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1dea2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Q4_model_weights.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Initialize model for the sake of weight transfer\u001b[39;00m\n\u001b[32m     13\u001b[39m src_model = CIFAR10_Classifier(c_dropout, f_dropout)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m src_model.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mQ4_model_weights.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m######## Begining training for CIFAR10 classifier + transfer learning ##########\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m current_k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, k, \u001b[32m1\u001b[39m):\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Setup data loaders\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mukad\\Desktop\\Projects and Related Work\\Intro-to-Deep-Learning-Projects\\Project 2\\.venv\\Lib\\site-packages\\torch\\serialization.py:1425\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1423\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1427\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1428\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1429\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1430\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mukad\\Desktop\\Projects and Related Work\\Intro-to-Deep-Learning-Projects\\Project 2\\.venv\\Lib\\site-packages\\torch\\serialization.py:751\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    750\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mukad\\Desktop\\Projects and Related Work\\Intro-to-Deep-Learning-Projects\\Project 2\\.venv\\Lib\\site-packages\\torch\\serialization.py:732\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Q4_model_weights.pth'"
     ]
    }
   ],
   "source": [
    "# Hyperparameter setup\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "decay_rate = 1e-4\n",
    "\n",
    "c_dropout = 0.40\n",
    "f_dropout = 0.50\n",
    "\n",
    "k = 5 # Max number of layers for the current model ~~ Excluding the output layer\n",
    "\n",
    "# Initialize model for the sake of weight transfer\n",
    "src_model = CIFAR10_Transformed_Classifier(c_dropout, f_dropout)\n",
    "src_model.load_state_dict(torch.load('Q4_model_weights.pth'))\n",
    "\n",
    "\n",
    "print('######## Begining training for CIFAR10 classifier + transfer learning ##########')\n",
    "\n",
    "for i in range(2):\n",
    "    \n",
    "    is_frozen = False if i == 0 else True\n",
    "    \n",
    "    for current_k in range(1, k, 1):\n",
    "        # Setup data loaders\n",
    "        trainset_loader_CIFAR10 = data.DataLoader(trainset_full_CIFAR10,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=True,\n",
    "                                        # num_workers=5,\n",
    "                                        pin_memory=True)\n",
    "\n",
    "        testset_loader_CIFAR10 = data.DataLoader(testset_full_CIFAR10,\n",
    "                                        batch_size=batch_size,\n",
    "                                        # num_workers=5,\n",
    "                                        shuffle=False,\n",
    "                                        pin_memory=True)\n",
    "\n",
    "        model_final = CIFAR10_Classifier(c_dropout, f_dropout)\n",
    "\n",
    "        transfer_weights(model_final, src_model, k, is_frozen)\n",
    "\n",
    "        model_final.to(device)\n",
    "\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model_final.parameters(), \n",
    "                            lr=learning_rate, \n",
    "                            weight_decay=decay_rate\n",
    "                            )\n",
    "\n",
    "        # Have references to variables outside of the epoch loop\n",
    "        avg_training_loss = 0\n",
    "        avg_testing_loss = 0\n",
    "\n",
    "        # Epoch Loop\n",
    "        for epoch in range(epochs):\n",
    "            print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "            \n",
    "            avg_training_loss = 0\n",
    "            avg_testing_loss = 0\n",
    "\n",
    "            model_final.train()\n",
    "\n",
    "            for x, _ in tqdm(trainset_loader_CIFAR10, desc='Training', unit=' batch'):\n",
    "\n",
    "                labels_upright = torch.zeros(x.size(0), dtype=torch.long)\n",
    "\n",
    "                images_rotated = torch.rot90(x, 1, [2, 3])\n",
    "                labels_rotated = torch.ones(x.size(0), dtype=torch.long)\n",
    "\n",
    "                all_images = torch.cat([x, images_rotated])\n",
    "                all_labels = torch.cat([labels_upright, labels_rotated])\n",
    "                \n",
    "                \n",
    "                # Transfer images to GPU\n",
    "                all_images = all_images.to(device)\n",
    "                all_labels = all_labels.to(device)\n",
    "\n",
    "                # Zero out gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Send images to model\n",
    "                x_pred = model_final(all_images)\n",
    "\n",
    "                # Calc loss\n",
    "                loss = loss_function(x_pred, all_labels)\n",
    "\n",
    "                # Calc gradient and update weights\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    avg_training_loss += loss\n",
    "\n",
    "            # Switch to eval mode\n",
    "            model_final.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for x, _ in tqdm(testset_loader_CIFAR10, desc='Testing', unit=' batches'):\n",
    "                    \n",
    "                    labels_upright = torch.zeros(x.size(0), dtype=torch.long)\n",
    "\n",
    "                    images_rotated = torch.rot90(x, 1, [2, 3])\n",
    "                    labels_rotated = torch.ones(x.size(0), dtype=torch.long)\n",
    "\n",
    "                    all_images = torch.cat([x, images_rotated])\n",
    "                    all_labels = torch.cat([labels_upright, labels_rotated])\n",
    "                    \n",
    "                    # Transfer images to GPU\n",
    "                    all_images = all_images.to(device)\n",
    "                    all_labels = all_labels.to(device)\n",
    "                    \n",
    "                    # Move the images to the GPU\n",
    "                    all_images = all_images.to(device)\n",
    "                    all_labels = all_labels.to(device)\n",
    "\n",
    "                    # Get logits and sum up total loss\n",
    "                    x_pred = model_final(all_images)\n",
    "                    avg_testing_loss += loss_function(x_pred, all_labels).item()\n",
    "\n",
    "            # Get training loss\n",
    "            avg_training_loss /= len(trainset_loader_CIFAR10)\n",
    "\n",
    "            # Get testing loss\n",
    "            avg_testing_loss /= len(testset_loader_CIFAR10)\n",
    "\n",
    "            # Switch model back to training mode\n",
    "            model_final.train()\n",
    "\n",
    "            epoch_over_training_loss_CIFAR10_per_k.append({\n",
    "                \"k\": current_k,\n",
    "                \"epoch\": epoch,\n",
    "                \"training_loss\": avg_training_loss\n",
    "                })\n",
    "            \n",
    "            epoch_over_testing_loss_CIFAR10_per_k.append({\n",
    "                \"k\": current_k,\n",
    "                \"epoch\": epoch,\n",
    "                \"training_loss\": avg_training_loss\n",
    "                })\n",
    "            \n",
    "\n",
    "            print(\"\")\n",
    "\n",
    "            print(f'   -> Training Loss: {avg_training_loss: .4f}\\n')\n",
    "            print(f'   -> Testing Loss: {avg_testing_loss: .4f}\\n')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4754fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate frozen and unfrozen runs\n",
    "for frozen_status, title in zip([True, False], [\"Frozen Transfer Learning\", \"Unfrozen Transfer Learning\"]):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ks = sorted(set(d[\"k\"] for d in epoch_over_training_loss if d[\"frozen\"] == frozen_status))\n",
    "    for k in ks:\n",
    "        epochs = [d[\"epoch\"] for d in epoch_over_training_loss if d[\"k\"] == k and d[\"frozen\"] == frozen_status]\n",
    "        train_loss = [d[\"training_loss\"] for d in epoch_over_training_loss if d[\"k\"] == k and d[\"frozen\"] == frozen_status]\n",
    "        test_loss = [d[\"training_loss\"] for d in epoch_over_testing_loss if d[\"k\"] == k and d[\"frozen\"] == frozen_status]\n",
    "        plt.plot(epochs, train_loss, label=f\"Train k={k}\")\n",
    "        plt.plot(epochs, test_loss, '--', label=f\"Test k={k}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(title + \": Epoch vs. Loss (per k)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e40d68a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_Encoder(CIFAR10_Classifier):\n",
    "    def __init__(self, C_dropout, F_dropout, embedding_size=2):\n",
    "        super().__init__(C_dropout, F_dropout)\n",
    "\n",
    "        self.output_layer = nn.Linear(in_features=self.output_nodes, out_features=embedding_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.partial_forward(x)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d348d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveCIFAR10(data.Dataset):\n",
    "    def __init__(self, base_dataset):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.labels = np.array(self.base_dataset.targets)\n",
    "\n",
    "        # Pre-compute a dictionary mapping each class to a list of its indices\n",
    "        self.labels_to_indices = {label: np.where(self.labels == label)[0]\n",
    "                                  for label in set(self.labels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the anchor image and its label\n",
    "        img1, label1 = self.base_dataset[index]\n",
    "\n",
    "        # Decide whether to sample a positive or negative pair (50% chance)\n",
    "        is_similar = random.random() > 0.5\n",
    "\n",
    "        if is_similar:\n",
    "            # Positive pair: sample another image from the same class\n",
    "            positive_indices = self.labels_to_indices[label1]\n",
    "            # Make sure we don't pick the same image\n",
    "            positive_index = index\n",
    "            while positive_index == index:\n",
    "                positive_index = np.random.choice(positive_indices)\n",
    "            img2, _ = self.base_dataset[positive_index]\n",
    "            similarity = 1.0 # Similarity label is 1 for positive pairs\n",
    "        else:\n",
    "            # Negative pair: sample an image from a different class\n",
    "            negative_label = np.random.choice(list(set(self.labels) - {label1}))\n",
    "            negative_indices = self.labels_to_indices[negative_label]\n",
    "            negative_index = np.random.choice(negative_indices)\n",
    "            img2, _ = self.base_dataset[negative_index]\n",
    "            similarity = 0.0 # Similarity label is 0 for negative pairs\n",
    "\n",
    "        return img1, img2, torch.tensor(similarity, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf11b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, embedding1, embedding2, similarity_label):\n",
    "        # Calculate the euclidean distance squared between the embeddings\n",
    "        euclidean_distance = F.pairwise_distance(embedding1, embedding2, keepdim=True)\n",
    "        dist_sq = torch.pow(euclidean_distance, 2)\n",
    "\n",
    "        # Loss for similar pairs (S=1): we want their distance to be small\n",
    "        loss_similar = similarity_label * dist_sq\n",
    "\n",
    "        # Loss for dissimilar pairs (S=0): we want their distance to be large, at least > margin\n",
    "        # The loss is max(0, margin - distance)^2\n",
    "        loss_dissimilar = (1 - similarity_label) * torch.pow(\n",
    "            torch.clamp(self.margin - euclidean_distance, min=0.0), 2\n",
    "        )\n",
    "\n",
    "        # Combine the losses and average over the batch\n",
    "        total_loss = torch.mean(loss_similar + loss_dissimilar)\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea658b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_embeddings(model, loader):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            embs = model(images).cpu().numpy()\n",
    "            embeddings.append(embs)\n",
    "            all_labels.append(labels.numpy())\n",
    "    return np.concatenate(embeddings), np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b755285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(embeddings, labels, title=\"\"):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    class_names = trainset_full_CIFAR10.classes\n",
    "    for i in range(len(class_names)):\n",
    "        # Select embeddings that correspond to the current class\n",
    "        inds = np.where(labels == i)[0]\n",
    "        plt.scatter(embeddings[inds, 0], embeddings[inds, 1], alpha=0.5, label=class_names[i])\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae054d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Starting training of CIFAR10 embedding model ##########\n",
      "----- Epoch: 1/30 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/782 [00:00<?, ? batchs/s]"
     ]
    }
   ],
   "source": [
    "# Hyperparameter setup\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "learning_rate = 7.5e-5\n",
    "decay_rate = 5e-4\n",
    "\n",
    "c_dropout = 0.30\n",
    "f_dropout = 0.62\n",
    "\n",
    "embedding_model = CIFAR10_Encoder(c_dropout, f_dropout).to(device)\n",
    "contrastive_loss_fn = ContrastiveLoss(margin=1.0)\n",
    "optimizer = optim.Adam(embedding_model.parameters(), lr=learning_rate, weight_decay=decay_rate)\n",
    "\n",
    "contrastive_train_ds = ContrastiveCIFAR10(trainset_full_CIFAR10)\n",
    "contrastive_train_loader = data.DataLoader(contrastive_train_ds, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True)\n",
    "\n",
    "print(f'######## Starting training of CIFAR10 embedding model ##########')\n",
    "\n",
    "embedding_model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'----- Epoch: {epoch + 1}/{epochs} -----')\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for img1, img2, sim in tqdm(contrastive_train_loader, desc='Training', unit=' batchs'):\n",
    "        img1, img2, sim = img1.to(device), img2.to(device), sim.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        emb1, emb2 = embedding_model(img1), embedding_model(img2)\n",
    "        loss = contrastive_loss_fn(emb1, emb2, sim)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"  -> [Contrastive] Epoch {epoch+1}/3 | Loss={running_loss/len(contrastive_train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d584a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_vis = data.DataLoader(testset_full_CIFAR10, batch_size=256, shuffle=False)\n",
    "\n",
    "final_embeddings, final_labels = get_all_embeddings(embedding_model, test_loader_vis)\n",
    "plot_embeddings(final_embeddings, final_labels, \"Embeddings After Training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b3234c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for this project\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ea66ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Grab the MNIST dataset\n",
    "training_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testing_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64c1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin data preprocessing\n",
    "\n",
    "def data_prepocessor(dataset):\n",
    "    \"\"\"\n",
    "    Used to prepare the data for processing by normalizing the data and flattening the images.\n",
    "\n",
    "    Args:\n",
    "        dataset (torch.utils.data.Dataset): The dataset to preprocess.\n",
    "\n",
    "    Returns:\n",
    "        return_tensors Tuple[torch.Tensor, torch.Tensor]: A tuple containing the preprocessed data and the corresponding\n",
    "    \"\"\"\n",
    "\n",
    "    new_data = (dataset.data / 255.0) - 0.5\n",
    "    flattened_img_data = new_data.view(new_data.shape[0], -1)\n",
    "    targets = dataset.targets\n",
    "\n",
    "    return flattened_img_data, targets\n",
    "\n",
    "x_train, y_train = data_prepocessor(training_set)\n",
    "x_test, y_test = data_prepocessor(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040f5af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "The system GPU | NVIDIA GeForce RTX 4060 Laptop GPU | is AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "# Verify that GPU is connected and available\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'The system GPU | {torch.cuda.get_device_name(0) if not None else 'Error'} | is {'AVAILABLE' if torch.cuda.is_available() else 'NOT AVAILABLE' }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c0c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Auto_Encoder(nn.Module):\n",
    "    def __init__(self, bottleneck, input_size=784, hidden_layer_size=784):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        layers.append(\n",
    "            nn.Linear(in_features=input_size, out_features=hidden_layer_size)\n",
    "        )\n",
    "\n",
    "        layers.append(\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        layers.append(\n",
    "            nn.Linear(in_features=hidden_layer_size, out_features=bottleneck)\n",
    "        )\n",
    "\n",
    "        layers.append(\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        layers.append(\n",
    "            nn.Linear(in_features=bottleneck, out_features=hidden_layer_size)\n",
    "        )\n",
    "\n",
    "        self.hidden_layers = nn.Sequential(*layers)\n",
    "\n",
    "        self.ouput_layer = nn.Linear(in_features=hidden_layer_size, out_features=input_size)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        x = self.hidden_layers(x)\n",
    "        logits = self.ouput_layer(x)\n",
    "\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144822a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50\n",
      "   -> Loss: 8.789774989709258\n",
      "Epoch: 2/50\n",
      "   -> Loss: 2.5282192705199122\n",
      "Epoch: 3/50\n",
      "   -> Loss: 1.6945428120161523\n",
      "Epoch: 4/50\n",
      "   -> Loss: 1.2996626258391188\n",
      "Epoch: 5/50\n",
      "   -> Loss: 1.055821195102908\n",
      "Epoch: 6/50\n",
      "   -> Loss: 0.8589515625062631\n",
      "Epoch: 7/50\n",
      "   -> Loss: 0.7157718052421842\n",
      "Epoch: 8/50\n",
      "   -> Loss: 0.6021099982372107\n",
      "Epoch: 9/50\n",
      "   -> Loss: 0.4815529972456716\n",
      "Epoch: 10/50\n",
      "   -> Loss: 0.4646894164307014\n",
      "Epoch: 11/50\n",
      "   -> Loss: 0.35622766967480857\n",
      "Epoch: 12/50\n",
      "   -> Loss: 0.30523716997277006\n",
      "Epoch: 13/50\n",
      "   -> Loss: 0.2566499762260719\n",
      "Epoch: 14/50\n",
      "   -> Loss: 0.1972905791226367\n",
      "Epoch: 15/50\n",
      "   -> Loss: 0.17604048190150934\n",
      "Epoch: 16/50\n",
      "   -> Loss: 0.13618185880000055\n",
      "Epoch: 17/50\n",
      "   -> Loss: 0.1083854388139116\n",
      "Epoch: 18/50\n",
      "   -> Loss: 0.07994410171670552\n",
      "Epoch: 19/50\n",
      "   -> Loss: 0.09178971332150354\n",
      "Epoch: 20/50\n",
      "   -> Loss: 0.05670880131690126\n",
      "Epoch: 21/50\n",
      "   -> Loss: 0.06269707425529703\n",
      "Epoch: 22/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m optimizer.zero_grad()\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Calc loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m loss = loss_function(logits, labels)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Calc gradient and step\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mukad\\Desktop\\Projects and Related Work\\Intro-to-Deep-Learning-Projects\\Project 2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mukad\\Desktop\\Projects and Related Work\\Intro-to-Deep-Learning-Projects\\Project 2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mMNIST_Auto_Encoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x) -> torch.Tensor:\n\u001b[32m     32\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.hidden_layers(x)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mouput_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mukad\\Desktop\\Projects and Related Work\\Intro-to-Deep-Learning-Projects\\Project 2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mukad\\Desktop\\Projects and Related Work\\Intro-to-Deep-Learning-Projects\\Project 2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mukad\\Desktop\\Projects and Related Work\\Intro-to-Deep-Learning-Projects\\Project 2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "\n",
    "model = MNIST_Auto_Encoder(700, hidden_layer_size=1000)\n",
    "model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "training_dataset = data.TensorDataset(x_train, y_train)\n",
    "\n",
    "data_loader = data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch + 1}/{epochs}')\n",
    "\n",
    "    avg_loss = 0\n",
    "\n",
    "    for inputs, labels in data_loader:\n",
    "        # Move data into the GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calc loss\n",
    "        logits = model(inputs)\n",
    "        loss = loss_function(logits, labels)\n",
    "\n",
    "        # Calc gradient and step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "    avg_loss = avg_loss / batch_size\n",
    "    print(f'   -> Loss: {avg_loss%.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446db5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
